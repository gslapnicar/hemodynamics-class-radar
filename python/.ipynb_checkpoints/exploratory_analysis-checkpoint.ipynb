{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools\n",
    "import scipy\n",
    "\n",
    "from pprint import pprint\n",
    "from scipy.io import loadmat\n",
    "from natsort import natsorted\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata analysis\n",
    "Start by exploring the data. How many subjects have how much of which data. Make some summarization (and plots where possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_subject_metadata(file, summary=False, plot=False):\n",
    "    print(\"\\n=========================================[SUBJECT METADATA]===========================================\\n\")\n",
    "    metadata = pd.read_excel(file, sheet_name=\"Subject overview\", header=1)\n",
    "    metadata = metadata.drop([\"Unnamed: 0\", \"Unnamed: 7\", \"Unnamed: 8\", \"Count\", \"Ratio\"], axis=1).head(30)\n",
    "\n",
    "    if summary:\n",
    "        print(\"[Age]:\\n\", \"mean:\", metadata[\"Age\"].mean(), \"\\tstd:\", metadata[\"Age\"].std())\n",
    "        print()\n",
    "        print(\"[Sex]:\")\n",
    "        display(metadata[\"Sex\"].value_counts())\n",
    "        print()\n",
    "        print(\"[Height (cm)]:\\n\", \"mean:\", metadata[\"Height (cm)\"].mean(), \"\\tstd:\", metadata[\"Height (cm)\"].std())\n",
    "        print()\n",
    "        print(\"[Weight (kg)]:\\n\", \"mean:\", metadata[\"Weight (kg)\"].mean(), \"\\tstd:\", metadata[\"Weight (kg)\"].std())\n",
    "        print()\n",
    "        print(\"[BMI]:\\n\", \"mean:\", metadata[\"BMI\"].mean(), \"\\tstd:\", metadata[\"BMI\"].std())\n",
    "    else:\n",
    "        print(\"Supressed output.\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        metadata.hist(column=\"Age\", bins=10, grid=False, rwidth=0.9)\n",
    "        plt.title(\"Age distribution\")\n",
    "        plt.xlabel(\"Age [Years]\")\n",
    "        plt.ylabel(\"Instances\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(\"Sex distribution\")\n",
    "        metadata[\"Sex\"].value_counts().plot(kind=\"bar\", rot=0)\n",
    "        plt.xlabel(\"Sex [Male and Female]\")\n",
    "        plt.ylabel(\"Instances\")\n",
    "\n",
    "        plt.figure()\n",
    "        metadata.hist(column=\"Height (cm)\", bins=10, grid=False, rwidth=0.9)\n",
    "        plt.title(\"Height distribution\")\n",
    "        plt.xlabel(\"Height [cm]\")\n",
    "        plt.ylabel(\"Instances\")\n",
    "\n",
    "        plt.figure()\n",
    "        metadata.hist(column=\"Weight (kg)\", bins=10, grid=False, rwidth=0.9)\n",
    "        plt.title(\"Weight distribution\")\n",
    "        plt.xlabel(\"Weight [kg]\")\n",
    "        plt.ylabel(\"Instances\")\n",
    "\n",
    "        plt.figure()\n",
    "        metadata.hist(column=\"BMI\", bins=10, grid=False, rwidth=0.9)\n",
    "        plt.title(\"BMI distribution\")\n",
    "        plt.xlabel(\"BMI\")\n",
    "        plt.ylabel(\"Instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scenario_metadata(file, summary=False, plot=False):\n",
    "    print(\"\\n=========================================[SCENARIO METADATA]===========================================\\n\")\n",
    "    metadata = pd.read_excel(file, sheet_name=\"Scenario durations\", header=1)\n",
    "    metadata = metadata.drop([\"Unnamed: 0\", \"Unnamed: 9\", \"Unnamed: 10\", \"Resting.1\", \"Valsalva.1\", \"Apnea.1\", \"TiltUp.1\", \"TiltDown.1\"], axis=1).head(30)\n",
    "    \n",
    "    if summary:\n",
    "        print(\"[Subject recordings] How many subjects (out of 30) have this data:\")\n",
    "        metadata_counts = metadata[[\"Resting\", \"Valsalva\", \"Apnea\", \"TiltUp\", \"TiltUp_cut\", \"TiltDown\", \"TiltDown_cut\"]].fillna(0).astype(bool).sum(axis=0)\n",
    "        display(metadata_counts)\n",
    "        print()\n",
    "        print(\"[Recording durations] How many hours (in total) we have for each data:\")\n",
    "        metadata_duration = metadata[[\"Resting\", \"Valsalva\", \"Apnea\", \"TiltUp\", \"TiltUp_cut\", \"TiltDown\", \"TiltDown_cut\"]].sum(axis=0, skipna=True).divide(60*60, axis=0)\n",
    "        display(metadata_duration)\n",
    "    else:\n",
    "        print(\"Supressed output.\")\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        metadata[[\"Resting\", \"Valsalva\", \"Apnea\", \"TiltUp\", \"TiltUp_cut\", \"TiltDown\", \"TiltDown_cut\"]].fillna(0).astype(bool).sum(axis=0).plot(kind=\"bar\", rot=30)\n",
    "        plt.title(\"Number of recordings per class\")\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Number of recordings\")\n",
    "        \n",
    "        plt.figure()\n",
    "        metadata[[\"Resting\", \"Valsalva\", \"Apnea\", \"TiltUp\", \"TiltUp_cut\", \"TiltDown\", \"TiltDown_cut\"]].sum(axis=0, skipna=True).divide(60*60, axis=0).plot(kind=\"bar\", rot=30)\n",
    "        plt.title(\"Total duration of each class\")\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Duration in hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ground_truth_info(file, summary=False):\n",
    "    print(\"\\n=========================================[GROUND TRUTH METADATA]===========================================\\n\")\n",
    "    columns = [\"Resting\", \"Valsalva\", \"Apnea\", \"TiltUp\", \"TiltDown\"]\n",
    "    metadata = pd.read_excel(file, sheet_name=\"Measurement info\", header=1)\n",
    "    nan_counts = metadata.isnull().sum(axis=1)\n",
    "    \n",
    "    if summary:\n",
    "        print(\"Subjects with some missing data:\")\n",
    "        missing_data_subjects = metadata[columns].dropna(thresh=1)\n",
    "        display(missing_data_subjects)\n",
    "    \n",
    "        print(\"Subjects for which all data is available:\")\n",
    "        full_data_subjects = metadata.drop(missing_data_subjects.index, axis=0)\n",
    "        display(full_data_subjects[\"ID\"].to_frame())\n",
    "    else:\n",
    "        print(\"Supressed output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data reading\n",
    "Read the raw data from .mat files using python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mat_file(file, plot=False):\n",
    "    mat = loadmat(file)\n",
    "    signal_metadata = pd.DataFrame(columns=[\"signal\", \"fs\"])\n",
    "    actual_data = pd.DataFrame(columns=[\"signal\", \"fs\", \"data\", \"length\"])\n",
    "    i, j = 0, 0\n",
    "\n",
    "    for key, val in mat.items():\n",
    "        if key not in [\"__header__\", \"__version__\", \"__globals__\", \"measurement_info\"]:\n",
    "            if \"fs\" in key:\n",
    "                print(key, \":\", val[0][0])\n",
    "                parts = key.split(\"_\") \n",
    "                signal_metadata.loc[i, \"signal\"] = parts[1]\n",
    "                signal_metadata.loc[i, \"fs\"] = val[0][0]\n",
    "                i += 1\n",
    "            else:\n",
    "                if len(val) == 0:\n",
    "                    print(key, \": no data!\")\n",
    "                else:\n",
    "                    print(key, \": data of length\", len(val))\n",
    "                    \n",
    "                    for i, row in signal_metadata.iterrows():\n",
    "                        if row[\"signal\"] in key:\n",
    "                            actual_data.loc[j, \"signal\"] = key\n",
    "                            actual_data.loc[j, \"fs\"] = row[\"fs\"]\n",
    "                            actual_data.loc[j, \"data\"] = list(itertools.chain.from_iterable(val))\n",
    "                            actual_data.loc[j, \"length\"] = len(val)\n",
    "                            j += 1\n",
    "                            \n",
    "    if plot:\n",
    "        colors = plt.rcParams[\"axes.prop_cycle\"]()\n",
    "        n = actual_data.shape[0]\n",
    "        fig, axs = plt.subplots(n, sharex=False, figsize=(16, 2*n))\n",
    "        \n",
    "        for i, row in actual_data.iterrows():\n",
    "            axs[i].plot(row[\"data\"], color=next(colors)[\"color\"], label=row[\"signal\"])\n",
    "        axs[0].title.set_text(file)\n",
    "        \n",
    "        fig.legend(loc=\"right\")\n",
    "        plt.show()\n",
    "        \n",
    "        display(signal_metadata)\n",
    "        display(actual_data)\n",
    "        \n",
    "    return actual_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Preprocess the raw data:\n",
    "1. Filter (Butterworth band-pass)\n",
    "2. Downsample (lower the extremely high base sampling freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_raw_data(file, data, cut_low, cut_high, order=2, plot=False):\n",
    "    filtered_data = pd.DataFrame(columns=data.columns)\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        filtered_data.loc[i, [\"signal\", \"fs\"]] = row[[\"signal\", \"fs\"]]\n",
    "        filtered_signal = butter_bandpass_filter(np.subtract(row[\"data\"], np.mean(row[\"data\"])), cut_low, cut_high, row[\"fs\"], order)\n",
    "        filtered_data.loc[i, \"data\"] = filtered_signal\n",
    "        filtered_data.loc[i, \"length\"] = len(filtered_signal)\n",
    "        \n",
    "    if plot:\n",
    "        colors = plt.rcParams[\"axes.prop_cycle\"]()\n",
    "        n = filtered_data.shape[0]\n",
    "        fig, axs = plt.subplots(n, sharex=False, figsize=(16, 2*n))\n",
    "        \n",
    "        for i, row in filtered_data.iterrows():\n",
    "            axs[i].plot(row[\"data\"], color=next(colors)[\"color\"], label=row[\"signal\"])\n",
    "        axs[0].title.set_text(file)\n",
    "        \n",
    "        fig.legend(loc=\"right\")\n",
    "        plt.show()\n",
    "        \n",
    "        display(filtered_data)\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "def resample_data(file, data, target_fs, plot=False):\n",
    "    resampled_data = pd.DataFrame(columns=data.columns)\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        resampled_data.loc[i, \"signal\"] = row[\"signal\"]\n",
    "        resampled_data.loc[i, \"fs\"] = target_fs\n",
    "        duration_s = math.floor(len(row[\"data\"]) / row[\"fs\"])\n",
    "        target_duration_samp = duration_s * target_fs\n",
    "        Y = resample(row[\"data\"], target_duration_samp)\n",
    "        resampled_data.loc[i, \"data\"] = Y\n",
    "        resampled_data.loc[i, \"length\"] = len(Y)\n",
    "        \n",
    "    if plot:\n",
    "        colors = plt.rcParams[\"axes.prop_cycle\"]()\n",
    "        n = resampled_data.shape[0]\n",
    "        fig, axs = plt.subplots(n, sharex=False, figsize=(16, 2*n))\n",
    "        \n",
    "        for i, row in resampled_data.iterrows():\n",
    "            axs[i].plot(row[\"data\"], color=next(colors)[\"color\"], label=row[\"signal\"])\n",
    "        axs[0].title.set_text(file)\n",
    "        \n",
    "        fig.legend(loc=\"right\")\n",
    "        plt.show()\n",
    "        \n",
    "        display(resampled_data)\n",
    "        \n",
    "    return resampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "Main cell that runs all other functions, including metadata analysis, raw data reading, preprocessing and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] Dir for subject: GDN0001 \t[We have: 5 files]\n",
      "=== GDN0001_1_Resting.mat ===\n",
      "fs_bp : 200\n",
      "fs_ecg : 2000\n",
      "fs_icg : 1000\n",
      "fs_intervention : 2000\n",
      "fs_radar : 2000\n",
      "fs_z0 : 100\n",
      "radar_i : data of length 1215200\n",
      "radar_q : data of length 1215200\n",
      "tfm_bp : data of length 121520\n",
      "tfm_ecg1 : data of length 1215200\n",
      "tfm_ecg2 : data of length 1215200\n",
      "tfm_icg : data of length 607600\n",
      "tfm_intervention : data of length 1215200\n",
      "tfm_z0 : data of length 60760\n",
      "tfm_param : no data!\n",
      "tfm_param_time : no data!\n",
      "[DATA] Dir for subject: GDN0002 \t[We have: 5 files]\n",
      "=== GDN0002_1_Resting.mat ===\n",
      "fs_bp : 200\n",
      "fs_ecg : 2000\n",
      "fs_icg : 1000\n",
      "fs_intervention : 2000\n",
      "fs_radar : 2000\n",
      "fs_z0 : 100\n",
      "radar_i : data of length 1244700\n",
      "radar_q : data of length 1244700\n",
      "tfm_bp : data of length 124472\n",
      "tfm_ecg1 : data of length 1244700\n",
      "tfm_ecg2 : data of length 1244700\n",
      "tfm_icg : data of length 622352\n",
      "tfm_intervention : data of length 1244700\n",
      "tfm_z0 : data of length 62236\n",
      "tfm_param : no data!\n",
      "tfm_param_time : no data!\n",
      "[DATA] Dir for subject: GDN0003 \t[We have: 5 files]\n",
      "=== GDN0003_1_Resting.mat ===\n",
      "fs_bp : 200\n",
      "fs_ecg : 2000\n",
      "fs_icg : 1000\n",
      "fs_intervention : 2000\n",
      "fs_radar : 2000\n",
      "fs_z0 : 100\n",
      "radar_i : data of length 1202700\n",
      "radar_q : data of length 1202700\n",
      "tfm_bp : data of length 120272\n",
      "tfm_ecg1 : data of length 1202700\n",
      "tfm_ecg2 : data of length 1202700\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2e24d9402c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Read the raw data from mat files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_mat_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Filter the data using a FIR butterworth band-pass filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mfiltered_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_high\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7c08a9fe5a37>\u001b[0m in \u001b[0;36mread_mat_file\u001b[0;34m(file, plot)\u001b[0m\n\u001b[1;32m     23\u001b[0m                             \u001b[0mactual_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"signal\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                             \u001b[0mactual_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                             \u001b[0mactual_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                             \u001b[0mactual_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                             \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BASE_DATA_DIR = \"../data/\"\n",
    "NEW_DATA_DIR = \"new/\"\n",
    "cut_low = 0.1\n",
    "cut_high = 5.0\n",
    "\n",
    "for file in natsorted(os.listdir(BASE_DATA_DIR)):\n",
    "    if file.startswith(\".\"):\n",
    "        print(\"Hidden temp file:\", file, \"so skipping...\")\n",
    "        continue\n",
    "    \n",
    "    if file.endswith(\".xlsx\"):\n",
    "        print(\"[METADATA]:\", file)\n",
    "        parse_subject_metadata(os.path.join(BASE_DATA_DIR, file), summary=False, plot=False)\n",
    "        parse_scenario_metadata(os.path.join(BASE_DATA_DIR, file), summary=False, plot=False)\n",
    "        parse_ground_truth_info(os.path.join(BASE_DATA_DIR, file), summary=False)\n",
    "    else:\n",
    "        print(\"[DATA] Dir for subject:\", file, \"\\t[We have:\", len(os.listdir(os.path.join(BASE_DATA_DIR, file))), \"files]\")\n",
    "        for data_file in natsorted(os.listdir(os.path.join(BASE_DATA_DIR, file))):\n",
    "            print(\"===\", data_file, \"===\")\n",
    "            # Read the raw data from mat files\n",
    "            data_df = read_mat_file(os.path.join(BASE_DATA_DIR, file, data_file), plot=False)\n",
    "            # Filter the data using a FIR butterworth band-pass filter\n",
    "            filtered_data_df = filter_raw_data(os.path.join(BASE_DATA_DIR, file, data_file), data_df, cut_low, cut_high, order=1, plot=False)\n",
    "            # Downsample the data, since original has extremely high Fs\n",
    "            downsampled_data_df = resample_data(os.path.join(BASE_DATA_DIR, file, data_file), filtered_data_df, target_fs=100, plot=False)\n",
    "            # Save into mat file for processing there...problems with plotting\n",
    "            if not os.path.exists(os.path.join(BASE_DATA_DIR, file, NEW_DATA_DIR)):\n",
    "                os.makedirs(os.path.join(BASE_DATA_DIR, file, NEW_DATA_DIR))\n",
    "            dict_data = {col_name : data_df[col_name].values for col_name in data_df.columns.values}\n",
    "            scipy.io.savemat(os.path.join(BASE_DATA_DIR, file, NEW_DATA_DIR, data_file[0:-4]+\"_new.mat\"), {'full_data': dict_data})\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
