{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Importing Jupyter notebook from helper_functions.ipynb\n",
      "Importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import math\n",
    "import gc\n",
    "import nbimporter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import optimizers, regularizers\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "print(\"Available GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "import helper_functions as helper_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning\n",
    "Create some baseline ANNs for classification of the scenarios. Consider different inputs (contact, contact-free, both) and compare results.\n",
    "\n",
    "Initially a **fully connected multi-branch ANN** is designed, separate for contact and radar inputs. We consider a **classification problem**, where target is the scenario with **6 possible class values (Resting, Valsalva, Apnea, TiltUp, TiltDown, Other)**.\n",
    "\n",
    "Output was one-hot encoded, categorical cross-entropy used as loss, accuracy as metric. Dropout layers are added for generalization. Adam optimizer was used, and other hyperparameters are currently randomly selected based on feeling (hyperparameter optimization pending)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some (hyper)parameters needed for the training are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make some of these a dict and add hyperparam optimization\n",
    "HYPERPARAMS = {\n",
    "    \"TRAIN_AMNT\" : 0.8,\n",
    "    \"BATCH_SIZE\" : 64,\n",
    "    \"N_EPOCHS\"   : 100,\n",
    "    \"LR\"         : 0.01,\n",
    "    \"DROPOUT\"    : 0.2,\n",
    "    \"REGULAR\"    : 0.001,\n",
    "    \"VALIDATION\" : 0.3,\n",
    "    \"VERBOSE\"    : 1,\n",
    "    \"SHUFFLE\"    : True,\n",
    "    \"STANDARD\"   : True,\n",
    "    \"OVERSAMPLE\" : True\n",
    "}\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.CategoricalCrossentropy(name=\"loss\"),\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\"),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "    \n",
    "CLASS_MAP = {\n",
    "    \"Other\":    0,\n",
    "    \"Resting\":  1,\n",
    "    \"Valsalva\": 2,\n",
    "    \"Apnea\":    3,\n",
    "    \"TiltUp\":   4,\n",
    "    \"TiltDown\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run train-test experiment for contact sensors [6 classes]\n",
    "\n",
    "The cell below is the equivalent of *main* function. It clears old logs and backend, reads stacked all subject data and feeds it to the models. 70% of data is taken for training, 30% of data is considered for validation.\n",
    "\n",
    "Callbacks are added that save the model after each epoch and logs for TensorBoard (visualisation) are saved.\n",
    "\n",
    "### Attention: \n",
    "\n",
    "If you are running this on GPU, you might want to consider removing callbacks! Those take the majority of time (writing tons of things to disk)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (8443, 2000, 6) (8443,)\n",
      "Oversampling signal 0\n",
      "Oversampling signal 1\n",
      "Oversampling signal 2\n",
      "Oversampling signal 3\n",
      "Oversampling signal 4\n",
      "Oversampling signal 5\n",
      "Shapes after oversampling: (18126, 2000, 6) (18126,)\n",
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_contact_bp (InputLayer)   [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_ecg1 (InputLayer) [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_ecg2 (InputLayer) [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_icg (InputLayer)  [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_resp (InputLayer) [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_z0 (InputLayer)   [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           64032       input_contact_bp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           64032       input_contact_ecg1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           64032       input_contact_ecg2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           64032       input_contact_icg[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           64032       input_contact_resp[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           64032       input_contact_z0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           272         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 56)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1824        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 390,766\n",
      "Trainable params: 390,766\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 3s 17ms/step - loss: 1.5839 - tp: 1155.0000 - fp: 514.0000 - tn: 50236.0000 - fn: 8995.0000 - categorical_accuracy: 0.3447 - precision: 0.6920 - recall: 0.1138 - auc: 0.7168 - val_loss: 1.3421 - val_tp: 672.0000 - val_fp: 66.0000 - val_tn: 21689.0000 - val_fn: 3679.0000 - val_categorical_accuracy: 0.4560 - val_precision: 0.9106 - val_recall: 0.1544 - val_auc: 0.8081 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.3476 - tp: 1803.0000 - fp: 465.0000 - tn: 50285.0000 - fn: 8347.0000 - categorical_accuracy: 0.4354 - precision: 0.7950 - recall: 0.1776 - auc: 0.8037 - val_loss: 1.2264 - val_tp: 1085.0000 - val_fp: 172.0000 - val_tn: 21583.0000 - val_fn: 3266.0000 - val_categorical_accuracy: 0.4755 - val_precision: 0.8632 - val_recall: 0.2494 - val_auc: 0.8393 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.2378 - tp: 2556.0000 - fp: 568.0000 - tn: 50182.0000 - fn: 7594.0000 - categorical_accuracy: 0.4799 - precision: 0.8182 - recall: 0.2518 - auc: 0.8369 - val_loss: 1.1070 - val_tp: 1259.0000 - val_fp: 152.0000 - val_tn: 21603.0000 - val_fn: 3092.0000 - val_categorical_accuracy: 0.5321 - val_precision: 0.8923 - val_recall: 0.2894 - val_auc: 0.8708 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.1742 - tp: 2756.0000 - fp: 479.0000 - tn: 50271.0000 - fn: 7394.0000 - categorical_accuracy: 0.4903 - precision: 0.8519 - recall: 0.2715 - auc: 0.8505 - val_loss: 1.0900 - val_tp: 1253.0000 - val_fp: 92.0000 - val_tn: 21663.0000 - val_fn: 3098.0000 - val_categorical_accuracy: 0.5318 - val_precision: 0.9316 - val_recall: 0.2880 - val_auc: 0.8749 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 1.1529 - tp: 2886.0000 - fp: 456.0000 - tn: 50294.0000 - fn: 7264.0000 - categorical_accuracy: 0.5025 - precision: 0.8636 - recall: 0.2843 - auc: 0.8570 - val_loss: 1.1285 - val_tp: 1140.0000 - val_fp: 60.0000 - val_tn: 21695.0000 - val_fn: 3211.0000 - val_categorical_accuracy: 0.5013 - val_precision: 0.9500 - val_recall: 0.2620 - val_auc: 0.8632 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 1.1574 - tp: 2858.0000 - fp: 494.0000 - tn: 50256.0000 - fn: 7292.0000 - categorical_accuracy: 0.5023 - precision: 0.8526 - recall: 0.2816 - auc: 0.8551 - val_loss: 1.1093 - val_tp: 1203.0000 - val_fp: 105.0000 - val_tn: 21650.0000 - val_fn: 3148.0000 - val_categorical_accuracy: 0.5123 - val_precision: 0.9197 - val_recall: 0.2765 - val_auc: 0.8649 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.1232 - tp: 2944.0000 - fp: 414.0000 - tn: 50336.0000 - fn: 7206.0000 - categorical_accuracy: 0.5095 - precision: 0.8767 - recall: 0.2900 - auc: 0.8619 - val_loss: 1.0744 - val_tp: 1271.0000 - val_fp: 134.0000 - val_tn: 21621.0000 - val_fn: 3080.0000 - val_categorical_accuracy: 0.5084 - val_precision: 0.9046 - val_recall: 0.2921 - val_auc: 0.8720 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.1120 - tp: 2975.0000 - fp: 452.0000 - tn: 50298.0000 - fn: 7175.0000 - categorical_accuracy: 0.5106 - precision: 0.8681 - recall: 0.2931 - auc: 0.8654 - val_loss: 1.0711 - val_tp: 1249.0000 - val_fp: 95.0000 - val_tn: 21660.0000 - val_fn: 3102.0000 - val_categorical_accuracy: 0.5231 - val_precision: 0.9293 - val_recall: 0.2871 - val_auc: 0.8749 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.0844 - tp: 3041.0000 - fp: 435.0000 - tn: 50315.0000 - fn: 7109.0000 - categorical_accuracy: 0.5143 - precision: 0.8749 - recall: 0.2996 - auc: 0.8708 - val_loss: 1.0450 - val_tp: 1241.0000 - val_fp: 67.0000 - val_tn: 21688.0000 - val_fn: 3110.0000 - val_categorical_accuracy: 0.5282 - val_precision: 0.9488 - val_recall: 0.2852 - val_auc: 0.8806 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 1.0796 - tp: 3012.0000 - fp: 377.0000 - tn: 50373.0000 - fn: 7138.0000 - categorical_accuracy: 0.5176 - precision: 0.8888 - recall: 0.2967 - auc: 0.8725 - val_loss: 1.0533 - val_tp: 1268.0000 - val_fp: 82.0000 - val_tn: 21673.0000 - val_fn: 3083.0000 - val_categorical_accuracy: 0.5378 - val_precision: 0.9393 - val_recall: 0.2914 - val_auc: 0.8804 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.0554 - tp: 3084.0000 - fp: 316.0000 - tn: 50434.0000 - fn: 7066.0000 - categorical_accuracy: 0.5297 - precision: 0.9071 - recall: 0.3038 - auc: 0.8780 - val_loss: 1.0345 - val_tp: 1343.0000 - val_fp: 112.0000 - val_tn: 21643.0000 - val_fn: 3008.0000 - val_categorical_accuracy: 0.5249 - val_precision: 0.9230 - val_recall: 0.3087 - val_auc: 0.8826 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 1.0728 - tp: 3130.0000 - fp: 413.0000 - tn: 50337.0000 - fn: 7020.0000 - categorical_accuracy: 0.5272 - precision: 0.8834 - recall: 0.3084 - auc: 0.8739 - val_loss: 1.0448 - val_tp: 1351.0000 - val_fp: 166.0000 - val_tn: 21589.0000 - val_fn: 3000.0000 - val_categorical_accuracy: 0.5300 - val_precision: 0.8906 - val_recall: 0.3105 - val_auc: 0.8811 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 1.0478 - tp: 3228.0000 - fp: 430.0000 - tn: 50320.0000 - fn: 6922.0000 - categorical_accuracy: 0.5393 - precision: 0.8824 - recall: 0.3180 - auc: 0.8805 - val_loss: 1.0444 - val_tp: 1335.0000 - val_fp: 102.0000 - val_tn: 21653.0000 - val_fn: 3016.0000 - val_categorical_accuracy: 0.5288 - val_precision: 0.9290 - val_recall: 0.3068 - val_auc: 0.8809 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.0346 - tp: 3216.0000 - fp: 396.0000 - tn: 50354.0000 - fn: 6934.0000 - categorical_accuracy: 0.5394 - precision: 0.8904 - recall: 0.3168 - auc: 0.8840 - val_loss: 1.0166 - val_tp: 1255.0000 - val_fp: 85.0000 - val_tn: 21670.0000 - val_fn: 3096.0000 - val_categorical_accuracy: 0.5410 - val_precision: 0.9366 - val_recall: 0.2884 - val_auc: 0.8875 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 1.0157 - tp: 3281.0000 - fp: 425.0000 - tn: 50325.0000 - fn: 6869.0000 - categorical_accuracy: 0.5468 - precision: 0.8853 - recall: 0.3233 - auc: 0.8872 - val_loss: 1.0435 - val_tp: 1230.0000 - val_fp: 59.0000 - val_tn: 21696.0000 - val_fn: 3121.0000 - val_categorical_accuracy: 0.5484 - val_precision: 0.9542 - val_recall: 0.2827 - val_auc: 0.8848 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.0190 - tp: 3308.0000 - fp: 465.0000 - tn: 50285.0000 - fn: 6842.0000 - categorical_accuracy: 0.5551 - precision: 0.8768 - recall: 0.3259 - auc: 0.8877 - val_loss: 1.0060 - val_tp: 1349.0000 - val_fp: 116.0000 - val_tn: 21639.0000 - val_fn: 3002.0000 - val_categorical_accuracy: 0.5560 - val_precision: 0.9208 - val_recall: 0.3100 - val_auc: 0.8907 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.0136 - tp: 3300.0000 - fp: 455.0000 - tn: 50295.0000 - fn: 6850.0000 - categorical_accuracy: 0.5544 - precision: 0.8788 - recall: 0.3251 - auc: 0.8890 - val_loss: 0.9951 - val_tp: 1350.0000 - val_fp: 120.0000 - val_tn: 21635.0000 - val_fn: 3001.0000 - val_categorical_accuracy: 0.5525 - val_precision: 0.9184 - val_recall: 0.3103 - val_auc: 0.8913 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.0058 - tp: 3337.0000 - fp: 464.0000 - tn: 50286.0000 - fn: 6813.0000 - categorical_accuracy: 0.5582 - precision: 0.8779 - recall: 0.3288 - auc: 0.8909 - val_loss: 0.9854 - val_tp: 1342.0000 - val_fp: 110.0000 - val_tn: 21645.0000 - val_fn: 3009.0000 - val_categorical_accuracy: 0.5649 - val_precision: 0.9242 - val_recall: 0.3084 - val_auc: 0.8939 - lr: 0.0091\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9929 - tp: 3343.0000 - fp: 477.0000 - tn: 50273.0000 - fn: 6807.0000 - categorical_accuracy: 0.5568 - precision: 0.8751 - recall: 0.3294 - auc: 0.8928 - val_loss: 0.9890 - val_tp: 1369.0000 - val_fp: 120.0000 - val_tn: 21635.0000 - val_fn: 2982.0000 - val_categorical_accuracy: 0.5626 - val_precision: 0.9194 - val_recall: 0.3146 - val_auc: 0.8936 - lr: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 1.0043 - tp: 3301.0000 - fp: 471.0000 - tn: 50279.0000 - fn: 6849.0000 - categorical_accuracy: 0.5569 - precision: 0.8751 - recall: 0.3252 - auc: 0.8904 - val_loss: 0.9606 - val_tp: 1392.0000 - val_fp: 104.0000 - val_tn: 21651.0000 - val_fn: 2959.0000 - val_categorical_accuracy: 0.5665 - val_precision: 0.9305 - val_recall: 0.3199 - val_auc: 0.8992 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 1.0012 - tp: 3322.0000 - fp: 451.0000 - tn: 50299.0000 - fn: 6828.0000 - categorical_accuracy: 0.5569 - precision: 0.8805 - recall: 0.3273 - auc: 0.8914 - val_loss: 0.9757 - val_tp: 1420.0000 - val_fp: 122.0000 - val_tn: 21633.0000 - val_fn: 2931.0000 - val_categorical_accuracy: 0.5642 - val_precision: 0.9209 - val_recall: 0.3264 - val_auc: 0.8958 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.9787 - tp: 3541.0000 - fp: 498.0000 - tn: 50252.0000 - fn: 6609.0000 - categorical_accuracy: 0.5650 - precision: 0.8767 - recall: 0.3489 - auc: 0.8964 - val_loss: 0.9581 - val_tp: 1458.0000 - val_fp: 159.0000 - val_tn: 21596.0000 - val_fn: 2893.0000 - val_categorical_accuracy: 0.5615 - val_precision: 0.9017 - val_recall: 0.3351 - val_auc: 0.8984 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.9647 - tp: 3558.0000 - fp: 540.0000 - tn: 50210.0000 - fn: 6592.0000 - categorical_accuracy: 0.5690 - precision: 0.8682 - recall: 0.3505 - auc: 0.8987 - val_loss: 0.9494 - val_tp: 1417.0000 - val_fp: 137.0000 - val_tn: 21618.0000 - val_fn: 2934.0000 - val_categorical_accuracy: 0.5753 - val_precision: 0.9118 - val_recall: 0.3257 - val_auc: 0.9015 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9774 - tp: 3498.0000 - fp: 505.0000 - tn: 50245.0000 - fn: 6652.0000 - categorical_accuracy: 0.5668 - precision: 0.8738 - recall: 0.3446 - auc: 0.8972 - val_loss: 0.9583 - val_tp: 1514.0000 - val_fp: 274.0000 - val_tn: 21481.0000 - val_fn: 2837.0000 - val_categorical_accuracy: 0.5704 - val_precision: 0.8468 - val_recall: 0.3480 - val_auc: 0.8989 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.9661 - tp: 3637.0000 - fp: 583.0000 - tn: 50167.0000 - fn: 6513.0000 - categorical_accuracy: 0.5787 - precision: 0.8618 - recall: 0.3583 - auc: 0.8998 - val_loss: 0.9322 - val_tp: 1476.0000 - val_fp: 161.0000 - val_tn: 21594.0000 - val_fn: 2875.0000 - val_categorical_accuracy: 0.5852 - val_precision: 0.9016 - val_recall: 0.3392 - val_auc: 0.9054 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9557 - tp: 3705.0000 - fp: 694.0000 - tn: 50056.0000 - fn: 6445.0000 - categorical_accuracy: 0.5830 - precision: 0.8422 - recall: 0.3650 - auc: 0.9022 - val_loss: 0.9555 - val_tp: 1447.0000 - val_fp: 130.0000 - val_tn: 21625.0000 - val_fn: 2904.0000 - val_categorical_accuracy: 0.5888 - val_precision: 0.9176 - val_recall: 0.3326 - val_auc: 0.9012 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.9392 - tp: 3668.0000 - fp: 606.0000 - tn: 50144.0000 - fn: 6482.0000 - categorical_accuracy: 0.5859 - precision: 0.8582 - recall: 0.3614 - auc: 0.9047 - val_loss: 0.9300 - val_tp: 1509.0000 - val_fp: 195.0000 - val_tn: 21560.0000 - val_fn: 2842.0000 - val_categorical_accuracy: 0.5858 - val_precision: 0.8856 - val_recall: 0.3468 - val_auc: 0.9060 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.9181 - tp: 3826.0000 - fp: 639.0000 - tn: 50111.0000 - fn: 6324.0000 - categorical_accuracy: 0.6048 - precision: 0.8569 - recall: 0.3769 - auc: 0.9099 - val_loss: 0.9143 - val_tp: 1607.0000 - val_fp: 248.0000 - val_tn: 21507.0000 - val_fn: 2744.0000 - val_categorical_accuracy: 0.5893 - val_precision: 0.8663 - val_recall: 0.3693 - val_auc: 0.9084 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9400 - tp: 3812.0000 - fp: 709.0000 - tn: 50041.0000 - fn: 6338.0000 - categorical_accuracy: 0.5977 - precision: 0.8432 - recall: 0.3756 - auc: 0.9061 - val_loss: 0.9661 - val_tp: 1607.0000 - val_fp: 284.0000 - val_tn: 21471.0000 - val_fn: 2744.0000 - val_categorical_accuracy: 0.5861 - val_precision: 0.8498 - val_recall: 0.3693 - val_auc: 0.9002 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9408 - tp: 3833.0000 - fp: 680.0000 - tn: 50070.0000 - fn: 6317.0000 - categorical_accuracy: 0.5988 - precision: 0.8493 - recall: 0.3776 - auc: 0.9067 - val_loss: 0.9220 - val_tp: 1540.0000 - val_fp: 205.0000 - val_tn: 21550.0000 - val_fn: 2811.0000 - val_categorical_accuracy: 0.5955 - val_precision: 0.8825 - val_recall: 0.3539 - val_auc: 0.9073 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9432 - tp: 3868.0000 - fp: 698.0000 - tn: 50052.0000 - fn: 6282.0000 - categorical_accuracy: 0.5972 - precision: 0.8471 - recall: 0.3811 - auc: 0.9059 - val_loss: 0.9489 - val_tp: 1481.0000 - val_fp: 217.0000 - val_tn: 21538.0000 - val_fn: 2870.0000 - val_categorical_accuracy: 0.5861 - val_precision: 0.8722 - val_recall: 0.3404 - val_auc: 0.9038 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9521 - tp: 3776.0000 - fp: 685.0000 - tn: 50065.0000 - fn: 6374.0000 - categorical_accuracy: 0.5853 - precision: 0.8464 - recall: 0.3720 - auc: 0.9033 - val_loss: 0.9395 - val_tp: 1503.0000 - val_fp: 184.0000 - val_tn: 21571.0000 - val_fn: 2848.0000 - val_categorical_accuracy: 0.5966 - val_precision: 0.8909 - val_recall: 0.3454 - val_auc: 0.9056 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9315 - tp: 3953.0000 - fp: 771.0000 - tn: 49979.0000 - fn: 6197.0000 - categorical_accuracy: 0.6053 - precision: 0.8368 - recall: 0.3895 - auc: 0.9086 - val_loss: 0.9354 - val_tp: 1557.0000 - val_fp: 227.0000 - val_tn: 21528.0000 - val_fn: 2794.0000 - val_categorical_accuracy: 0.6001 - val_precision: 0.8728 - val_recall: 0.3578 - val_auc: 0.9069 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9286 - tp: 4070.0000 - fp: 837.0000 - tn: 49913.0000 - fn: 6080.0000 - categorical_accuracy: 0.6091 - precision: 0.8294 - recall: 0.4010 - auc: 0.9095 - val_loss: 0.9162 - val_tp: 1621.0000 - val_fp: 252.0000 - val_tn: 21503.0000 - val_fn: 2730.0000 - val_categorical_accuracy: 0.6033 - val_precision: 0.8655 - val_recall: 0.3726 - val_auc: 0.9101 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.9158 - tp: 4111.0000 - fp: 817.0000 - tn: 49933.0000 - fn: 6039.0000 - categorical_accuracy: 0.6143 - precision: 0.8342 - recall: 0.4050 - auc: 0.9118 - val_loss: 0.9350 - val_tp: 1577.0000 - val_fp: 295.0000 - val_tn: 21460.0000 - val_fn: 2774.0000 - val_categorical_accuracy: 0.6065 - val_precision: 0.8424 - val_recall: 0.3624 - val_auc: 0.9070 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.9040 - tp: 4128.0000 - fp: 888.0000 - tn: 49862.0000 - fn: 6022.0000 - categorical_accuracy: 0.6162 - precision: 0.8230 - recall: 0.4067 - auc: 0.9135 - val_loss: 0.9062 - val_tp: 1636.0000 - val_fp: 293.0000 - val_tn: 21462.0000 - val_fn: 2715.0000 - val_categorical_accuracy: 0.6056 - val_precision: 0.8481 - val_recall: 0.3760 - val_auc: 0.9111 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.8749 - tp: 4321.0000 - fp: 884.0000 - tn: 49866.0000 - fn: 5829.0000 - categorical_accuracy: 0.6294 - precision: 0.8302 - recall: 0.4257 - auc: 0.9194 - val_loss: 0.9044 - val_tp: 1668.0000 - val_fp: 315.0000 - val_tn: 21440.0000 - val_fn: 2683.0000 - val_categorical_accuracy: 0.6150 - val_precision: 0.8411 - val_recall: 0.3834 - val_auc: 0.9129 - lr: 0.0055\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.8762 - tp: 4411.0000 - fp: 862.0000 - tn: 49888.0000 - fn: 5739.0000 - categorical_accuracy: 0.6291 - precision: 0.8365 - recall: 0.4346 - auc: 0.9196 - val_loss: 0.9126 - val_tp: 1709.0000 - val_fp: 320.0000 - val_tn: 21435.0000 - val_fn: 2642.0000 - val_categorical_accuracy: 0.6015 - val_precision: 0.8423 - val_recall: 0.3928 - val_auc: 0.9107 - lr: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.8521 - tp: 4570.0000 - fp: 976.0000 - tn: 49774.0000 - fn: 5580.0000 - categorical_accuracy: 0.6413 - precision: 0.8240 - recall: 0.4502 - auc: 0.9239 - val_loss: 0.9068 - val_tp: 1736.0000 - val_fp: 375.0000 - val_tn: 21380.0000 - val_fn: 2615.0000 - val_categorical_accuracy: 0.6088 - val_precision: 0.8224 - val_recall: 0.3990 - val_auc: 0.9121 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.8383 - tp: 4700.0000 - fp: 988.0000 - tn: 49762.0000 - fn: 5450.0000 - categorical_accuracy: 0.6507 - precision: 0.8263 - recall: 0.4631 - auc: 0.9271 - val_loss: 0.9030 - val_tp: 1898.0000 - val_fp: 498.0000 - val_tn: 21257.0000 - val_fn: 2453.0000 - val_categorical_accuracy: 0.6028 - val_precision: 0.7922 - val_recall: 0.4362 - val_auc: 0.9128 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.8420 - tp: 4564.0000 - fp: 956.0000 - tn: 49794.0000 - fn: 5586.0000 - categorical_accuracy: 0.6447 - precision: 0.8268 - recall: 0.4497 - auc: 0.9255 - val_loss: 0.8988 - val_tp: 1753.0000 - val_fp: 358.0000 - val_tn: 21397.0000 - val_fn: 2598.0000 - val_categorical_accuracy: 0.6148 - val_precision: 0.8304 - val_recall: 0.4029 - val_auc: 0.9136 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.8331 - tp: 4755.0000 - fp: 997.0000 - tn: 49753.0000 - fn: 5395.0000 - categorical_accuracy: 0.6494 - precision: 0.8267 - recall: 0.4685 - auc: 0.9275 - val_loss: 0.8739 - val_tp: 1846.0000 - val_fp: 394.0000 - val_tn: 21361.0000 - val_fn: 2505.0000 - val_categorical_accuracy: 0.6251 - val_precision: 0.8241 - val_recall: 0.4243 - val_auc: 0.9182 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.8199 - tp: 4860.0000 - fp: 1057.0000 - tn: 49693.0000 - fn: 5290.0000 - categorical_accuracy: 0.6545 - precision: 0.8214 - recall: 0.4788 - auc: 0.9295 - val_loss: 0.8754 - val_tp: 1942.0000 - val_fp: 513.0000 - val_tn: 21242.0000 - val_fn: 2409.0000 - val_categorical_accuracy: 0.6256 - val_precision: 0.7910 - val_recall: 0.4463 - val_auc: 0.9180 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.8022 - tp: 5045.0000 - fp: 1122.0000 - tn: 49628.0000 - fn: 5105.0000 - categorical_accuracy: 0.6668 - precision: 0.8181 - recall: 0.4970 - auc: 0.9331 - val_loss: 0.8511 - val_tp: 1848.0000 - val_fp: 387.0000 - val_tn: 21368.0000 - val_fn: 2503.0000 - val_categorical_accuracy: 0.6380 - val_precision: 0.8268 - val_recall: 0.4247 - val_auc: 0.9228 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.8087 - tp: 5007.0000 - fp: 1122.0000 - tn: 49628.0000 - fn: 5143.0000 - categorical_accuracy: 0.6617 - precision: 0.8169 - recall: 0.4933 - auc: 0.9319 - val_loss: 0.8614 - val_tp: 1822.0000 - val_fp: 353.0000 - val_tn: 21402.0000 - val_fn: 2529.0000 - val_categorical_accuracy: 0.6265 - val_precision: 0.8377 - val_recall: 0.4188 - val_auc: 0.9205 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.7862 - tp: 5164.0000 - fp: 1144.0000 - tn: 49606.0000 - fn: 4986.0000 - categorical_accuracy: 0.6707 - precision: 0.8186 - recall: 0.5088 - auc: 0.9355 - val_loss: 0.8555 - val_tp: 2029.0000 - val_fp: 562.0000 - val_tn: 21193.0000 - val_fn: 2322.0000 - val_categorical_accuracy: 0.6222 - val_precision: 0.7831 - val_recall: 0.4663 - val_auc: 0.9213 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.7724 - tp: 5358.0000 - fp: 1274.0000 - tn: 49476.0000 - fn: 4792.0000 - categorical_accuracy: 0.6789 - precision: 0.8079 - recall: 0.5279 - auc: 0.9380 - val_loss: 0.8681 - val_tp: 2041.0000 - val_fp: 577.0000 - val_tn: 21178.0000 - val_fn: 2310.0000 - val_categorical_accuracy: 0.6355 - val_precision: 0.7796 - val_recall: 0.4691 - val_auc: 0.9207 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.7740 - tp: 5331.0000 - fp: 1218.0000 - tn: 49532.0000 - fn: 4819.0000 - categorical_accuracy: 0.6802 - precision: 0.8140 - recall: 0.5252 - auc: 0.9378 - val_loss: 0.8559 - val_tp: 2084.0000 - val_fp: 579.0000 - val_tn: 21176.0000 - val_fn: 2267.0000 - val_categorical_accuracy: 0.6376 - val_precision: 0.7826 - val_recall: 0.4790 - val_auc: 0.9219 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.7547 - tp: 5491.0000 - fp: 1286.0000 - tn: 49464.0000 - fn: 4659.0000 - categorical_accuracy: 0.6891 - precision: 0.8102 - recall: 0.5410 - auc: 0.9409 - val_loss: 0.8640 - val_tp: 2114.0000 - val_fp: 686.0000 - val_tn: 21069.0000 - val_fn: 2237.0000 - val_categorical_accuracy: 0.6350 - val_precision: 0.7550 - val_recall: 0.4859 - val_auc: 0.9208 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.7396 - tp: 5718.0000 - fp: 1430.0000 - tn: 49320.0000 - fn: 4432.0000 - categorical_accuracy: 0.6987 - precision: 0.7999 - recall: 0.5633 - auc: 0.9432 - val_loss: 0.8658 - val_tp: 2276.0000 - val_fp: 843.0000 - val_tn: 20912.0000 - val_fn: 2075.0000 - val_categorical_accuracy: 0.6247 - val_precision: 0.7297 - val_recall: 0.5231 - val_auc: 0.9202 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.7301 - tp: 5742.0000 - fp: 1407.0000 - tn: 49343.0000 - fn: 4408.0000 - categorical_accuracy: 0.6971 - precision: 0.8032 - recall: 0.5657 - auc: 0.9445 - val_loss: 0.8563 - val_tp: 2269.0000 - val_fp: 789.0000 - val_tn: 20966.0000 - val_fn: 2082.0000 - val_categorical_accuracy: 0.6373 - val_precision: 0.7420 - val_recall: 0.5215 - val_auc: 0.9227 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.7305 - tp: 5793.0000 - fp: 1389.0000 - tn: 49361.0000 - fn: 4357.0000 - categorical_accuracy: 0.7004 - precision: 0.8066 - recall: 0.5707 - auc: 0.9448 - val_loss: 0.8476 - val_tp: 2314.0000 - val_fp: 809.0000 - val_tn: 20946.0000 - val_fn: 2037.0000 - val_categorical_accuracy: 0.6422 - val_precision: 0.7410 - val_recall: 0.5318 - val_auc: 0.9243 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.7028 - tp: 6066.0000 - fp: 1461.0000 - tn: 49289.0000 - fn: 4084.0000 - categorical_accuracy: 0.7089 - precision: 0.8059 - recall: 0.5976 - auc: 0.9488 - val_loss: 0.8564 - val_tp: 2274.0000 - val_fp: 810.0000 - val_tn: 20945.0000 - val_fn: 2077.0000 - val_categorical_accuracy: 0.6396 - val_precision: 0.7374 - val_recall: 0.5226 - val_auc: 0.9235 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.7047 - tp: 6080.0000 - fp: 1477.0000 - tn: 49273.0000 - fn: 4070.0000 - categorical_accuracy: 0.7110 - precision: 0.8046 - recall: 0.5990 - auc: 0.9486 - val_loss: 0.8336 - val_tp: 2304.0000 - val_fp: 725.0000 - val_tn: 21030.0000 - val_fn: 2047.0000 - val_categorical_accuracy: 0.6550 - val_precision: 0.7606 - val_recall: 0.5295 - val_auc: 0.9272 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.6866 - tp: 6252.0000 - fp: 1476.0000 - tn: 49274.0000 - fn: 3898.0000 - categorical_accuracy: 0.7210 - precision: 0.8090 - recall: 0.6160 - auc: 0.9514 - val_loss: 0.8539 - val_tp: 2371.0000 - val_fp: 862.0000 - val_tn: 20893.0000 - val_fn: 1980.0000 - val_categorical_accuracy: 0.6513 - val_precision: 0.7334 - val_recall: 0.5449 - val_auc: 0.9246 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.6737 - tp: 6337.0000 - fp: 1519.0000 - tn: 49231.0000 - fn: 3813.0000 - categorical_accuracy: 0.7274 - precision: 0.8066 - recall: 0.6243 - auc: 0.9533 - val_loss: 0.8641 - val_tp: 2330.0000 - val_fp: 832.0000 - val_tn: 20923.0000 - val_fn: 2021.0000 - val_categorical_accuracy: 0.6399 - val_precision: 0.7369 - val_recall: 0.5355 - val_auc: 0.9231 - lr: 0.0023\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.6660 - tp: 6440.0000 - fp: 1495.0000 - tn: 49255.0000 - fn: 3710.0000 - categorical_accuracy: 0.7324 - precision: 0.8116 - recall: 0.6345 - auc: 0.9542 - val_loss: 0.8682 - val_tp: 2343.0000 - val_fp: 861.0000 - val_tn: 20894.0000 - val_fn: 2008.0000 - val_categorical_accuracy: 0.6500 - val_precision: 0.7313 - val_recall: 0.5385 - val_auc: 0.9232 - lr: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.6650 - tp: 6588.0000 - fp: 1615.0000 - tn: 49135.0000 - fn: 3562.0000 - categorical_accuracy: 0.7356 - precision: 0.8031 - recall: 0.6491 - auc: 0.9546 - val_loss: 0.8578 - val_tp: 2456.0000 - val_fp: 959.0000 - val_tn: 20796.0000 - val_fn: 1895.0000 - val_categorical_accuracy: 0.6493 - val_precision: 0.7192 - val_recall: 0.5645 - val_auc: 0.9251 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.6518 - tp: 6569.0000 - fp: 1646.0000 - tn: 49104.0000 - fn: 3581.0000 - categorical_accuracy: 0.7337 - precision: 0.7996 - recall: 0.6472 - auc: 0.9561 - val_loss: 0.8550 - val_tp: 2430.0000 - val_fp: 926.0000 - val_tn: 20829.0000 - val_fn: 1921.0000 - val_categorical_accuracy: 0.6479 - val_precision: 0.7241 - val_recall: 0.5585 - val_auc: 0.9250 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.6367 - tp: 6689.0000 - fp: 1537.0000 - tn: 49213.0000 - fn: 3461.0000 - categorical_accuracy: 0.7432 - precision: 0.8132 - recall: 0.6590 - auc: 0.9583 - val_loss: 0.8656 - val_tp: 2443.0000 - val_fp: 981.0000 - val_tn: 20774.0000 - val_fn: 1908.0000 - val_categorical_accuracy: 0.6438 - val_precision: 0.7135 - val_recall: 0.5615 - val_auc: 0.9235 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.6397 - tp: 6734.0000 - fp: 1574.0000 - tn: 49176.0000 - fn: 3416.0000 - categorical_accuracy: 0.7447 - precision: 0.8105 - recall: 0.6634 - auc: 0.9577 - val_loss: 0.8799 - val_tp: 2420.0000 - val_fp: 1018.0000 - val_tn: 20737.0000 - val_fn: 1931.0000 - val_categorical_accuracy: 0.6359 - val_precision: 0.7039 - val_recall: 0.5562 - val_auc: 0.9213 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.6250 - tp: 6801.0000 - fp: 1598.0000 - tn: 49152.0000 - fn: 3349.0000 - categorical_accuracy: 0.7464 - precision: 0.8097 - recall: 0.6700 - auc: 0.9597 - val_loss: 0.8785 - val_tp: 2479.0000 - val_fp: 994.0000 - val_tn: 20761.0000 - val_fn: 1872.0000 - val_categorical_accuracy: 0.6507 - val_precision: 0.7138 - val_recall: 0.5698 - val_auc: 0.9232 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.6153 - tp: 6855.0000 - fp: 1582.0000 - tn: 49168.0000 - fn: 3295.0000 - categorical_accuracy: 0.7503 - precision: 0.8125 - recall: 0.6754 - auc: 0.9608 - val_loss: 0.8781 - val_tp: 2459.0000 - val_fp: 1009.0000 - val_tn: 20746.0000 - val_fn: 1892.0000 - val_categorical_accuracy: 0.6449 - val_precision: 0.7091 - val_recall: 0.5652 - val_auc: 0.9227 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.6084 - tp: 6927.0000 - fp: 1556.0000 - tn: 49194.0000 - fn: 3223.0000 - categorical_accuracy: 0.7588 - precision: 0.8166 - recall: 0.6825 - auc: 0.9618 - val_loss: 0.8733 - val_tp: 2435.0000 - val_fp: 1021.0000 - val_tn: 20734.0000 - val_fn: 1916.0000 - val_categorical_accuracy: 0.6422 - val_precision: 0.7046 - val_recall: 0.5596 - val_auc: 0.9236 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5964 - tp: 7078.0000 - fp: 1536.0000 - tn: 49214.0000 - fn: 3072.0000 - categorical_accuracy: 0.7628 - precision: 0.8217 - recall: 0.6973 - auc: 0.9633 - val_loss: 0.8795 - val_tp: 2499.0000 - val_fp: 1025.0000 - val_tn: 20730.0000 - val_fn: 1852.0000 - val_categorical_accuracy: 0.6456 - val_precision: 0.7091 - val_recall: 0.5744 - val_auc: 0.9235 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5944 - tp: 7100.0000 - fp: 1589.0000 - tn: 49161.0000 - fn: 3050.0000 - categorical_accuracy: 0.7634 - precision: 0.8171 - recall: 0.6995 - auc: 0.9635 - val_loss: 0.8929 - val_tp: 2497.0000 - val_fp: 1061.0000 - val_tn: 20694.0000 - val_fn: 1854.0000 - val_categorical_accuracy: 0.6477 - val_precision: 0.7018 - val_recall: 0.5739 - val_auc: 0.9220 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5780 - tp: 7137.0000 - fp: 1551.0000 - tn: 49199.0000 - fn: 3013.0000 - categorical_accuracy: 0.7665 - precision: 0.8215 - recall: 0.7032 - auc: 0.9656 - val_loss: 0.8812 - val_tp: 2484.0000 - val_fp: 1077.0000 - val_tn: 20678.0000 - val_fn: 1867.0000 - val_categorical_accuracy: 0.6472 - val_precision: 0.6976 - val_recall: 0.5709 - val_auc: 0.9237 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5736 - tp: 7301.0000 - fp: 1555.0000 - tn: 49195.0000 - fn: 2849.0000 - categorical_accuracy: 0.7769 - precision: 0.8244 - recall: 0.7193 - auc: 0.9660 - val_loss: 0.8843 - val_tp: 2554.0000 - val_fp: 1085.0000 - val_tn: 20670.0000 - val_fn: 1797.0000 - val_categorical_accuracy: 0.6493 - val_precision: 0.7018 - val_recall: 0.5870 - val_auc: 0.9245 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.5700 - tp: 7306.0000 - fp: 1558.0000 - tn: 49192.0000 - fn: 2844.0000 - categorical_accuracy: 0.7756 - precision: 0.8242 - recall: 0.7198 - auc: 0.9666 - val_loss: 0.8931 - val_tp: 2569.0000 - val_fp: 1088.0000 - val_tn: 20667.0000 - val_fn: 1782.0000 - val_categorical_accuracy: 0.6518 - val_precision: 0.7025 - val_recall: 0.5904 - val_auc: 0.9233 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5731 - tp: 7288.0000 - fp: 1592.0000 - tn: 49158.0000 - fn: 2862.0000 - categorical_accuracy: 0.7719 - precision: 0.8207 - recall: 0.7180 - auc: 0.9662 - val_loss: 0.8856 - val_tp: 2571.0000 - val_fp: 1103.0000 - val_tn: 20652.0000 - val_fn: 1780.0000 - val_categorical_accuracy: 0.6559 - val_precision: 0.6998 - val_recall: 0.5909 - val_auc: 0.9242 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5483 - tp: 7367.0000 - fp: 1510.0000 - tn: 49240.0000 - fn: 2783.0000 - categorical_accuracy: 0.7826 - precision: 0.8299 - recall: 0.7258 - auc: 0.9689 - val_loss: 0.8976 - val_tp: 2588.0000 - val_fp: 1130.0000 - val_tn: 20625.0000 - val_fn: 1763.0000 - val_categorical_accuracy: 0.6477 - val_precision: 0.6961 - val_recall: 0.5948 - val_auc: 0.9236 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.5566 - tp: 7421.0000 - fp: 1532.0000 - tn: 49218.0000 - fn: 2729.0000 - categorical_accuracy: 0.7831 - precision: 0.8289 - recall: 0.7311 - auc: 0.9680 - val_loss: 0.8973 - val_tp: 2584.0000 - val_fp: 1091.0000 - val_tn: 20664.0000 - val_fn: 1767.0000 - val_categorical_accuracy: 0.6566 - val_precision: 0.7031 - val_recall: 0.5939 - val_auc: 0.9239 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5551 - tp: 7422.0000 - fp: 1580.0000 - tn: 49170.0000 - fn: 2728.0000 - categorical_accuracy: 0.7827 - precision: 0.8245 - recall: 0.7312 - auc: 0.9680 - val_loss: 0.8955 - val_tp: 2593.0000 - val_fp: 1101.0000 - val_tn: 20654.0000 - val_fn: 1758.0000 - val_categorical_accuracy: 0.6564 - val_precision: 0.7019 - val_recall: 0.5960 - val_auc: 0.9240 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5343 - tp: 7531.0000 - fp: 1526.0000 - tn: 49224.0000 - fn: 2619.0000 - categorical_accuracy: 0.7905 - precision: 0.8315 - recall: 0.7420 - auc: 0.9705 - val_loss: 0.9109 - val_tp: 2585.0000 - val_fp: 1141.0000 - val_tn: 20614.0000 - val_fn: 1766.0000 - val_categorical_accuracy: 0.6516 - val_precision: 0.6938 - val_recall: 0.5941 - val_auc: 0.9231 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5355 - tp: 7528.0000 - fp: 1502.0000 - tn: 49248.0000 - fn: 2622.0000 - categorical_accuracy: 0.7925 - precision: 0.8337 - recall: 0.7417 - auc: 0.9705 - val_loss: 0.9009 - val_tp: 2633.0000 - val_fp: 1177.0000 - val_tn: 20578.0000 - val_fn: 1718.0000 - val_categorical_accuracy: 0.6500 - val_precision: 0.6911 - val_recall: 0.6051 - val_auc: 0.9240 - lr: 7.0388e-04\n",
      "Epoch 76/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5387 - tp: 7509.0000 - fp: 1553.0000 - tn: 49197.0000 - fn: 2641.0000 - categorical_accuracy: 0.7905 - precision: 0.8286 - recall: 0.7398 - auc: 0.9700 - val_loss: 0.9022 - val_tp: 2646.0000 - val_fp: 1162.0000 - val_tn: 20593.0000 - val_fn: 1705.0000 - val_categorical_accuracy: 0.6507 - val_precision: 0.6949 - val_recall: 0.6081 - val_auc: 0.9245 - lr: 6.5477e-04\n",
      "Epoch 77/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5246 - tp: 7628.0000 - fp: 1516.0000 - tn: 49234.0000 - fn: 2522.0000 - categorical_accuracy: 0.7978 - precision: 0.8342 - recall: 0.7515 - auc: 0.9715 - val_loss: 0.8895 - val_tp: 2620.0000 - val_fp: 1127.0000 - val_tn: 20628.0000 - val_fn: 1731.0000 - val_categorical_accuracy: 0.6582 - val_precision: 0.6992 - val_recall: 0.6022 - val_auc: 0.9259 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5149 - tp: 7651.0000 - fp: 1453.0000 - tn: 49297.0000 - fn: 2499.0000 - categorical_accuracy: 0.8043 - precision: 0.8404 - recall: 0.7538 - auc: 0.9727 - val_loss: 0.8956 - val_tp: 2649.0000 - val_fp: 1129.0000 - val_tn: 20626.0000 - val_fn: 1702.0000 - val_categorical_accuracy: 0.6587 - val_precision: 0.7012 - val_recall: 0.6088 - val_auc: 0.9256 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5092 - tp: 7779.0000 - fp: 1436.0000 - tn: 49314.0000 - fn: 2371.0000 - categorical_accuracy: 0.8089 - precision: 0.8442 - recall: 0.7664 - auc: 0.9731 - val_loss: 0.9126 - val_tp: 2650.0000 - val_fp: 1169.0000 - val_tn: 20586.0000 - val_fn: 1701.0000 - val_categorical_accuracy: 0.6553 - val_precision: 0.6939 - val_recall: 0.6091 - val_auc: 0.9241 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5151 - tp: 7672.0000 - fp: 1496.0000 - tn: 49254.0000 - fn: 2478.0000 - categorical_accuracy: 0.7995 - precision: 0.8368 - recall: 0.7559 - auc: 0.9726 - val_loss: 0.9109 - val_tp: 2652.0000 - val_fp: 1180.0000 - val_tn: 20575.0000 - val_fn: 1699.0000 - val_categorical_accuracy: 0.6550 - val_precision: 0.6921 - val_recall: 0.6095 - val_auc: 0.9246 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5102 - tp: 7727.0000 - fp: 1495.0000 - tn: 49255.0000 - fn: 2423.0000 - categorical_accuracy: 0.8039 - precision: 0.8379 - recall: 0.7613 - auc: 0.9731 - val_loss: 0.9128 - val_tp: 2631.0000 - val_fp: 1177.0000 - val_tn: 20578.0000 - val_fn: 1720.0000 - val_categorical_accuracy: 0.6557 - val_precision: 0.6909 - val_recall: 0.6047 - val_auc: 0.9243 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5018 - tp: 7795.0000 - fp: 1467.0000 - tn: 49283.0000 - fn: 2355.0000 - categorical_accuracy: 0.8090 - precision: 0.8416 - recall: 0.7680 - auc: 0.9738 - val_loss: 0.9108 - val_tp: 2626.0000 - val_fp: 1170.0000 - val_tn: 20585.0000 - val_fn: 1725.0000 - val_categorical_accuracy: 0.6571 - val_precision: 0.6918 - val_recall: 0.6035 - val_auc: 0.9250 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5066 - tp: 7781.0000 - fp: 1491.0000 - tn: 49259.0000 - fn: 2369.0000 - categorical_accuracy: 0.8073 - precision: 0.8392 - recall: 0.7666 - auc: 0.9735 - val_loss: 0.9155 - val_tp: 2666.0000 - val_fp: 1192.0000 - val_tn: 20563.0000 - val_fn: 1685.0000 - val_categorical_accuracy: 0.6532 - val_precision: 0.6910 - val_recall: 0.6127 - val_auc: 0.9246 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.5007 - tp: 7777.0000 - fp: 1460.0000 - tn: 49290.0000 - fn: 2373.0000 - categorical_accuracy: 0.8095 - precision: 0.8419 - recall: 0.7662 - auc: 0.9742 - val_loss: 0.9207 - val_tp: 2680.0000 - val_fp: 1185.0000 - val_tn: 20570.0000 - val_fn: 1671.0000 - val_categorical_accuracy: 0.6520 - val_precision: 0.6934 - val_recall: 0.6160 - val_auc: 0.9240 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.4965 - tp: 7795.0000 - fp: 1471.0000 - tn: 49279.0000 - fn: 2355.0000 - categorical_accuracy: 0.8107 - precision: 0.8412 - recall: 0.7680 - auc: 0.9743 - val_loss: 0.9243 - val_tp: 2697.0000 - val_fp: 1195.0000 - val_tn: 20560.0000 - val_fn: 1654.0000 - val_categorical_accuracy: 0.6541 - val_precision: 0.6930 - val_recall: 0.6199 - val_auc: 0.9237 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4966 - tp: 7867.0000 - fp: 1415.0000 - tn: 49335.0000 - fn: 2283.0000 - categorical_accuracy: 0.8145 - precision: 0.8476 - recall: 0.7751 - auc: 0.9744 - val_loss: 0.9310 - val_tp: 2687.0000 - val_fp: 1235.0000 - val_tn: 20520.0000 - val_fn: 1664.0000 - val_categorical_accuracy: 0.6539 - val_precision: 0.6851 - val_recall: 0.6176 - val_auc: 0.9230 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.5001 - tp: 7820.0000 - fp: 1501.0000 - tn: 49249.0000 - fn: 2330.0000 - categorical_accuracy: 0.8077 - precision: 0.8390 - recall: 0.7704 - auc: 0.9739 - val_loss: 0.9258 - val_tp: 2711.0000 - val_fp: 1203.0000 - val_tn: 20552.0000 - val_fn: 1640.0000 - val_categorical_accuracy: 0.6562 - val_precision: 0.6926 - val_recall: 0.6231 - val_auc: 0.9239 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4890 - tp: 7880.0000 - fp: 1464.0000 - tn: 49286.0000 - fn: 2270.0000 - categorical_accuracy: 0.8139 - precision: 0.8433 - recall: 0.7764 - auc: 0.9751 - val_loss: 0.9274 - val_tp: 2703.0000 - val_fp: 1201.0000 - val_tn: 20554.0000 - val_fn: 1648.0000 - val_categorical_accuracy: 0.6557 - val_precision: 0.6924 - val_recall: 0.6212 - val_auc: 0.9241 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4857 - tp: 7884.0000 - fp: 1445.0000 - tn: 49305.0000 - fn: 2266.0000 - categorical_accuracy: 0.8125 - precision: 0.8451 - recall: 0.7767 - auc: 0.9754 - val_loss: 0.9282 - val_tp: 2678.0000 - val_fp: 1212.0000 - val_tn: 20543.0000 - val_fn: 1673.0000 - val_categorical_accuracy: 0.6555 - val_precision: 0.6884 - val_recall: 0.6155 - val_auc: 0.9239 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4810 - tp: 7900.0000 - fp: 1427.0000 - tn: 49323.0000 - fn: 2250.0000 - categorical_accuracy: 0.8185 - precision: 0.8470 - recall: 0.7783 - auc: 0.9760 - val_loss: 0.9290 - val_tp: 2705.0000 - val_fp: 1223.0000 - val_tn: 20532.0000 - val_fn: 1646.0000 - val_categorical_accuracy: 0.6559 - val_precision: 0.6886 - val_recall: 0.6217 - val_auc: 0.9239 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.4878 - tp: 7875.0000 - fp: 1475.0000 - tn: 49275.0000 - fn: 2275.0000 - categorical_accuracy: 0.8121 - precision: 0.8422 - recall: 0.7759 - auc: 0.9753 - val_loss: 0.9287 - val_tp: 2693.0000 - val_fp: 1204.0000 - val_tn: 20551.0000 - val_fn: 1658.0000 - val_categorical_accuracy: 0.6573 - val_precision: 0.6910 - val_recall: 0.6189 - val_auc: 0.9241 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.4819 - tp: 7943.0000 - fp: 1398.0000 - tn: 49352.0000 - fn: 2207.0000 - categorical_accuracy: 0.8203 - precision: 0.8503 - recall: 0.7826 - auc: 0.9759 - val_loss: 0.9323 - val_tp: 2716.0000 - val_fp: 1209.0000 - val_tn: 20546.0000 - val_fn: 1635.0000 - val_categorical_accuracy: 0.6587 - val_precision: 0.6920 - val_recall: 0.6242 - val_auc: 0.9239 - lr: 1.8151e-04\n",
      "Epoch 93/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4827 - tp: 7878.0000 - fp: 1457.0000 - tn: 49293.0000 - fn: 2272.0000 - categorical_accuracy: 0.8141 - precision: 0.8439 - recall: 0.7762 - auc: 0.9756 - val_loss: 0.9336 - val_tp: 2695.0000 - val_fp: 1213.0000 - val_tn: 20542.0000 - val_fn: 1656.0000 - val_categorical_accuracy: 0.6580 - val_precision: 0.6896 - val_recall: 0.6194 - val_auc: 0.9236 - lr: 1.6621e-04\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 2s 12ms/step - loss: 0.4754 - tp: 7983.0000 - fp: 1420.0000 - tn: 49330.0000 - fn: 2167.0000 - categorical_accuracy: 0.8192 - precision: 0.8490 - recall: 0.7865 - auc: 0.9766 - val_loss: 0.9372 - val_tp: 2689.0000 - val_fp: 1210.0000 - val_tn: 20545.0000 - val_fn: 1662.0000 - val_categorical_accuracy: 0.6569 - val_precision: 0.6897 - val_recall: 0.6180 - val_auc: 0.9233 - lr: 1.5207e-04\n",
      "Epoch 95/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.4773 - tp: 7950.0000 - fp: 1437.0000 - tn: 49313.0000 - fn: 2200.0000 - categorical_accuracy: 0.8200 - precision: 0.8469 - recall: 0.7833 - auc: 0.9763 - val_loss: 0.9336 - val_tp: 2710.0000 - val_fp: 1225.0000 - val_tn: 20530.0000 - val_fn: 1641.0000 - val_categorical_accuracy: 0.6573 - val_precision: 0.6887 - val_recall: 0.6228 - val_auc: 0.9238 - lr: 1.3900e-04\n",
      "Epoch 96/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4759 - tp: 7953.0000 - fp: 1410.0000 - tn: 49340.0000 - fn: 2197.0000 - categorical_accuracy: 0.8229 - precision: 0.8494 - recall: 0.7835 - auc: 0.9766 - val_loss: 0.9370 - val_tp: 2717.0000 - val_fp: 1227.0000 - val_tn: 20528.0000 - val_fn: 1634.0000 - val_categorical_accuracy: 0.6585 - val_precision: 0.6889 - val_recall: 0.6245 - val_auc: 0.9235 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4786 - tp: 7926.0000 - fp: 1439.0000 - tn: 49311.0000 - fn: 2224.0000 - categorical_accuracy: 0.8166 - precision: 0.8463 - recall: 0.7809 - auc: 0.9762 - val_loss: 0.9347 - val_tp: 2695.0000 - val_fp: 1197.0000 - val_tn: 20558.0000 - val_fn: 1656.0000 - val_categorical_accuracy: 0.6598 - val_precision: 0.6924 - val_recall: 0.6194 - val_auc: 0.9239 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.4639 - tp: 8021.0000 - fp: 1367.0000 - tn: 49383.0000 - fn: 2129.0000 - categorical_accuracy: 0.8249 - precision: 0.8544 - recall: 0.7902 - auc: 0.9777 - val_loss: 0.9349 - val_tp: 2720.0000 - val_fp: 1208.0000 - val_tn: 20547.0000 - val_fn: 1631.0000 - val_categorical_accuracy: 0.6592 - val_precision: 0.6925 - val_recall: 0.6251 - val_auc: 0.9241 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "159/159 [==============================] - 2s 12ms/step - loss: 0.4731 - tp: 7930.0000 - fp: 1438.0000 - tn: 49312.0000 - fn: 2220.0000 - categorical_accuracy: 0.8170 - precision: 0.8465 - recall: 0.7813 - auc: 0.9766 - val_loss: 0.9361 - val_tp: 2703.0000 - val_fp: 1204.0000 - val_tn: 20551.0000 - val_fn: 1648.0000 - val_categorical_accuracy: 0.6596 - val_precision: 0.6918 - val_recall: 0.6212 - val_auc: 0.9238 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "159/159 [==============================] - 2s 11ms/step - loss: 0.4671 - tp: 8010.0000 - fp: 1399.0000 - tn: 49351.0000 - fn: 2140.0000 - categorical_accuracy: 0.8222 - precision: 0.8513 - recall: 0.7892 - auc: 0.9771 - val_loss: 0.9359 - val_tp: 2690.0000 - val_fp: 1195.0000 - val_tn: 20560.0000 - val_fn: 1661.0000 - val_categorical_accuracy: 0.6587 - val_precision: 0.6924 - val_recall: 0.6182 - val_auc: 0.9240 - lr: 8.7498e-05\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.1821 - tp: 1326.0000 - fp: 825.0000 - tn: 17300.0000 - fn: 2299.0000 - categorical_accuracy: 0.5319 - precision: 0.6165 - recall: 0.3658 - auc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.182067</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>17300.0</td>\n",
       "      <td>2299.0</td>\n",
       "      <td>0.531862</td>\n",
       "      <td>0.616457</td>\n",
       "      <td>0.365793</td>\n",
       "      <td>0.859393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss      tp     fp       tn      fn  accuracy  precision    recall  \\\n",
       "0  1.182067  1326.0  825.0  17300.0  2299.0  0.531862   0.616457  0.365793   \n",
       "\n",
       "        auc  \n",
       "0  0.859393  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WHICH_DATA = \"contact\" # can be \"contact\" or \"radar\"\n",
    "WHICH_MODEL = \"fully_connected_small\"\n",
    "all_results_contact = helper_functions.train_test_experiment(which_data=WHICH_DATA, which_model=WHICH_MODEL, hyperparams=HYPERPARAMS, metrics=METRICS, class_map=CLASS_MAP)\n",
    "display(all_results_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 313236), started 18:02:22 ago. (Use '!kill 313236' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7d590fad92873978\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7d590fad92873978\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tensorboard for visualisation, use jupyter magic to run it based on things saved during training\n",
    "%load_ext tensorboard\n",
    "if WHICH_DATA==\"contact\":\n",
    "    %tensorboard --logdir model_training_logs/contact_train_test/ --host localhost\n",
    "else:\n",
    "    %tensorboard --logdir model_training_logs/radar_train_test/ --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run train-test experiment for radar sensors [6 classes]\n",
    "\n",
    "The cell below is the equivalent of *main* function. It clears old logs and backend, reads stacked all subject data and feeds it to the models. 70% of data is taken for training, 30% of data is considered for validation.\n",
    "\n",
    "Callbacks are added that save the model after each epoch and logs for TensorBoard (visualisation) are saved.\n",
    "\n",
    "### Attention: \n",
    "\n",
    "If you are running this on GPU, you might want to consider removing callbacks! Those take the majority of time (writing tons of things to disk)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (17090, 1000, 6) (17090,)\n",
      "Oversampling signal 0\n",
      "Oversampling signal 1\n",
      "Oversampling signal 2\n",
      "Oversampling signal 3\n",
      "Oversampling signal 4\n",
      "Oversampling signal 5\n",
      "Shapes after oversampling: (36846, 1000, 6) (36846,)\n",
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_radar_i (InputLayer)      [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_q (InputLayer)      [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_dist (InputLayer)   [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_pulse (InputLayer)  [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_resp (InputLayer)   [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_heartSound (InputLa [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           32032       input_radar_i[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           32032       input_radar_q[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           32032       input_radar_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           32032       input_radar_pulse[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           32032       input_radar_resp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           32032       input_radar_heartSound[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 48)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1568        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 198,374\n",
      "Trainable params: 198,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/323 [..............................] - ETA: 43s - loss: 0.8496 - tp: 4692.0000 - fp: 1467.0000 - tn: 43393.0000 - fn: 4280.0000 - categorical_accuracy: 0.6624 - precision: 0.7618 - recall: 0.5230 - auc: 0.9272WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.132534). Check your callbacks.\n",
      "323/323 [==============================] - 4s 14ms/step - loss: 1.4613 - tp: 5127.0000 - fp: 1873.0000 - tn: 145512.0000 - fn: 24350.0000 - categorical_accuracy: 0.3856 - precision: 0.7324 - recall: 0.1739 - auc: 0.7486 - val_loss: 1.6143 - val_tp: 26.0000 - val_fp: 10.0000 - val_tn: 44210.0000 - val_fn: 8818.0000 - val_categorical_accuracy: 0.3563 - val_precision: 0.7222 - val_recall: 0.0029 - val_auc: 0.7153 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6017 - tp: 1498.0000 - fp: 863.0000 - tn: 102302.0000 - fn: 19135.0000 - categorical_accuracy: 0.3388 - precision: 0.6345 - recall: 0.0726 - auc: 0.7025 - val_loss: 1.5140 - val_tp: 326.0000 - val_fp: 89.0000 - val_tn: 44131.0000 - val_fn: 8518.0000 - val_categorical_accuracy: 0.4080 - val_precision: 0.7855 - val_recall: 0.0369 - val_auc: 0.7507 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5881 - tp: 1532.0000 - fp: 952.0000 - tn: 102213.0000 - fn: 19101.0000 - categorical_accuracy: 0.3475 - precision: 0.6167 - recall: 0.0742 - auc: 0.7101 - val_loss: 1.5769 - val_tp: 137.0000 - val_fp: 50.0000 - val_tn: 44170.0000 - val_fn: 8707.0000 - val_categorical_accuracy: 0.3721 - val_precision: 0.7326 - val_recall: 0.0155 - val_auc: 0.7302 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5956 - tp: 1487.0000 - fp: 871.0000 - tn: 102294.0000 - fn: 19146.0000 - categorical_accuracy: 0.3394 - precision: 0.6306 - recall: 0.0721 - auc: 0.7048 - val_loss: 1.5394 - val_tp: 1223.0000 - val_fp: 818.0000 - val_tn: 43402.0000 - val_fn: 7621.0000 - val_categorical_accuracy: 0.3912 - val_precision: 0.5992 - val_recall: 0.1383 - val_auc: 0.7407 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5782 - tp: 1608.0000 - fp: 909.0000 - tn: 102256.0000 - fn: 19025.0000 - categorical_accuracy: 0.3472 - precision: 0.6389 - recall: 0.0779 - auc: 0.7146 - val_loss: 1.5170 - val_tp: 516.0000 - val_fp: 227.0000 - val_tn: 43993.0000 - val_fn: 8328.0000 - val_categorical_accuracy: 0.3861 - val_precision: 0.6945 - val_recall: 0.0583 - val_auc: 0.7492 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5625 - tp: 1776.0000 - fp: 1015.0000 - tn: 102150.0000 - fn: 18857.0000 - categorical_accuracy: 0.3529 - precision: 0.6363 - recall: 0.0861 - auc: 0.7213 - val_loss: 1.5801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 44220.0000 - val_fn: 8844.0000 - val_categorical_accuracy: 0.3563 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7315 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5536 - tp: 1879.0000 - fp: 1056.0000 - tn: 102109.0000 - fn: 18754.0000 - categorical_accuracy: 0.3558 - precision: 0.6402 - recall: 0.0911 - auc: 0.7251 - val_loss: 1.4744 - val_tp: 419.0000 - val_fp: 140.0000 - val_tn: 44080.0000 - val_fn: 8425.0000 - val_categorical_accuracy: 0.4033 - val_precision: 0.7496 - val_recall: 0.0474 - val_auc: 0.7672 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5359 - tp: 2035.0000 - fp: 1116.0000 - tn: 102049.0000 - fn: 18598.0000 - categorical_accuracy: 0.3677 - precision: 0.6458 - recall: 0.0986 - auc: 0.7343 - val_loss: 1.5004 - val_tp: 590.0000 - val_fp: 214.0000 - val_tn: 44006.0000 - val_fn: 8254.0000 - val_categorical_accuracy: 0.3859 - val_precision: 0.7338 - val_recall: 0.0667 - val_auc: 0.7566 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5471 - tp: 1952.0000 - fp: 1061.0000 - tn: 102104.0000 - fn: 18681.0000 - categorical_accuracy: 0.3570 - precision: 0.6479 - recall: 0.0946 - auc: 0.7283 - val_loss: 1.5277 - val_tp: 372.0000 - val_fp: 113.0000 - val_tn: 44107.0000 - val_fn: 8472.0000 - val_categorical_accuracy: 0.3459 - val_precision: 0.7670 - val_recall: 0.0421 - val_auc: 0.7382 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5684 - tp: 1759.0000 - fp: 944.0000 - tn: 102221.0000 - fn: 18874.0000 - categorical_accuracy: 0.3453 - precision: 0.6508 - recall: 0.0853 - auc: 0.7167 - val_loss: 1.4459 - val_tp: 1243.0000 - val_fp: 500.0000 - val_tn: 43720.0000 - val_fn: 7601.0000 - val_categorical_accuracy: 0.4142 - val_precision: 0.7131 - val_recall: 0.1405 - val_auc: 0.7686 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5548 - tp: 2011.0000 - fp: 1148.0000 - tn: 102017.0000 - fn: 18622.0000 - categorical_accuracy: 0.3582 - precision: 0.6366 - recall: 0.0975 - auc: 0.7246 - val_loss: 1.5248 - val_tp: 661.0000 - val_fp: 240.0000 - val_tn: 43980.0000 - val_fn: 8183.0000 - val_categorical_accuracy: 0.3541 - val_precision: 0.7336 - val_recall: 0.0747 - val_auc: 0.7438 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5641 - tp: 1867.0000 - fp: 1046.0000 - tn: 102119.0000 - fn: 18766.0000 - categorical_accuracy: 0.3473 - precision: 0.6409 - recall: 0.0905 - auc: 0.7196 - val_loss: 1.4700 - val_tp: 590.0000 - val_fp: 191.0000 - val_tn: 44029.0000 - val_fn: 8254.0000 - val_categorical_accuracy: 0.3934 - val_precision: 0.7554 - val_recall: 0.0667 - val_auc: 0.7690 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5943 - tp: 1607.0000 - fp: 878.0000 - tn: 102287.0000 - fn: 19026.0000 - categorical_accuracy: 0.3231 - precision: 0.6467 - recall: 0.0779 - auc: 0.6999 - val_loss: 1.6716 - val_tp: 421.0000 - val_fp: 167.0000 - val_tn: 44053.0000 - val_fn: 8423.0000 - val_categorical_accuracy: 0.2934 - val_precision: 0.7160 - val_recall: 0.0476 - val_auc: 0.6384 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6116 - tp: 1334.0000 - fp: 701.0000 - tn: 102464.0000 - fn: 19299.0000 - categorical_accuracy: 0.3223 - precision: 0.6555 - recall: 0.0647 - auc: 0.6919 - val_loss: 1.5088 - val_tp: 658.0000 - val_fp: 352.0000 - val_tn: 43868.0000 - val_fn: 8186.0000 - val_categorical_accuracy: 0.3575 - val_precision: 0.6515 - val_recall: 0.0744 - val_auc: 0.7439 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6203 - tp: 1310.0000 - fp: 713.0000 - tn: 102452.0000 - fn: 19323.0000 - categorical_accuracy: 0.3147 - precision: 0.6476 - recall: 0.0635 - auc: 0.6848 - val_loss: 1.6328 - val_tp: 169.0000 - val_fp: 47.0000 - val_tn: 44173.0000 - val_fn: 8675.0000 - val_categorical_accuracy: 0.3365 - val_precision: 0.7824 - val_recall: 0.0191 - val_auc: 0.6825 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6387 - tp: 1031.0000 - fp: 524.0000 - tn: 102641.0000 - fn: 19602.0000 - categorical_accuracy: 0.3199 - precision: 0.6630 - recall: 0.0500 - auc: 0.6737 - val_loss: 1.6371 - val_tp: 404.0000 - val_fp: 168.0000 - val_tn: 44052.0000 - val_fn: 8440.0000 - val_categorical_accuracy: 0.3316 - val_precision: 0.7063 - val_recall: 0.0457 - val_auc: 0.6745 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6331 - tp: 1069.0000 - fp: 540.0000 - tn: 102625.0000 - fn: 19564.0000 - categorical_accuracy: 0.3242 - precision: 0.6644 - recall: 0.0518 - auc: 0.6758 - val_loss: 1.6245 - val_tp: 455.0000 - val_fp: 197.0000 - val_tn: 44023.0000 - val_fn: 8389.0000 - val_categorical_accuracy: 0.3325 - val_precision: 0.6979 - val_recall: 0.0514 - val_auc: 0.6757 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 4s 11ms/step - loss: 1.6249 - tp: 1128.0000 - fp: 589.0000 - tn: 102576.0000 - fn: 19505.0000 - categorical_accuracy: 0.3237 - precision: 0.6570 - recall: 0.0547 - auc: 0.6797 - val_loss: 1.5996 - val_tp: 463.0000 - val_fp: 223.0000 - val_tn: 43997.0000 - val_fn: 8381.0000 - val_categorical_accuracy: 0.3519 - val_precision: 0.6749 - val_recall: 0.0524 - val_auc: 0.6905 - lr: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6182 - tp: 1205.0000 - fp: 631.0000 - tn: 102534.0000 - fn: 19428.0000 - categorical_accuracy: 0.3135 - precision: 0.6563 - recall: 0.0584 - auc: 0.6827 - val_loss: 1.5818 - val_tp: 499.0000 - val_fp: 234.0000 - val_tn: 43986.0000 - val_fn: 8345.0000 - val_categorical_accuracy: 0.3338 - val_precision: 0.6808 - val_recall: 0.0564 - val_auc: 0.7018 - lr: 0.0089\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6096 - tp: 1233.0000 - fp: 602.0000 - tn: 102563.0000 - fn: 19400.0000 - categorical_accuracy: 0.3199 - precision: 0.6719 - recall: 0.0598 - auc: 0.6881 - val_loss: 1.5782 - val_tp: 590.0000 - val_fp: 335.0000 - val_tn: 43885.0000 - val_fn: 8254.0000 - val_categorical_accuracy: 0.3453 - val_precision: 0.6378 - val_recall: 0.0667 - val_auc: 0.7046 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6197 - tp: 1261.0000 - fp: 599.0000 - tn: 102566.0000 - fn: 19372.0000 - categorical_accuracy: 0.3245 - precision: 0.6780 - recall: 0.0611 - auc: 0.6817 - val_loss: 1.5965 - val_tp: 550.0000 - val_fp: 323.0000 - val_tn: 43897.0000 - val_fn: 8294.0000 - val_categorical_accuracy: 0.3539 - val_precision: 0.6300 - val_recall: 0.0622 - val_auc: 0.6936 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6161 - tp: 1261.0000 - fp: 628.0000 - tn: 102537.0000 - fn: 19372.0000 - categorical_accuracy: 0.3260 - precision: 0.6675 - recall: 0.0611 - auc: 0.6835 - val_loss: 1.5829 - val_tp: 499.0000 - val_fp: 205.0000 - val_tn: 44015.0000 - val_fn: 8345.0000 - val_categorical_accuracy: 0.3591 - val_precision: 0.7088 - val_recall: 0.0564 - val_auc: 0.7014 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6161 - tp: 1328.0000 - fp: 632.0000 - tn: 102533.0000 - fn: 19305.0000 - categorical_accuracy: 0.3279 - precision: 0.6776 - recall: 0.0644 - auc: 0.6840 - val_loss: 1.6226 - val_tp: 450.0000 - val_fp: 200.0000 - val_tn: 44020.0000 - val_fn: 8394.0000 - val_categorical_accuracy: 0.3418 - val_precision: 0.6923 - val_recall: 0.0509 - val_auc: 0.6808 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6156 - tp: 1168.0000 - fp: 616.0000 - tn: 102549.0000 - fn: 19465.0000 - categorical_accuracy: 0.3167 - precision: 0.6547 - recall: 0.0566 - auc: 0.6863 - val_loss: 1.6074 - val_tp: 511.0000 - val_fp: 297.0000 - val_tn: 43923.0000 - val_fn: 8333.0000 - val_categorical_accuracy: 0.3200 - val_precision: 0.6324 - val_recall: 0.0578 - val_auc: 0.7001 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6160 - tp: 1220.0000 - fp: 610.0000 - tn: 102555.0000 - fn: 19413.0000 - categorical_accuracy: 0.3179 - precision: 0.6667 - recall: 0.0591 - auc: 0.6843 - val_loss: 1.5990 - val_tp: 492.0000 - val_fp: 231.0000 - val_tn: 43989.0000 - val_fn: 8352.0000 - val_categorical_accuracy: 0.3422 - val_precision: 0.6805 - val_recall: 0.0556 - val_auc: 0.6953 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6207 - tp: 1226.0000 - fp: 619.0000 - tn: 102546.0000 - fn: 19407.0000 - categorical_accuracy: 0.3283 - precision: 0.6645 - recall: 0.0594 - auc: 0.6808 - val_loss: 1.5820 - val_tp: 534.0000 - val_fp: 266.0000 - val_tn: 43954.0000 - val_fn: 8310.0000 - val_categorical_accuracy: 0.3466 - val_precision: 0.6675 - val_recall: 0.0604 - val_auc: 0.7023 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6055 - tp: 1413.0000 - fp: 660.0000 - tn: 102505.0000 - fn: 19220.0000 - categorical_accuracy: 0.3313 - precision: 0.6816 - recall: 0.0685 - auc: 0.6885 - val_loss: 1.5763 - val_tp: 510.0000 - val_fp: 233.0000 - val_tn: 43987.0000 - val_fn: 8334.0000 - val_categorical_accuracy: 0.3566 - val_precision: 0.6864 - val_recall: 0.0577 - val_auc: 0.7072 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6048 - tp: 1392.0000 - fp: 653.0000 - tn: 102512.0000 - fn: 19241.0000 - categorical_accuracy: 0.3328 - precision: 0.6807 - recall: 0.0675 - auc: 0.6885 - val_loss: 1.5610 - val_tp: 548.0000 - val_fp: 238.0000 - val_tn: 43982.0000 - val_fn: 8296.0000 - val_categorical_accuracy: 0.3370 - val_precision: 0.6972 - val_recall: 0.0620 - val_auc: 0.7151 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6056 - tp: 1342.0000 - fp: 674.0000 - tn: 102491.0000 - fn: 19291.0000 - categorical_accuracy: 0.3222 - precision: 0.6657 - recall: 0.0650 - auc: 0.6900 - val_loss: 1.5571 - val_tp: 456.0000 - val_fp: 187.0000 - val_tn: 44033.0000 - val_fn: 8388.0000 - val_categorical_accuracy: 0.3327 - val_precision: 0.7092 - val_recall: 0.0516 - val_auc: 0.7189 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6075 - tp: 1342.0000 - fp: 665.0000 - tn: 102500.0000 - fn: 19291.0000 - categorical_accuracy: 0.3192 - precision: 0.6687 - recall: 0.0650 - auc: 0.6879 - val_loss: 1.5798 - val_tp: 544.0000 - val_fp: 225.0000 - val_tn: 43995.0000 - val_fn: 8300.0000 - val_categorical_accuracy: 0.3637 - val_precision: 0.7074 - val_recall: 0.0615 - val_auc: 0.7082 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6072 - tp: 1354.0000 - fp: 658.0000 - tn: 102507.0000 - fn: 19279.0000 - categorical_accuracy: 0.3323 - precision: 0.6730 - recall: 0.0656 - auc: 0.6879 - val_loss: 1.5895 - val_tp: 456.0000 - val_fp: 196.0000 - val_tn: 44024.0000 - val_fn: 8388.0000 - val_categorical_accuracy: 0.3652 - val_precision: 0.6994 - val_recall: 0.0516 - val_auc: 0.6956 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5895 - tp: 1483.0000 - fp: 725.0000 - tn: 102440.0000 - fn: 19150.0000 - categorical_accuracy: 0.3293 - precision: 0.6716 - recall: 0.0719 - auc: 0.6963 - val_loss: 1.5486 - val_tp: 544.0000 - val_fp: 239.0000 - val_tn: 43981.0000 - val_fn: 8300.0000 - val_categorical_accuracy: 0.3322 - val_precision: 0.6948 - val_recall: 0.0615 - val_auc: 0.7223 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5875 - tp: 1480.0000 - fp: 703.0000 - tn: 102462.0000 - fn: 19153.0000 - categorical_accuracy: 0.3353 - precision: 0.6780 - recall: 0.0717 - auc: 0.6963 - val_loss: 1.5790 - val_tp: 548.0000 - val_fp: 245.0000 - val_tn: 43975.0000 - val_fn: 8296.0000 - val_categorical_accuracy: 0.3615 - val_precision: 0.6910 - val_recall: 0.0620 - val_auc: 0.7010 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5972 - tp: 1412.0000 - fp: 662.0000 - tn: 102503.0000 - fn: 19221.0000 - categorical_accuracy: 0.3418 - precision: 0.6808 - recall: 0.0684 - auc: 0.6905 - val_loss: 1.5727 - val_tp: 547.0000 - val_fp: 267.0000 - val_tn: 43953.0000 - val_fn: 8297.0000 - val_categorical_accuracy: 0.3625 - val_precision: 0.6720 - val_recall: 0.0618 - val_auc: 0.7049 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5881 - tp: 1468.0000 - fp: 700.0000 - tn: 102465.0000 - fn: 19165.0000 - categorical_accuracy: 0.3279 - precision: 0.6771 - recall: 0.0711 - auc: 0.6967 - val_loss: 1.5591 - val_tp: 558.0000 - val_fp: 302.0000 - val_tn: 43918.0000 - val_fn: 8286.0000 - val_categorical_accuracy: 0.3556 - val_precision: 0.6488 - val_recall: 0.0631 - val_auc: 0.7152 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5736 - tp: 1531.0000 - fp: 751.0000 - tn: 102414.0000 - fn: 19102.0000 - categorical_accuracy: 0.3209 - precision: 0.6709 - recall: 0.0742 - auc: 0.7030 - val_loss: 1.5825 - val_tp: 621.0000 - val_fp: 352.0000 - val_tn: 43868.0000 - val_fn: 8223.0000 - val_categorical_accuracy: 0.3609 - val_precision: 0.6382 - val_recall: 0.0702 - val_auc: 0.7011 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5946 - tp: 1437.0000 - fp: 698.0000 - tn: 102467.0000 - fn: 19196.0000 - categorical_accuracy: 0.3308 - precision: 0.6731 - recall: 0.0696 - auc: 0.6912 - val_loss: 1.5632 - val_tp: 600.0000 - val_fp: 304.0000 - val_tn: 43916.0000 - val_fn: 8244.0000 - val_categorical_accuracy: 0.3596 - val_precision: 0.6637 - val_recall: 0.0678 - val_auc: 0.7087 - lr: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5911 - tp: 1511.0000 - fp: 707.0000 - tn: 102458.0000 - fn: 19122.0000 - categorical_accuracy: 0.3278 - precision: 0.6812 - recall: 0.0732 - auc: 0.6929 - val_loss: 1.5951 - val_tp: 475.0000 - val_fp: 204.0000 - val_tn: 44016.0000 - val_fn: 8369.0000 - val_categorical_accuracy: 0.3356 - val_precision: 0.6996 - val_recall: 0.0537 - val_auc: 0.6934 - lr: 0.0053\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5941 - tp: 1469.0000 - fp: 677.0000 - tn: 102488.0000 - fn: 19164.0000 - categorical_accuracy: 0.3247 - precision: 0.6845 - recall: 0.0712 - auc: 0.6895 - val_loss: 1.5989 - val_tp: 381.0000 - val_fp: 141.0000 - val_tn: 44079.0000 - val_fn: 8463.0000 - val_categorical_accuracy: 0.3321 - val_precision: 0.7299 - val_recall: 0.0431 - val_auc: 0.6916 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.6030 - tp: 1452.0000 - fp: 651.0000 - tn: 102514.0000 - fn: 19181.0000 - categorical_accuracy: 0.3228 - precision: 0.6904 - recall: 0.0704 - auc: 0.6871 - val_loss: 1.6275 - val_tp: 468.0000 - val_fp: 186.0000 - val_tn: 44034.0000 - val_fn: 8376.0000 - val_categorical_accuracy: 0.3325 - val_precision: 0.7156 - val_recall: 0.0529 - val_auc: 0.6780 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.6035 - tp: 1452.0000 - fp: 662.0000 - tn: 102503.0000 - fn: 19181.0000 - categorical_accuracy: 0.3244 - precision: 0.6868 - recall: 0.0704 - auc: 0.6863 - val_loss: 1.5942 - val_tp: 549.0000 - val_fp: 241.0000 - val_tn: 43979.0000 - val_fn: 8295.0000 - val_categorical_accuracy: 0.3336 - val_precision: 0.6949 - val_recall: 0.0621 - val_auc: 0.6936 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5929 - tp: 1463.0000 - fp: 676.0000 - tn: 102489.0000 - fn: 19170.0000 - categorical_accuracy: 0.3286 - precision: 0.6840 - recall: 0.0709 - auc: 0.6911 - val_loss: 1.6113 - val_tp: 407.0000 - val_fp: 127.0000 - val_tn: 44093.0000 - val_fn: 8437.0000 - val_categorical_accuracy: 0.3242 - val_precision: 0.7622 - val_recall: 0.0460 - val_auc: 0.6853 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5964 - tp: 1432.0000 - fp: 633.0000 - tn: 102532.0000 - fn: 19201.0000 - categorical_accuracy: 0.3281 - precision: 0.6935 - recall: 0.0694 - auc: 0.6901 - val_loss: 1.5950 - val_tp: 557.0000 - val_fp: 271.0000 - val_tn: 43949.0000 - val_fn: 8287.0000 - val_categorical_accuracy: 0.3373 - val_precision: 0.6727 - val_recall: 0.0630 - val_auc: 0.6917 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5944 - tp: 1428.0000 - fp: 666.0000 - tn: 102499.0000 - fn: 19205.0000 - categorical_accuracy: 0.3271 - precision: 0.6819 - recall: 0.0692 - auc: 0.6917 - val_loss: 1.5991 - val_tp: 484.0000 - val_fp: 200.0000 - val_tn: 44020.0000 - val_fn: 8360.0000 - val_categorical_accuracy: 0.3350 - val_precision: 0.7076 - val_recall: 0.0547 - val_auc: 0.6909 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5923 - tp: 1555.0000 - fp: 692.0000 - tn: 102473.0000 - fn: 19078.0000 - categorical_accuracy: 0.3268 - precision: 0.6920 - recall: 0.0754 - auc: 0.6913 - val_loss: 1.6143 - val_tp: 639.0000 - val_fp: 326.0000 - val_tn: 43894.0000 - val_fn: 8205.0000 - val_categorical_accuracy: 0.3355 - val_precision: 0.6622 - val_recall: 0.0723 - val_auc: 0.6849 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 4s 11ms/step - loss: 1.5794 - tp: 1594.0000 - fp: 718.0000 - tn: 102447.0000 - fn: 19039.0000 - categorical_accuracy: 0.3307 - precision: 0.6894 - recall: 0.0773 - auc: 0.6972 - val_loss: 1.5850 - val_tp: 530.0000 - val_fp: 222.0000 - val_tn: 43998.0000 - val_fn: 8314.0000 - val_categorical_accuracy: 0.3388 - val_precision: 0.7048 - val_recall: 0.0599 - val_auc: 0.6974 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5821 - tp: 1530.0000 - fp: 683.0000 - tn: 102482.0000 - fn: 19103.0000 - categorical_accuracy: 0.3304 - precision: 0.6914 - recall: 0.0742 - auc: 0.6964 - val_loss: 1.5879 - val_tp: 540.0000 - val_fp: 237.0000 - val_tn: 43983.0000 - val_fn: 8304.0000 - val_categorical_accuracy: 0.3388 - val_precision: 0.6950 - val_recall: 0.0611 - val_auc: 0.6959 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5768 - tp: 1607.0000 - fp: 692.0000 - tn: 102473.0000 - fn: 19026.0000 - categorical_accuracy: 0.3308 - precision: 0.6990 - recall: 0.0779 - auc: 0.6979 - val_loss: 1.5847 - val_tp: 544.0000 - val_fp: 250.0000 - val_tn: 43970.0000 - val_fn: 8300.0000 - val_categorical_accuracy: 0.3399 - val_precision: 0.6851 - val_recall: 0.0615 - val_auc: 0.6972 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5754 - tp: 1589.0000 - fp: 718.0000 - tn: 102447.0000 - fn: 19044.0000 - categorical_accuracy: 0.3356 - precision: 0.6888 - recall: 0.0770 - auc: 0.6995 - val_loss: 1.5836 - val_tp: 511.0000 - val_fp: 221.0000 - val_tn: 43999.0000 - val_fn: 8333.0000 - val_categorical_accuracy: 0.3411 - val_precision: 0.6981 - val_recall: 0.0578 - val_auc: 0.6979 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5869 - tp: 1568.0000 - fp: 680.0000 - tn: 102485.0000 - fn: 19065.0000 - categorical_accuracy: 0.3305 - precision: 0.6975 - recall: 0.0760 - auc: 0.6944 - val_loss: 1.5910 - val_tp: 428.0000 - val_fp: 170.0000 - val_tn: 44050.0000 - val_fn: 8416.0000 - val_categorical_accuracy: 0.3358 - val_precision: 0.7157 - val_recall: 0.0484 - val_auc: 0.6957 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5783 - tp: 1550.0000 - fp: 697.0000 - tn: 102468.0000 - fn: 19083.0000 - categorical_accuracy: 0.3329 - precision: 0.6898 - recall: 0.0751 - auc: 0.6991 - val_loss: 1.5861 - val_tp: 547.0000 - val_fp: 276.0000 - val_tn: 43944.0000 - val_fn: 8297.0000 - val_categorical_accuracy: 0.3372 - val_precision: 0.6646 - val_recall: 0.0618 - val_auc: 0.6987 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5695 - tp: 1605.0000 - fp: 728.0000 - tn: 102437.0000 - fn: 19028.0000 - categorical_accuracy: 0.3341 - precision: 0.6880 - recall: 0.0778 - auc: 0.7011 - val_loss: 1.5961 - val_tp: 627.0000 - val_fp: 294.0000 - val_tn: 43926.0000 - val_fn: 8217.0000 - val_categorical_accuracy: 0.3358 - val_precision: 0.6808 - val_recall: 0.0709 - val_auc: 0.6934 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5798 - tp: 1555.0000 - fp: 693.0000 - tn: 102472.0000 - fn: 19078.0000 - categorical_accuracy: 0.3304 - precision: 0.6917 - recall: 0.0754 - auc: 0.6974 - val_loss: 1.5896 - val_tp: 424.0000 - val_fp: 167.0000 - val_tn: 44053.0000 - val_fn: 8420.0000 - val_categorical_accuracy: 0.3370 - val_precision: 0.7174 - val_recall: 0.0479 - val_auc: 0.6954 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5735 - tp: 1565.0000 - fp: 687.0000 - tn: 102478.0000 - fn: 19068.0000 - categorical_accuracy: 0.3309 - precision: 0.6949 - recall: 0.0758 - auc: 0.6997 - val_loss: 1.5793 - val_tp: 581.0000 - val_fp: 276.0000 - val_tn: 43944.0000 - val_fn: 8263.0000 - val_categorical_accuracy: 0.3390 - val_precision: 0.6779 - val_recall: 0.0657 - val_auc: 0.6999 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 3s 11ms/step - loss: 1.5687 - tp: 1607.0000 - fp: 685.0000 - tn: 102480.0000 - fn: 19026.0000 - categorical_accuracy: 0.3367 - precision: 0.7011 - recall: 0.0779 - auc: 0.7024 - val_loss: 1.5800 - val_tp: 498.0000 - val_fp: 192.0000 - val_tn: 44028.0000 - val_fn: 8346.0000 - val_categorical_accuracy: 0.3446 - val_precision: 0.7217 - val_recall: 0.0563 - val_auc: 0.6994 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5631 - tp: 1614.0000 - fp: 693.0000 - tn: 102472.0000 - fn: 19019.0000 - categorical_accuracy: 0.3370 - precision: 0.6996 - recall: 0.0782 - auc: 0.7032 - val_loss: 1.5730 - val_tp: 606.0000 - val_fp: 291.0000 - val_tn: 43929.0000 - val_fn: 8238.0000 - val_categorical_accuracy: 0.3466 - val_precision: 0.6756 - val_recall: 0.0685 - val_auc: 0.7035 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5595 - tp: 1631.0000 - fp: 731.0000 - tn: 102434.0000 - fn: 19002.0000 - categorical_accuracy: 0.3383 - precision: 0.6905 - recall: 0.0790 - auc: 0.7061 - val_loss: 1.5752 - val_tp: 539.0000 - val_fp: 253.0000 - val_tn: 43967.0000 - val_fn: 8305.0000 - val_categorical_accuracy: 0.3416 - val_precision: 0.6806 - val_recall: 0.0609 - val_auc: 0.7018 - lr: 0.0022\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5582 - tp: 1645.0000 - fp: 701.0000 - tn: 102464.0000 - fn: 18988.0000 - categorical_accuracy: 0.3400 - precision: 0.7012 - recall: 0.0797 - auc: 0.7055 - val_loss: 1.5751 - val_tp: 601.0000 - val_fp: 307.0000 - val_tn: 43913.0000 - val_fn: 8243.0000 - val_categorical_accuracy: 0.3405 - val_precision: 0.6619 - val_recall: 0.0680 - val_auc: 0.7025 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5587 - tp: 1686.0000 - fp: 725.0000 - tn: 102440.0000 - fn: 18947.0000 - categorical_accuracy: 0.3372 - precision: 0.6993 - recall: 0.0817 - auc: 0.7050 - val_loss: 1.5762 - val_tp: 518.0000 - val_fp: 220.0000 - val_tn: 44000.0000 - val_fn: 8326.0000 - val_categorical_accuracy: 0.3443 - val_precision: 0.7019 - val_recall: 0.0586 - val_auc: 0.7018 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 3s 10ms/step - loss: 1.5618 - tp: 1615.0000 - fp: 667.0000 - tn: 102498.0000 - fn: 19018.0000 - categorical_accuracy: 0.3402 - precision: 0.7077 - recall: 0.0783 - auc: 0.7054 - val_loss: 1.5745 - val_tp: 489.0000 - val_fp: 205.0000 - val_tn: 44015.0000 - val_fn: 8355.0000 - val_categorical_accuracy: 0.3454 - val_precision: 0.7046 - val_recall: 0.0553 - val_auc: 0.7036 - lr: 0.0019\n",
      "Epoch 00060: early stopping\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 1.9998 - tp: 0.0000e+00 - fp: 553.0000 - tn: 36292.0000 - fn: 7369.0000 - categorical_accuracy: 0.0014 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.999804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>36292.0</td>\n",
       "      <td>7369.0</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss   tp     fp       tn      fn  accuracy  precision  recall  \\\n",
       "0  1.999804  0.0  553.0  36292.0  7369.0  0.001357        0.0     0.0   \n",
       "\n",
       "        auc  \n",
       "0  0.475544  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WHICH_DATA = \"radar\" # can be \"contact\" or \"radar\"\n",
    "all_results_radar = helper_functions.train_test_experiment(which_data=WHICH_DATA, which_model=WHICH_MODEL, hyperparams=HYPERPARAMS, metrics=METRICS, class_map=CLASS_MAP)\n",
    "display(all_results_radar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-45222e7ab641e92c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-45222e7ab641e92c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tensorboard for visualisation, use jupyter magic to run it based on things saved during training\n",
    "%load_ext tensorboard\n",
    "if WHICH_DATA==\"contact\":\n",
    "    %tensorboard --logdir model_training_logs/contact_train_test/ --host localhost\n",
    "else:\n",
    "    %tensorboard --logdir model_training_logs/radar_train_test/ --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify problem [2 classes]\n",
    "\n",
    "As default ANNs with all 6 classes do not seem to work (loss does not decrease, accuracy does not increase), we invstigate a simplified problem. We select only **apnea** and **resting** classes and attempt to separate them using only contact data.\n",
    "\n",
    "**NOTE**: This is a heavily imbalanced problem, but our aim is to see if we recognize apnea. We work around this by setting the class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown experiment type!\n",
      "Original shape: (17090, 1000, 6) (17090,)\n",
      "Taking subsets of data for classes: ['Apnea', 'Resting']\n",
      "Subset shapes: (4136, 1000, 6) (4136,)\n",
      "Oversampling signal 0\n",
      "Oversampling signal 1\n",
      "Oversampling signal 2\n",
      "Oversampling signal 3\n",
      "Oversampling signal 4\n",
      "Oversampling signal 5\n",
      "Shapes after oversampling: (7530, 1000, 6) (7530,)\n",
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_contact_bp (InputLayer)   [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_ecg1 (InputLayer) [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_ecg2 (InputLayer) [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_icg (InputLayer)  [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_resp (InputLayer) [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_z0 (InputLayer)   [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           32032       input_contact_bp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           32032       input_contact_ecg1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           32032       input_contact_ecg2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           32032       input_contact_icg[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           32032       input_contact_resp[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           32032       input_contact_z0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           272         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 56)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1824        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 4)            68          dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 198,732\n",
      "Trainable params: 198,732\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.5497 - tp: 3232.0000 - fp: 724.0000 - tn: 11924.0000 - fn: 984.0000 - categorical_accuracy: 0.7993 - precision: 0.8170 - recall: 0.7666 - auc: 0.9478 - val_loss: 0.2497 - val_tp: 1648.0000 - val_fp: 141.0000 - val_tn: 5283.0000 - val_fn: 160.0000 - val_categorical_accuracy: 0.9181 - val_precision: 0.9212 - val_recall: 0.9115 - val_auc: 0.9878 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2799 - tp: 3777.0000 - fp: 401.0000 - tn: 12247.0000 - fn: 439.0000 - categorical_accuracy: 0.9001 - precision: 0.9040 - recall: 0.8959 - auc: 0.9844 - val_loss: 0.1887 - val_tp: 1686.0000 - val_fp: 118.0000 - val_tn: 5306.0000 - val_fn: 122.0000 - val_categorical_accuracy: 0.9336 - val_precision: 0.9346 - val_recall: 0.9325 - val_auc: 0.9926 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2586 - tp: 3814.0000 - fp: 384.0000 - tn: 12264.0000 - fn: 402.0000 - categorical_accuracy: 0.9068 - precision: 0.9085 - recall: 0.9046 - auc: 0.9862 - val_loss: 0.1784 - val_tp: 1697.0000 - val_fp: 105.0000 - val_tn: 5319.0000 - val_fn: 111.0000 - val_categorical_accuracy: 0.9403 - val_precision: 0.9417 - val_recall: 0.9386 - val_auc: 0.9947 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2433 - tp: 3840.0000 - fp: 367.0000 - tn: 12281.0000 - fn: 376.0000 - categorical_accuracy: 0.9120 - precision: 0.9128 - recall: 0.9108 - auc: 0.9878 - val_loss: 0.1456 - val_tp: 1717.0000 - val_fp: 89.0000 - val_tn: 5335.0000 - val_fn: 91.0000 - val_categorical_accuracy: 0.9497 - val_precision: 0.9507 - val_recall: 0.9497 - val_auc: 0.9963 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1915 - tp: 3902.0000 - fp: 300.0000 - tn: 12348.0000 - fn: 314.0000 - categorical_accuracy: 0.9269 - precision: 0.9286 - recall: 0.9255 - auc: 0.9925 - val_loss: 0.1702 - val_tp: 1690.0000 - val_fp: 111.0000 - val_tn: 5313.0000 - val_fn: 118.0000 - val_categorical_accuracy: 0.9358 - val_precision: 0.9384 - val_recall: 0.9347 - val_auc: 0.9943 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1983 - tp: 3900.0000 - fp: 300.0000 - tn: 12348.0000 - fn: 316.0000 - categorical_accuracy: 0.9267 - precision: 0.9286 - recall: 0.9250 - auc: 0.9918 - val_loss: 0.1456 - val_tp: 1721.0000 - val_fp: 84.0000 - val_tn: 5340.0000 - val_fn: 87.0000 - val_categorical_accuracy: 0.9519 - val_precision: 0.9535 - val_recall: 0.9519 - val_auc: 0.9960 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1922 - tp: 3910.0000 - fp: 301.0000 - tn: 12347.0000 - fn: 306.0000 - categorical_accuracy: 0.9284 - precision: 0.9285 - recall: 0.9274 - auc: 0.9921 - val_loss: 0.1190 - val_tp: 1735.0000 - val_fp: 72.0000 - val_tn: 5352.0000 - val_fn: 73.0000 - val_categorical_accuracy: 0.9602 - val_precision: 0.9602 - val_recall: 0.9596 - val_auc: 0.9975 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1916 - tp: 3919.0000 - fp: 292.0000 - tn: 12356.0000 - fn: 297.0000 - categorical_accuracy: 0.9298 - precision: 0.9307 - recall: 0.9296 - auc: 0.9918 - val_loss: 0.1342 - val_tp: 1714.0000 - val_fp: 94.0000 - val_tn: 5330.0000 - val_fn: 94.0000 - val_categorical_accuracy: 0.9480 - val_precision: 0.9480 - val_recall: 0.9480 - val_auc: 0.9964 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1634 - tp: 3955.0000 - fp: 258.0000 - tn: 12390.0000 - fn: 261.0000 - categorical_accuracy: 0.9386 - precision: 0.9388 - recall: 0.9381 - auc: 0.9945 - val_loss: 0.1083 - val_tp: 1739.0000 - val_fp: 67.0000 - val_tn: 5357.0000 - val_fn: 69.0000 - val_categorical_accuracy: 0.9618 - val_precision: 0.9629 - val_recall: 0.9618 - val_auc: 0.9979 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1796 - tp: 3937.0000 - fp: 275.0000 - tn: 12373.0000 - fn: 279.0000 - categorical_accuracy: 0.9338 - precision: 0.9347 - recall: 0.9338 - auc: 0.9930 - val_loss: 0.1102 - val_tp: 1736.0000 - val_fp: 69.0000 - val_tn: 5355.0000 - val_fn: 72.0000 - val_categorical_accuracy: 0.9607 - val_precision: 0.9618 - val_recall: 0.9602 - val_auc: 0.9972 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1873 - tp: 3893.0000 - fp: 320.0000 - tn: 12328.0000 - fn: 323.0000 - categorical_accuracy: 0.9239 - precision: 0.9240 - recall: 0.9234 - auc: 0.9925 - val_loss: 0.1456 - val_tp: 1716.0000 - val_fp: 92.0000 - val_tn: 5332.0000 - val_fn: 92.0000 - val_categorical_accuracy: 0.9491 - val_precision: 0.9491 - val_recall: 0.9491 - val_auc: 0.9950 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1997 - tp: 3867.0000 - fp: 344.0000 - tn: 12304.0000 - fn: 349.0000 - categorical_accuracy: 0.9182 - precision: 0.9183 - recall: 0.9172 - auc: 0.9918 - val_loss: 0.1354 - val_tp: 1724.0000 - val_fp: 84.0000 - val_tn: 5340.0000 - val_fn: 84.0000 - val_categorical_accuracy: 0.9535 - val_precision: 0.9535 - val_recall: 0.9535 - val_auc: 0.9963 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1902 - tp: 3918.0000 - fp: 296.0000 - tn: 12352.0000 - fn: 298.0000 - categorical_accuracy: 0.9296 - precision: 0.9298 - recall: 0.9293 - auc: 0.9920 - val_loss: 0.1229 - val_tp: 1731.0000 - val_fp: 77.0000 - val_tn: 5347.0000 - val_fn: 77.0000 - val_categorical_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_auc: 0.9976 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1825 - tp: 3917.0000 - fp: 294.0000 - tn: 12354.0000 - fn: 299.0000 - categorical_accuracy: 0.9298 - precision: 0.9302 - recall: 0.9291 - auc: 0.9930 - val_loss: 0.1349 - val_tp: 1709.0000 - val_fp: 98.0000 - val_tn: 5326.0000 - val_fn: 99.0000 - val_categorical_accuracy: 0.9452 - val_precision: 0.9458 - val_recall: 0.9452 - val_auc: 0.9963 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1563 - tp: 3972.0000 - fp: 241.0000 - tn: 12407.0000 - fn: 244.0000 - categorical_accuracy: 0.9426 - precision: 0.9428 - recall: 0.9421 - auc: 0.9944 - val_loss: 0.1819 - val_tp: 1684.0000 - val_fp: 123.0000 - val_tn: 5301.0000 - val_fn: 124.0000 - val_categorical_accuracy: 0.9320 - val_precision: 0.9319 - val_recall: 0.9314 - val_auc: 0.9936 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2116 - tp: 3854.0000 - fp: 359.0000 - tn: 12289.0000 - fn: 362.0000 - categorical_accuracy: 0.9144 - precision: 0.9148 - recall: 0.9141 - auc: 0.9907 - val_loss: 0.1189 - val_tp: 1727.0000 - val_fp: 80.0000 - val_tn: 5344.0000 - val_fn: 81.0000 - val_categorical_accuracy: 0.9552 - val_precision: 0.9557 - val_recall: 0.9552 - val_auc: 0.9968 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1469 - tp: 3990.0000 - fp: 225.0000 - tn: 12423.0000 - fn: 226.0000 - categorical_accuracy: 0.9464 - precision: 0.9466 - recall: 0.9464 - auc: 0.9951 - val_loss: 0.1138 - val_tp: 1739.0000 - val_fp: 69.0000 - val_tn: 5355.0000 - val_fn: 69.0000 - val_categorical_accuracy: 0.9618 - val_precision: 0.9618 - val_recall: 0.9618 - val_auc: 0.9967 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1783 - tp: 3939.0000 - fp: 274.0000 - tn: 12374.0000 - fn: 277.0000 - categorical_accuracy: 0.9348 - precision: 0.9350 - recall: 0.9343 - auc: 0.9929 - val_loss: 0.1834 - val_tp: 1688.0000 - val_fp: 118.0000 - val_tn: 5306.0000 - val_fn: 120.0000 - val_categorical_accuracy: 0.9342 - val_precision: 0.9347 - val_recall: 0.9336 - val_auc: 0.9924 - lr: 0.0091\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1853 - tp: 3912.0000 - fp: 300.0000 - tn: 12348.0000 - fn: 304.0000 - categorical_accuracy: 0.9284 - precision: 0.9288 - recall: 0.9279 - auc: 0.9925 - val_loss: 0.1227 - val_tp: 1730.0000 - val_fp: 78.0000 - val_tn: 5346.0000 - val_fn: 78.0000 - val_categorical_accuracy: 0.9569 - val_precision: 0.9569 - val_recall: 0.9569 - val_auc: 0.9974 - lr: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1634 - tp: 3945.0000 - fp: 270.0000 - tn: 12378.0000 - fn: 271.0000 - categorical_accuracy: 0.9360 - precision: 0.9359 - recall: 0.9357 - auc: 0.9944 - val_loss: 0.1322 - val_tp: 1717.0000 - val_fp: 91.0000 - val_tn: 5333.0000 - val_fn: 91.0000 - val_categorical_accuracy: 0.9497 - val_precision: 0.9497 - val_recall: 0.9497 - val_auc: 0.9968 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1623 - tp: 3966.0000 - fp: 250.0000 - tn: 12398.0000 - fn: 250.0000 - categorical_accuracy: 0.9407 - precision: 0.9407 - recall: 0.9407 - auc: 0.9941 - val_loss: 0.1571 - val_tp: 1695.0000 - val_fp: 112.0000 - val_tn: 5312.0000 - val_fn: 113.0000 - val_categorical_accuracy: 0.9375 - val_precision: 0.9380 - val_recall: 0.9375 - val_auc: 0.9950 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1674 - tp: 3954.0000 - fp: 262.0000 - tn: 12386.0000 - fn: 262.0000 - categorical_accuracy: 0.9379 - precision: 0.9379 - recall: 0.9379 - auc: 0.9936 - val_loss: 0.1063 - val_tp: 1742.0000 - val_fp: 66.0000 - val_tn: 5358.0000 - val_fn: 66.0000 - val_categorical_accuracy: 0.9635 - val_precision: 0.9635 - val_recall: 0.9635 - val_auc: 0.9980 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1402 - tp: 3980.0000 - fp: 235.0000 - tn: 12413.0000 - fn: 236.0000 - categorical_accuracy: 0.9440 - precision: 0.9442 - recall: 0.9440 - auc: 0.9958 - val_loss: 0.1481 - val_tp: 1693.0000 - val_fp: 114.0000 - val_tn: 5310.0000 - val_fn: 115.0000 - val_categorical_accuracy: 0.9364 - val_precision: 0.9369 - val_recall: 0.9364 - val_auc: 0.9953 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1567 - tp: 3959.0000 - fp: 254.0000 - tn: 12394.0000 - fn: 257.0000 - categorical_accuracy: 0.9398 - precision: 0.9397 - recall: 0.9390 - auc: 0.9948 - val_loss: 0.1420 - val_tp: 1718.0000 - val_fp: 90.0000 - val_tn: 5334.0000 - val_fn: 90.0000 - val_categorical_accuracy: 0.9502 - val_precision: 0.9502 - val_recall: 0.9502 - val_auc: 0.9955 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1336 - tp: 3995.0000 - fp: 221.0000 - tn: 12427.0000 - fn: 221.0000 - categorical_accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - auc: 0.9958 - val_loss: 0.0973 - val_tp: 1747.0000 - val_fp: 61.0000 - val_tn: 5363.0000 - val_fn: 61.0000 - val_categorical_accuracy: 0.9663 - val_precision: 0.9663 - val_recall: 0.9663 - val_auc: 0.9980 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1354 - tp: 3989.0000 - fp: 226.0000 - tn: 12422.0000 - fn: 227.0000 - categorical_accuracy: 0.9462 - precision: 0.9464 - recall: 0.9462 - auc: 0.9959 - val_loss: 0.1341 - val_tp: 1722.0000 - val_fp: 85.0000 - val_tn: 5339.0000 - val_fn: 86.0000 - val_categorical_accuracy: 0.9530 - val_precision: 0.9530 - val_recall: 0.9524 - val_auc: 0.9949 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1424 - tp: 3980.0000 - fp: 236.0000 - tn: 12412.0000 - fn: 236.0000 - categorical_accuracy: 0.9440 - precision: 0.9440 - recall: 0.9440 - auc: 0.9954 - val_loss: 0.1009 - val_tp: 1748.0000 - val_fp: 58.0000 - val_tn: 5366.0000 - val_fn: 60.0000 - val_categorical_accuracy: 0.9674 - val_precision: 0.9679 - val_recall: 0.9668 - val_auc: 0.9977 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1333 - tp: 4002.0000 - fp: 211.0000 - tn: 12437.0000 - fn: 214.0000 - categorical_accuracy: 0.9497 - precision: 0.9499 - recall: 0.9492 - auc: 0.9961 - val_loss: 0.1425 - val_tp: 1707.0000 - val_fp: 98.0000 - val_tn: 5326.0000 - val_fn: 101.0000 - val_categorical_accuracy: 0.9452 - val_precision: 0.9457 - val_recall: 0.9441 - val_auc: 0.9961 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1615 - tp: 3952.0000 - fp: 259.0000 - tn: 12389.0000 - fn: 264.0000 - categorical_accuracy: 0.9381 - precision: 0.9385 - recall: 0.9374 - auc: 0.9944 - val_loss: 0.1254 - val_tp: 1735.0000 - val_fp: 72.0000 - val_tn: 5352.0000 - val_fn: 73.0000 - val_categorical_accuracy: 0.9596 - val_precision: 0.9602 - val_recall: 0.9596 - val_auc: 0.9969 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1790 - tp: 3912.0000 - fp: 301.0000 - tn: 12347.0000 - fn: 304.0000 - categorical_accuracy: 0.9284 - precision: 0.9286 - recall: 0.9279 - auc: 0.9933 - val_loss: 0.1284 - val_tp: 1729.0000 - val_fp: 77.0000 - val_tn: 5347.0000 - val_fn: 79.0000 - val_categorical_accuracy: 0.9569 - val_precision: 0.9574 - val_recall: 0.9563 - val_auc: 0.9967 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1516 - tp: 3974.0000 - fp: 240.0000 - tn: 12408.0000 - fn: 242.0000 - categorical_accuracy: 0.9428 - precision: 0.9430 - recall: 0.9426 - auc: 0.9949 - val_loss: 0.1317 - val_tp: 1708.0000 - val_fp: 100.0000 - val_tn: 5324.0000 - val_fn: 100.0000 - val_categorical_accuracy: 0.9447 - val_precision: 0.9447 - val_recall: 0.9447 - val_auc: 0.9970 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1331 - tp: 4011.0000 - fp: 203.0000 - tn: 12445.0000 - fn: 205.0000 - categorical_accuracy: 0.9519 - precision: 0.9518 - recall: 0.9514 - auc: 0.9962 - val_loss: 0.1104 - val_tp: 1731.0000 - val_fp: 77.0000 - val_tn: 5347.0000 - val_fn: 77.0000 - val_categorical_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_auc: 0.9976 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1605 - tp: 3951.0000 - fp: 264.0000 - tn: 12384.0000 - fn: 265.0000 - categorical_accuracy: 0.9374 - precision: 0.9374 - recall: 0.9371 - auc: 0.9947 - val_loss: 0.1118 - val_tp: 1735.0000 - val_fp: 73.0000 - val_tn: 5351.0000 - val_fn: 73.0000 - val_categorical_accuracy: 0.9596 - val_precision: 0.9596 - val_recall: 0.9596 - val_auc: 0.9975 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1187 - tp: 4033.0000 - fp: 181.0000 - tn: 12467.0000 - fn: 183.0000 - categorical_accuracy: 0.9568 - precision: 0.9570 - recall: 0.9566 - auc: 0.9969 - val_loss: 0.1046 - val_tp: 1738.0000 - val_fp: 70.0000 - val_tn: 5354.0000 - val_fn: 70.0000 - val_categorical_accuracy: 0.9613 - val_precision: 0.9613 - val_recall: 0.9613 - val_auc: 0.9980 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1229 - tp: 4025.0000 - fp: 190.0000 - tn: 12458.0000 - fn: 191.0000 - categorical_accuracy: 0.9547 - precision: 0.9549 - recall: 0.9547 - auc: 0.9965 - val_loss: 0.1186 - val_tp: 1731.0000 - val_fp: 77.0000 - val_tn: 5347.0000 - val_fn: 77.0000 - val_categorical_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_auc: 0.9969 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1395 - tp: 3987.0000 - fp: 229.0000 - tn: 12419.0000 - fn: 229.0000 - categorical_accuracy: 0.9457 - precision: 0.9457 - recall: 0.9457 - auc: 0.9958 - val_loss: 0.0847 - val_tp: 1751.0000 - val_fp: 57.0000 - val_tn: 5367.0000 - val_fn: 57.0000 - val_categorical_accuracy: 0.9685 - val_precision: 0.9685 - val_recall: 0.9685 - val_auc: 0.9983 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0975 - tp: 4059.0000 - fp: 157.0000 - tn: 12491.0000 - fn: 157.0000 - categorical_accuracy: 0.9628 - precision: 0.9628 - recall: 0.9628 - auc: 0.9976 - val_loss: 0.1088 - val_tp: 1734.0000 - val_fp: 73.0000 - val_tn: 5351.0000 - val_fn: 74.0000 - val_categorical_accuracy: 0.9591 - val_precision: 0.9596 - val_recall: 0.9591 - val_auc: 0.9970 - lr: 0.0055\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1230 - tp: 4029.0000 - fp: 185.0000 - tn: 12463.0000 - fn: 187.0000 - categorical_accuracy: 0.9559 - precision: 0.9561 - recall: 0.9556 - auc: 0.9962 - val_loss: 0.0930 - val_tp: 1757.0000 - val_fp: 51.0000 - val_tn: 5373.0000 - val_fn: 51.0000 - val_categorical_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_auc: 0.9978 - lr: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1217 - tp: 4008.0000 - fp: 207.0000 - tn: 12441.0000 - fn: 208.0000 - categorical_accuracy: 0.9507 - precision: 0.9509 - recall: 0.9507 - auc: 0.9968 - val_loss: 0.1478 - val_tp: 1709.0000 - val_fp: 99.0000 - val_tn: 5325.0000 - val_fn: 99.0000 - val_categorical_accuracy: 0.9452 - val_precision: 0.9452 - val_recall: 0.9452 - val_auc: 0.9955 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1448 - tp: 3987.0000 - fp: 229.0000 - tn: 12419.0000 - fn: 229.0000 - categorical_accuracy: 0.9457 - precision: 0.9457 - recall: 0.9457 - auc: 0.9954 - val_loss: 0.0961 - val_tp: 1748.0000 - val_fp: 60.0000 - val_tn: 5364.0000 - val_fn: 60.0000 - val_categorical_accuracy: 0.9668 - val_precision: 0.9668 - val_recall: 0.9668 - val_auc: 0.9980 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1219 - tp: 4016.0000 - fp: 198.0000 - tn: 12450.0000 - fn: 200.0000 - categorical_accuracy: 0.9528 - precision: 0.9530 - recall: 0.9526 - auc: 0.9964 - val_loss: 0.1091 - val_tp: 1735.0000 - val_fp: 73.0000 - val_tn: 5351.0000 - val_fn: 73.0000 - val_categorical_accuracy: 0.9596 - val_precision: 0.9596 - val_recall: 0.9596 - val_auc: 0.9975 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0854 - tp: 4072.0000 - fp: 144.0000 - tn: 12504.0000 - fn: 144.0000 - categorical_accuracy: 0.9658 - precision: 0.9658 - recall: 0.9658 - auc: 0.9985 - val_loss: 0.1188 - val_tp: 1724.0000 - val_fp: 84.0000 - val_tn: 5340.0000 - val_fn: 84.0000 - val_categorical_accuracy: 0.9535 - val_precision: 0.9535 - val_recall: 0.9535 - val_auc: 0.9973 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1080 - tp: 4039.0000 - fp: 177.0000 - tn: 12471.0000 - fn: 177.0000 - categorical_accuracy: 0.9580 - precision: 0.9580 - recall: 0.9580 - auc: 0.9975 - val_loss: 0.1184 - val_tp: 1717.0000 - val_fp: 91.0000 - val_tn: 5333.0000 - val_fn: 91.0000 - val_categorical_accuracy: 0.9497 - val_precision: 0.9497 - val_recall: 0.9497 - val_auc: 0.9962 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0984 - tp: 4054.0000 - fp: 161.0000 - tn: 12487.0000 - fn: 162.0000 - categorical_accuracy: 0.9616 - precision: 0.9618 - recall: 0.9616 - auc: 0.9977 - val_loss: 0.0943 - val_tp: 1756.0000 - val_fp: 52.0000 - val_tn: 5372.0000 - val_fn: 52.0000 - val_categorical_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_auc: 0.9979 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0912 - tp: 4069.0000 - fp: 144.0000 - tn: 12504.0000 - fn: 147.0000 - categorical_accuracy: 0.9654 - precision: 0.9658 - recall: 0.9651 - auc: 0.9983 - val_loss: 0.1149 - val_tp: 1730.0000 - val_fp: 78.0000 - val_tn: 5346.0000 - val_fn: 78.0000 - val_categorical_accuracy: 0.9569 - val_precision: 0.9569 - val_recall: 0.9569 - val_auc: 0.9965 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0919 - tp: 4069.0000 - fp: 146.0000 - tn: 12502.0000 - fn: 147.0000 - categorical_accuracy: 0.9651 - precision: 0.9654 - recall: 0.9651 - auc: 0.9980 - val_loss: 0.0846 - val_tp: 1753.0000 - val_fp: 54.0000 - val_tn: 5370.0000 - val_fn: 55.0000 - val_categorical_accuracy: 0.9701 - val_precision: 0.9701 - val_recall: 0.9696 - val_auc: 0.9980 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0626 - tp: 4120.0000 - fp: 94.0000 - tn: 12554.0000 - fn: 96.0000 - categorical_accuracy: 0.9775 - precision: 0.9777 - recall: 0.9772 - auc: 0.9989 - val_loss: 0.0870 - val_tp: 1753.0000 - val_fp: 55.0000 - val_tn: 5369.0000 - val_fn: 55.0000 - val_categorical_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_auc: 0.9976 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0964 - tp: 4069.0000 - fp: 147.0000 - tn: 12501.0000 - fn: 147.0000 - categorical_accuracy: 0.9651 - precision: 0.9651 - recall: 0.9651 - auc: 0.9978 - val_loss: 0.1027 - val_tp: 1744.0000 - val_fp: 64.0000 - val_tn: 5360.0000 - val_fn: 64.0000 - val_categorical_accuracy: 0.9646 - val_precision: 0.9646 - val_recall: 0.9646 - val_auc: 0.9967 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0808 - tp: 4079.0000 - fp: 137.0000 - tn: 12511.0000 - fn: 137.0000 - categorical_accuracy: 0.9675 - precision: 0.9675 - recall: 0.9675 - auc: 0.9985 - val_loss: 0.1057 - val_tp: 1735.0000 - val_fp: 73.0000 - val_tn: 5351.0000 - val_fn: 73.0000 - val_categorical_accuracy: 0.9596 - val_precision: 0.9596 - val_recall: 0.9596 - val_auc: 0.9972 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0694 - tp: 4114.0000 - fp: 102.0000 - tn: 12546.0000 - fn: 102.0000 - categorical_accuracy: 0.9758 - precision: 0.9758 - recall: 0.9758 - auc: 0.9988 - val_loss: 0.0925 - val_tp: 1752.0000 - val_fp: 56.0000 - val_tn: 5368.0000 - val_fn: 56.0000 - val_categorical_accuracy: 0.9690 - val_precision: 0.9690 - val_recall: 0.9690 - val_auc: 0.9968 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0649 - tp: 4110.0000 - fp: 105.0000 - tn: 12543.0000 - fn: 106.0000 - categorical_accuracy: 0.9749 - precision: 0.9751 - recall: 0.9749 - auc: 0.9990 - val_loss: 0.0842 - val_tp: 1757.0000 - val_fp: 51.0000 - val_tn: 5373.0000 - val_fn: 51.0000 - val_categorical_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_auc: 0.9979 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0640 - tp: 4112.0000 - fp: 103.0000 - tn: 12545.0000 - fn: 104.0000 - categorical_accuracy: 0.9753 - precision: 0.9756 - recall: 0.9753 - auc: 0.9990 - val_loss: 0.0862 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9979 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0673 - tp: 4106.0000 - fp: 108.0000 - tn: 12540.0000 - fn: 110.0000 - categorical_accuracy: 0.9741 - precision: 0.9744 - recall: 0.9739 - auc: 0.9989 - val_loss: 0.0762 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9978 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0528 - tp: 4133.0000 - fp: 83.0000 - tn: 12565.0000 - fn: 83.0000 - categorical_accuracy: 0.9803 - precision: 0.9803 - recall: 0.9803 - auc: 0.9991 - val_loss: 0.1022 - val_tp: 1746.0000 - val_fp: 61.0000 - val_tn: 5363.0000 - val_fn: 62.0000 - val_categorical_accuracy: 0.9657 - val_precision: 0.9662 - val_recall: 0.9657 - val_auc: 0.9964 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0722 - tp: 4125.0000 - fp: 91.0000 - tn: 12557.0000 - fn: 91.0000 - categorical_accuracy: 0.9784 - precision: 0.9784 - recall: 0.9784 - auc: 0.9984 - val_loss: 0.0819 - val_tp: 1760.0000 - val_fp: 48.0000 - val_tn: 5376.0000 - val_fn: 48.0000 - val_categorical_accuracy: 0.9735 - val_precision: 0.9735 - val_recall: 0.9735 - val_auc: 0.9979 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0601 - tp: 4130.0000 - fp: 86.0000 - tn: 12562.0000 - fn: 86.0000 - categorical_accuracy: 0.9796 - precision: 0.9796 - recall: 0.9796 - auc: 0.9988 - val_loss: 0.0745 - val_tp: 1767.0000 - val_fp: 41.0000 - val_tn: 5383.0000 - val_fn: 41.0000 - val_categorical_accuracy: 0.9773 - val_precision: 0.9773 - val_recall: 0.9773 - val_auc: 0.9971 - lr: 0.0023\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0567 - tp: 4135.0000 - fp: 81.0000 - tn: 12567.0000 - fn: 81.0000 - categorical_accuracy: 0.9808 - precision: 0.9808 - recall: 0.9808 - auc: 0.9989 - val_loss: 0.0767 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9978 - lr: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0531 - tp: 4138.0000 - fp: 78.0000 - tn: 12570.0000 - fn: 78.0000 - categorical_accuracy: 0.9815 - precision: 0.9815 - recall: 0.9815 - auc: 0.9994 - val_loss: 0.0711 - val_tp: 1767.0000 - val_fp: 40.0000 - val_tn: 5384.0000 - val_fn: 41.0000 - val_categorical_accuracy: 0.9779 - val_precision: 0.9779 - val_recall: 0.9773 - val_auc: 0.9979 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0789 - tp: 4099.0000 - fp: 117.0000 - tn: 12531.0000 - fn: 117.0000 - categorical_accuracy: 0.9722 - precision: 0.9722 - recall: 0.9722 - auc: 0.9983 - val_loss: 0.0760 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9972 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0528 - tp: 4144.0000 - fp: 72.0000 - tn: 12576.0000 - fn: 72.0000 - categorical_accuracy: 0.9829 - precision: 0.9829 - recall: 0.9829 - auc: 0.9992 - val_loss: 0.0865 - val_tp: 1752.0000 - val_fp: 55.0000 - val_tn: 5369.0000 - val_fn: 56.0000 - val_categorical_accuracy: 0.9690 - val_precision: 0.9696 - val_recall: 0.9690 - val_auc: 0.9974 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.0681 - tp: 4108.0000 - fp: 108.0000 - tn: 12540.0000 - fn: 108.0000 - categorical_accuracy: 0.9744 - precision: 0.9744 - recall: 0.9744 - auc: 0.9989 - val_loss: 0.0814 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9974 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0674 - tp: 4114.0000 - fp: 101.0000 - tn: 12547.0000 - fn: 102.0000 - categorical_accuracy: 0.9760 - precision: 0.9760 - recall: 0.9758 - auc: 0.9989 - val_loss: 0.0834 - val_tp: 1753.0000 - val_fp: 55.0000 - val_tn: 5369.0000 - val_fn: 55.0000 - val_categorical_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_auc: 0.9980 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0460 - tp: 4150.0000 - fp: 66.0000 - tn: 12582.0000 - fn: 66.0000 - categorical_accuracy: 0.9843 - precision: 0.9843 - recall: 0.9843 - auc: 0.9993 - val_loss: 0.0706 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9980 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0412 - tp: 4148.0000 - fp: 68.0000 - tn: 12580.0000 - fn: 68.0000 - categorical_accuracy: 0.9839 - precision: 0.9839 - recall: 0.9839 - auc: 0.9997 - val_loss: 0.0909 - val_tp: 1747.0000 - val_fp: 61.0000 - val_tn: 5363.0000 - val_fn: 61.0000 - val_categorical_accuracy: 0.9663 - val_precision: 0.9663 - val_recall: 0.9663 - val_auc: 0.9976 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0482 - tp: 4148.0000 - fp: 68.0000 - tn: 12580.0000 - fn: 68.0000 - categorical_accuracy: 0.9839 - precision: 0.9839 - recall: 0.9839 - auc: 0.9992 - val_loss: 0.0878 - val_tp: 1757.0000 - val_fp: 51.0000 - val_tn: 5373.0000 - val_fn: 51.0000 - val_categorical_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_auc: 0.9971 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0355 - tp: 4165.0000 - fp: 51.0000 - tn: 12597.0000 - fn: 51.0000 - categorical_accuracy: 0.9879 - precision: 0.9879 - recall: 0.9879 - auc: 0.9997 - val_loss: 0.0929 - val_tp: 1757.0000 - val_fp: 51.0000 - val_tn: 5373.0000 - val_fn: 51.0000 - val_categorical_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_auc: 0.9966 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0440 - tp: 4153.0000 - fp: 63.0000 - tn: 12585.0000 - fn: 63.0000 - categorical_accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - auc: 0.9990 - val_loss: 0.0830 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9978 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0428 - tp: 4151.0000 - fp: 64.0000 - tn: 12584.0000 - fn: 65.0000 - categorical_accuracy: 0.9848 - precision: 0.9848 - recall: 0.9846 - auc: 0.9995 - val_loss: 0.0857 - val_tp: 1753.0000 - val_fp: 55.0000 - val_tn: 5369.0000 - val_fn: 55.0000 - val_categorical_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_auc: 0.9971 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0376 - tp: 4157.0000 - fp: 59.0000 - tn: 12589.0000 - fn: 59.0000 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9860 - auc: 0.9994 - val_loss: 0.0709 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9981 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0327 - tp: 4172.0000 - fp: 44.0000 - tn: 12604.0000 - fn: 44.0000 - categorical_accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - auc: 0.9998 - val_loss: 0.0845 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9968 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.0429 - tp: 4157.0000 - fp: 58.0000 - tn: 12590.0000 - fn: 59.0000 - categorical_accuracy: 0.9862 - precision: 0.9862 - recall: 0.9860 - auc: 0.9995 - val_loss: 0.0921 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9970 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0341 - tp: 4168.0000 - fp: 48.0000 - tn: 12600.0000 - fn: 48.0000 - categorical_accuracy: 0.9886 - precision: 0.9886 - recall: 0.9886 - auc: 0.9995 - val_loss: 0.0834 - val_tp: 1760.0000 - val_fp: 48.0000 - val_tn: 5376.0000 - val_fn: 48.0000 - val_categorical_accuracy: 0.9735 - val_precision: 0.9735 - val_recall: 0.9735 - val_auc: 0.9976 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0373 - tp: 4164.0000 - fp: 52.0000 - tn: 12596.0000 - fn: 52.0000 - categorical_accuracy: 0.9877 - precision: 0.9877 - recall: 0.9877 - auc: 0.9994 - val_loss: 0.0794 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9973 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0369 - tp: 4154.0000 - fp: 61.0000 - tn: 12587.0000 - fn: 62.0000 - categorical_accuracy: 0.9855 - precision: 0.9855 - recall: 0.9853 - auc: 0.9997 - val_loss: 0.0767 - val_tp: 1767.0000 - val_fp: 41.0000 - val_tn: 5383.0000 - val_fn: 41.0000 - val_categorical_accuracy: 0.9773 - val_precision: 0.9773 - val_recall: 0.9773 - val_auc: 0.9981 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0303 - tp: 4173.0000 - fp: 43.0000 - tn: 12605.0000 - fn: 43.0000 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9898 - auc: 0.9998 - val_loss: 0.0824 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9980 - lr: 7.0388e-04\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0309 - tp: 4175.0000 - fp: 41.0000 - tn: 12607.0000 - fn: 41.0000 - categorical_accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - auc: 0.9998 - val_loss: 0.0781 - val_tp: 1762.0000 - val_fp: 46.0000 - val_tn: 5378.0000 - val_fn: 46.0000 - val_categorical_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9976 - lr: 6.5477e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0292 - tp: 4174.0000 - fp: 41.0000 - tn: 12607.0000 - fn: 42.0000 - categorical_accuracy: 0.9900 - precision: 0.9903 - recall: 0.9900 - auc: 0.9994 - val_loss: 0.0765 - val_tp: 1770.0000 - val_fp: 38.0000 - val_tn: 5386.0000 - val_fn: 38.0000 - val_categorical_accuracy: 0.9790 - val_precision: 0.9790 - val_recall: 0.9790 - val_auc: 0.9977 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0332 - tp: 4162.0000 - fp: 54.0000 - tn: 12594.0000 - fn: 54.0000 - categorical_accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - auc: 0.9998 - val_loss: 0.0780 - val_tp: 1762.0000 - val_fp: 46.0000 - val_tn: 5378.0000 - val_fn: 46.0000 - val_categorical_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9977 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0300 - tp: 4177.0000 - fp: 39.0000 - tn: 12609.0000 - fn: 39.0000 - categorical_accuracy: 0.9907 - precision: 0.9907 - recall: 0.9907 - auc: 0.9996 - val_loss: 0.0862 - val_tp: 1761.0000 - val_fp: 47.0000 - val_tn: 5377.0000 - val_fn: 47.0000 - val_categorical_accuracy: 0.9740 - val_precision: 0.9740 - val_recall: 0.9740 - val_auc: 0.9973 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0351 - tp: 4169.0000 - fp: 46.0000 - tn: 12602.0000 - fn: 47.0000 - categorical_accuracy: 0.9891 - precision: 0.9891 - recall: 0.9889 - auc: 0.9997 - val_loss: 0.0942 - val_tp: 1757.0000 - val_fp: 50.0000 - val_tn: 5374.0000 - val_fn: 51.0000 - val_categorical_accuracy: 0.9723 - val_precision: 0.9723 - val_recall: 0.9718 - val_auc: 0.9971 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0341 - tp: 4163.0000 - fp: 53.0000 - tn: 12595.0000 - fn: 53.0000 - categorical_accuracy: 0.9874 - precision: 0.9874 - recall: 0.9874 - auc: 0.9997 - val_loss: 0.0945 - val_tp: 1761.0000 - val_fp: 47.0000 - val_tn: 5377.0000 - val_fn: 47.0000 - val_categorical_accuracy: 0.9740 - val_precision: 0.9740 - val_recall: 0.9740 - val_auc: 0.9960 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0306 - tp: 4172.0000 - fp: 43.0000 - tn: 12605.0000 - fn: 44.0000 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9896 - auc: 0.9997 - val_loss: 0.0904 - val_tp: 1758.0000 - val_fp: 50.0000 - val_tn: 5374.0000 - val_fn: 50.0000 - val_categorical_accuracy: 0.9723 - val_precision: 0.9723 - val_recall: 0.9723 - val_auc: 0.9965 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0303 - tp: 4172.0000 - fp: 44.0000 - tn: 12604.0000 - fn: 44.0000 - categorical_accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - auc: 0.9998 - val_loss: 0.0912 - val_tp: 1757.0000 - val_fp: 51.0000 - val_tn: 5373.0000 - val_fn: 51.0000 - val_categorical_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_auc: 0.9969 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0336 - tp: 4169.0000 - fp: 47.0000 - tn: 12601.0000 - fn: 47.0000 - categorical_accuracy: 0.9889 - precision: 0.9889 - recall: 0.9889 - auc: 0.9995 - val_loss: 0.0927 - val_tp: 1756.0000 - val_fp: 52.0000 - val_tn: 5372.0000 - val_fn: 52.0000 - val_categorical_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_auc: 0.9965 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0291 - tp: 4172.0000 - fp: 44.0000 - tn: 12604.0000 - fn: 44.0000 - categorical_accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - auc: 0.9998 - val_loss: 0.0924 - val_tp: 1762.0000 - val_fp: 46.0000 - val_tn: 5378.0000 - val_fn: 46.0000 - val_categorical_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9968 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0317 - tp: 4166.0000 - fp: 50.0000 - tn: 12598.0000 - fn: 50.0000 - categorical_accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - auc: 0.9996 - val_loss: 0.0830 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9970 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0249 - tp: 4181.0000 - fp: 35.0000 - tn: 12613.0000 - fn: 35.0000 - categorical_accuracy: 0.9917 - precision: 0.9917 - recall: 0.9917 - auc: 0.9999 - val_loss: 0.0831 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9973 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0232 - tp: 4185.0000 - fp: 31.0000 - tn: 12617.0000 - fn: 31.0000 - categorical_accuracy: 0.9926 - precision: 0.9926 - recall: 0.9926 - auc: 0.9997 - val_loss: 0.0820 - val_tp: 1767.0000 - val_fp: 41.0000 - val_tn: 5383.0000 - val_fn: 41.0000 - val_categorical_accuracy: 0.9773 - val_precision: 0.9773 - val_recall: 0.9773 - val_auc: 0.9974 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0286 - tp: 4164.0000 - fp: 51.0000 - tn: 12597.0000 - fn: 52.0000 - categorical_accuracy: 0.9879 - precision: 0.9879 - recall: 0.9877 - auc: 0.9999 - val_loss: 0.0871 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9973 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0214 - tp: 4188.0000 - fp: 28.0000 - tn: 12620.0000 - fn: 28.0000 - categorical_accuracy: 0.9934 - precision: 0.9934 - recall: 0.9934 - auc: 0.9999 - val_loss: 0.0863 - val_tp: 1761.0000 - val_fp: 46.0000 - val_tn: 5378.0000 - val_fn: 47.0000 - val_categorical_accuracy: 0.9740 - val_precision: 0.9745 - val_recall: 0.9740 - val_auc: 0.9973 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0284 - tp: 4172.0000 - fp: 44.0000 - tn: 12604.0000 - fn: 44.0000 - categorical_accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - auc: 0.9997 - val_loss: 0.0849 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9973 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0320 - tp: 4177.0000 - fp: 39.0000 - tn: 12609.0000 - fn: 39.0000 - categorical_accuracy: 0.9907 - precision: 0.9907 - recall: 0.9907 - auc: 0.9993 - val_loss: 0.0876 - val_tp: 1761.0000 - val_fp: 47.0000 - val_tn: 5377.0000 - val_fn: 47.0000 - val_categorical_accuracy: 0.9740 - val_precision: 0.9740 - val_recall: 0.9740 - val_auc: 0.9970 - lr: 1.8151e-04\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0234 - tp: 4180.0000 - fp: 36.0000 - tn: 12612.0000 - fn: 36.0000 - categorical_accuracy: 0.9915 - precision: 0.9915 - recall: 0.9915 - auc: 0.9997 - val_loss: 0.0876 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9970 - lr: 1.6621e-04\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0214 - tp: 4185.0000 - fp: 31.0000 - tn: 12617.0000 - fn: 31.0000 - categorical_accuracy: 0.9926 - precision: 0.9926 - recall: 0.9926 - auc: 0.9997 - val_loss: 0.0844 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9970 - lr: 1.5207e-04\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0264 - tp: 4177.0000 - fp: 39.0000 - tn: 12609.0000 - fn: 39.0000 - categorical_accuracy: 0.9907 - precision: 0.9907 - recall: 0.9907 - auc: 0.9995 - val_loss: 0.0830 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9971 - lr: 1.3900e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0205 - tp: 4191.0000 - fp: 25.0000 - tn: 12623.0000 - fn: 25.0000 - categorical_accuracy: 0.9941 - precision: 0.9941 - recall: 0.9941 - auc: 0.9999 - val_loss: 0.0828 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9967 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0222 - tp: 4186.0000 - fp: 30.0000 - tn: 12618.0000 - fn: 30.0000 - categorical_accuracy: 0.9929 - precision: 0.9929 - recall: 0.9929 - auc: 0.9999 - val_loss: 0.0847 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9967 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0205 - tp: 4188.0000 - fp: 27.0000 - tn: 12621.0000 - fn: 28.0000 - categorical_accuracy: 0.9934 - precision: 0.9936 - recall: 0.9934 - auc: 0.9999 - val_loss: 0.0850 - val_tp: 1763.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9757 - val_recall: 0.9751 - val_auc: 0.9967 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0242 - tp: 4176.0000 - fp: 40.0000 - tn: 12608.0000 - fn: 40.0000 - categorical_accuracy: 0.9905 - precision: 0.9905 - recall: 0.9905 - auc: 0.9999 - val_loss: 0.0843 - val_tp: 1762.0000 - val_fp: 46.0000 - val_tn: 5378.0000 - val_fn: 46.0000 - val_categorical_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9964 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0298 - tp: 4172.0000 - fp: 44.0000 - tn: 12604.0000 - fn: 44.0000 - categorical_accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - auc: 0.9993 - val_loss: 0.0825 - val_tp: 1762.0000 - val_fp: 46.0000 - val_tn: 5378.0000 - val_fn: 46.0000 - val_categorical_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9967 - lr: 8.7498e-05\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0402 - tp: 1491.0000 - fp: 15.0000 - tn: 4503.0000 - fn: 15.0000 - categorical_accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900 - auc: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040197</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4503.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99004</td>\n",
       "      <td>0.99004</td>\n",
       "      <td>0.99004</td>\n",
       "      <td>0.998707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss      tp    fp      tn    fn  accuracy  precision   recall  \\\n",
       "0  0.040197  1491.0  15.0  4503.0  15.0   0.99004    0.99004  0.99004   \n",
       "\n",
       "        auc  \n",
       "0  0.998707  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECTED_CLASSES = [\"Apnea\", \"Resting\"]\n",
    "WHICH_DATA = \"contact\" # can be \"contact\" or \"radar\"\n",
    "WHICH_MODEL = \"fully_connected_small\"\n",
    "results_contact_2class = helper_functions.train_test_experiment(which_data=WHICH_DATA, which_model=WHICH_MODEL, hyperparams=HYPERPARAMS, metrics=METRICS, class_map=CLASS_MAP, selected_classes=SELECTED_CLASSES)\n",
    "display(results_contact_2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 313236), started 18:41:27 ago. (Use '!kill 313236' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-739502e3cce5d437\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-739502e3cce5d437\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tensorboard for visualisation, use jupyter magic to run it based on things saved during training\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir model_training_logs/contact_train_test/ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (17090, 1000, 6) (17090,)\n",
      "Taking subsets of data for classes: ['Apnea', 'Resting']\n",
      "Subset shapes: (4136, 1000, 6) (4136,)\n",
      "Oversampling signal 0\n",
      "Oversampling signal 1\n",
      "Oversampling signal 2\n",
      "Oversampling signal 3\n",
      "Oversampling signal 4\n",
      "Oversampling signal 5\n",
      "Shapes after oversampling: (7530, 1000, 6) (7530,)\n",
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_radar_i (InputLayer)      [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_q (InputLayer)      [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_dist (InputLayer)   [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_pulse (InputLayer)  [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_resp (InputLayer)   [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_heartSound (InputLa [(None, 1000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           32032       input_radar_i[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           32032       input_radar_q[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           32032       input_radar_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           32032       input_radar_pulse[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           32032       input_radar_resp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           32032       input_radar_heartSound[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 48)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1568        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 4)            68          dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 198,340\n",
      "Trainable params: 198,340\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/66 [..............................] - ETA: 8s - loss: 0.1555 - tp: 1788.0000 - fp: 69.0000 - tn: 5739.0000 - fn: 148.0000 - categorical_accuracy: 0.9370 - precision: 0.9628 - recall: 0.9236 - auc: 0.9952WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.129956). Check your callbacks.\n",
      "66/66 [==============================] - 2s 25ms/step - loss: 0.3915 - tp: 4788.0000 - fp: 914.0000 - tn: 17158.0000 - fn: 1236.0000 - categorical_accuracy: 0.8202 - precision: 0.8397 - recall: 0.7948 - auc: 0.9695 - val_loss: 0.3195 - val_tp: 1648.0000 - val_fp: 153.0000 - val_tn: 5271.0000 - val_fn: 160.0000 - val_categorical_accuracy: 0.9148 - val_precision: 0.9150 - val_recall: 0.9115 - val_auc: 0.9887 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3305 - tp: 3654.0000 - fp: 540.0000 - tn: 12108.0000 - fn: 562.0000 - categorical_accuracy: 0.8684 - precision: 0.8712 - recall: 0.8667 - auc: 0.9780 - val_loss: 0.2118 - val_tp: 1668.0000 - val_fp: 133.0000 - val_tn: 5291.0000 - val_fn: 140.0000 - val_categorical_accuracy: 0.9242 - val_precision: 0.9262 - val_recall: 0.9226 - val_auc: 0.9919 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2988 - tp: 3691.0000 - fp: 498.0000 - tn: 12150.0000 - fn: 525.0000 - categorical_accuracy: 0.8783 - precision: 0.8811 - recall: 0.8755 - auc: 0.9818 - val_loss: 0.2169 - val_tp: 1663.0000 - val_fp: 139.0000 - val_tn: 5285.0000 - val_fn: 145.0000 - val_categorical_accuracy: 0.9209 - val_precision: 0.9229 - val_recall: 0.9198 - val_auc: 0.9925 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2527 - tp: 3794.0000 - fp: 418.0000 - tn: 12230.0000 - fn: 422.0000 - categorical_accuracy: 0.9004 - precision: 0.9008 - recall: 0.8999 - auc: 0.9869 - val_loss: 0.2355 - val_tp: 1659.0000 - val_fp: 147.0000 - val_tn: 5277.0000 - val_fn: 149.0000 - val_categorical_accuracy: 0.9176 - val_precision: 0.9186 - val_recall: 0.9176 - val_auc: 0.9898 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2304 - tp: 3839.0000 - fp: 373.0000 - tn: 12275.0000 - fn: 377.0000 - categorical_accuracy: 0.9108 - precision: 0.9114 - recall: 0.9106 - auc: 0.9892 - val_loss: 0.1716 - val_tp: 1709.0000 - val_fp: 99.0000 - val_tn: 5325.0000 - val_fn: 99.0000 - val_categorical_accuracy: 0.9452 - val_precision: 0.9452 - val_recall: 0.9452 - val_auc: 0.9947 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2538 - tp: 3788.0000 - fp: 423.0000 - tn: 12225.0000 - fn: 428.0000 - categorical_accuracy: 0.8992 - precision: 0.8995 - recall: 0.8985 - auc: 0.9867 - val_loss: 0.1713 - val_tp: 1706.0000 - val_fp: 101.0000 - val_tn: 5323.0000 - val_fn: 102.0000 - val_categorical_accuracy: 0.9436 - val_precision: 0.9441 - val_recall: 0.9436 - val_auc: 0.9957 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2389 - tp: 3811.0000 - fp: 400.0000 - tn: 12248.0000 - fn: 405.0000 - categorical_accuracy: 0.9044 - precision: 0.9050 - recall: 0.9039 - auc: 0.9881 - val_loss: 0.1919 - val_tp: 1709.0000 - val_fp: 99.0000 - val_tn: 5325.0000 - val_fn: 99.0000 - val_categorical_accuracy: 0.9452 - val_precision: 0.9452 - val_recall: 0.9452 - val_auc: 0.9938 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2779 - tp: 3743.0000 - fp: 471.0000 - tn: 12177.0000 - fn: 473.0000 - categorical_accuracy: 0.8880 - precision: 0.8882 - recall: 0.8878 - auc: 0.9840 - val_loss: 0.1752 - val_tp: 1711.0000 - val_fp: 97.0000 - val_tn: 5327.0000 - val_fn: 97.0000 - val_categorical_accuracy: 0.9463 - val_precision: 0.9463 - val_recall: 0.9463 - val_auc: 0.9924 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2415 - tp: 3828.0000 - fp: 387.0000 - tn: 12261.0000 - fn: 388.0000 - categorical_accuracy: 0.9082 - precision: 0.9082 - recall: 0.9080 - auc: 0.9879 - val_loss: 0.1759 - val_tp: 1709.0000 - val_fp: 99.0000 - val_tn: 5325.0000 - val_fn: 99.0000 - val_categorical_accuracy: 0.9452 - val_precision: 0.9452 - val_recall: 0.9452 - val_auc: 0.9951 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2362 - tp: 3818.0000 - fp: 398.0000 - tn: 12250.0000 - fn: 398.0000 - categorical_accuracy: 0.9056 - precision: 0.9056 - recall: 0.9056 - auc: 0.9883 - val_loss: 0.1940 - val_tp: 1689.0000 - val_fp: 118.0000 - val_tn: 5306.0000 - val_fn: 119.0000 - val_categorical_accuracy: 0.9347 - val_precision: 0.9347 - val_recall: 0.9342 - val_auc: 0.9930 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2772 - tp: 3751.0000 - fp: 464.0000 - tn: 12184.0000 - fn: 465.0000 - categorical_accuracy: 0.8899 - precision: 0.8899 - recall: 0.8897 - auc: 0.9842 - val_loss: 0.1647 - val_tp: 1723.0000 - val_fp: 85.0000 - val_tn: 5339.0000 - val_fn: 85.0000 - val_categorical_accuracy: 0.9530 - val_precision: 0.9530 - val_recall: 0.9530 - val_auc: 0.9957 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2359 - tp: 3818.0000 - fp: 398.0000 - tn: 12250.0000 - fn: 398.0000 - categorical_accuracy: 0.9056 - precision: 0.9056 - recall: 0.9056 - auc: 0.9885 - val_loss: 0.1601 - val_tp: 1704.0000 - val_fp: 103.0000 - val_tn: 5321.0000 - val_fn: 104.0000 - val_categorical_accuracy: 0.9430 - val_precision: 0.9430 - val_recall: 0.9425 - val_auc: 0.9949 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2105 - tp: 3871.0000 - fp: 343.0000 - tn: 12305.0000 - fn: 345.0000 - categorical_accuracy: 0.9186 - precision: 0.9186 - recall: 0.9182 - auc: 0.9907 - val_loss: 0.1857 - val_tp: 1698.0000 - val_fp: 110.0000 - val_tn: 5314.0000 - val_fn: 110.0000 - val_categorical_accuracy: 0.9392 - val_precision: 0.9392 - val_recall: 0.9392 - val_auc: 0.9942 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2453 - tp: 3806.0000 - fp: 410.0000 - tn: 12238.0000 - fn: 410.0000 - categorical_accuracy: 0.9028 - precision: 0.9028 - recall: 0.9028 - auc: 0.9873 - val_loss: 0.1872 - val_tp: 1694.0000 - val_fp: 114.0000 - val_tn: 5310.0000 - val_fn: 114.0000 - val_categorical_accuracy: 0.9369 - val_precision: 0.9369 - val_recall: 0.9369 - val_auc: 0.9932 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2140 - tp: 3862.0000 - fp: 351.0000 - tn: 12297.0000 - fn: 354.0000 - categorical_accuracy: 0.9167 - precision: 0.9167 - recall: 0.9160 - auc: 0.9903 - val_loss: 0.2071 - val_tp: 1667.0000 - val_fp: 141.0000 - val_tn: 5283.0000 - val_fn: 141.0000 - val_categorical_accuracy: 0.9220 - val_precision: 0.9220 - val_recall: 0.9220 - val_auc: 0.9913 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2358 - tp: 3816.0000 - fp: 400.0000 - tn: 12248.0000 - fn: 400.0000 - categorical_accuracy: 0.9051 - precision: 0.9051 - recall: 0.9051 - auc: 0.9885 - val_loss: 0.1722 - val_tp: 1714.0000 - val_fp: 94.0000 - val_tn: 5330.0000 - val_fn: 94.0000 - val_categorical_accuracy: 0.9480 - val_precision: 0.9480 - val_recall: 0.9480 - val_auc: 0.9951 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2320 - tp: 3846.0000 - fp: 369.0000 - tn: 12279.0000 - fn: 370.0000 - categorical_accuracy: 0.9125 - precision: 0.9125 - recall: 0.9122 - auc: 0.9887 - val_loss: 0.2183 - val_tp: 1692.0000 - val_fp: 116.0000 - val_tn: 5308.0000 - val_fn: 116.0000 - val_categorical_accuracy: 0.9358 - val_precision: 0.9358 - val_recall: 0.9358 - val_auc: 0.9939 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2165 - tp: 3842.0000 - fp: 374.0000 - tn: 12274.0000 - fn: 374.0000 - categorical_accuracy: 0.9113 - precision: 0.9113 - recall: 0.9113 - auc: 0.9906 - val_loss: 0.1771 - val_tp: 1693.0000 - val_fp: 115.0000 - val_tn: 5309.0000 - val_fn: 115.0000 - val_categorical_accuracy: 0.9364 - val_precision: 0.9364 - val_recall: 0.9364 - val_auc: 0.9930 - lr: 0.0091\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2323 - tp: 3847.0000 - fp: 369.0000 - tn: 12279.0000 - fn: 369.0000 - categorical_accuracy: 0.9125 - precision: 0.9125 - recall: 0.9125 - auc: 0.9887 - val_loss: 0.1945 - val_tp: 1693.0000 - val_fp: 115.0000 - val_tn: 5309.0000 - val_fn: 115.0000 - val_categorical_accuracy: 0.9364 - val_precision: 0.9364 - val_recall: 0.9364 - val_auc: 0.9933 - lr: 0.0089\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2389 - tp: 3836.0000 - fp: 380.0000 - tn: 12268.0000 - fn: 380.0000 - categorical_accuracy: 0.9099 - precision: 0.9099 - recall: 0.9099 - auc: 0.9885 - val_loss: 0.1812 - val_tp: 1700.0000 - val_fp: 108.0000 - val_tn: 5316.0000 - val_fn: 108.0000 - val_categorical_accuracy: 0.9403 - val_precision: 0.9403 - val_recall: 0.9403 - val_auc: 0.9937 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1899 - tp: 3924.0000 - fp: 290.0000 - tn: 12358.0000 - fn: 292.0000 - categorical_accuracy: 0.9310 - precision: 0.9312 - recall: 0.9307 - auc: 0.9923 - val_loss: 0.1448 - val_tp: 1731.0000 - val_fp: 77.0000 - val_tn: 5347.0000 - val_fn: 77.0000 - val_categorical_accuracy: 0.9574 - val_precision: 0.9574 - val_recall: 0.9574 - val_auc: 0.9963 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2216 - tp: 3850.0000 - fp: 363.0000 - tn: 12285.0000 - fn: 366.0000 - categorical_accuracy: 0.9137 - precision: 0.9138 - recall: 0.9132 - auc: 0.9898 - val_loss: 0.1674 - val_tp: 1710.0000 - val_fp: 98.0000 - val_tn: 5326.0000 - val_fn: 98.0000 - val_categorical_accuracy: 0.9458 - val_precision: 0.9458 - val_recall: 0.9458 - val_auc: 0.9948 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1840 - tp: 3913.0000 - fp: 303.0000 - tn: 12345.0000 - fn: 303.0000 - categorical_accuracy: 0.9281 - precision: 0.9281 - recall: 0.9281 - auc: 0.9929 - val_loss: 0.1933 - val_tp: 1678.0000 - val_fp: 130.0000 - val_tn: 5294.0000 - val_fn: 130.0000 - val_categorical_accuracy: 0.9281 - val_precision: 0.9281 - val_recall: 0.9281 - val_auc: 0.9932 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2145 - tp: 3889.0000 - fp: 327.0000 - tn: 12321.0000 - fn: 327.0000 - categorical_accuracy: 0.9224 - precision: 0.9224 - recall: 0.9224 - auc: 0.9904 - val_loss: 0.1483 - val_tp: 1724.0000 - val_fp: 84.0000 - val_tn: 5340.0000 - val_fn: 84.0000 - val_categorical_accuracy: 0.9535 - val_precision: 0.9535 - val_recall: 0.9535 - val_auc: 0.9950 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1929 - tp: 3907.0000 - fp: 309.0000 - tn: 12339.0000 - fn: 309.0000 - categorical_accuracy: 0.9267 - precision: 0.9267 - recall: 0.9267 - auc: 0.9924 - val_loss: 0.1406 - val_tp: 1726.0000 - val_fp: 82.0000 - val_tn: 5342.0000 - val_fn: 82.0000 - val_categorical_accuracy: 0.9546 - val_precision: 0.9546 - val_recall: 0.9546 - val_auc: 0.9961 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1991 - tp: 3887.0000 - fp: 328.0000 - tn: 12320.0000 - fn: 329.0000 - categorical_accuracy: 0.9220 - precision: 0.9222 - recall: 0.9220 - auc: 0.9918 - val_loss: 0.1529 - val_tp: 1711.0000 - val_fp: 97.0000 - val_tn: 5327.0000 - val_fn: 97.0000 - val_categorical_accuracy: 0.9463 - val_precision: 0.9463 - val_recall: 0.9463 - val_auc: 0.9956 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1830 - tp: 3922.0000 - fp: 293.0000 - tn: 12355.0000 - fn: 294.0000 - categorical_accuracy: 0.9303 - precision: 0.9305 - recall: 0.9303 - auc: 0.9930 - val_loss: 0.1254 - val_tp: 1732.0000 - val_fp: 76.0000 - val_tn: 5348.0000 - val_fn: 76.0000 - val_categorical_accuracy: 0.9580 - val_precision: 0.9580 - val_recall: 0.9580 - val_auc: 0.9965 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2048 - tp: 3879.0000 - fp: 336.0000 - tn: 12312.0000 - fn: 337.0000 - categorical_accuracy: 0.9201 - precision: 0.9203 - recall: 0.9201 - auc: 0.9914 - val_loss: 0.1767 - val_tp: 1687.0000 - val_fp: 121.0000 - val_tn: 5303.0000 - val_fn: 121.0000 - val_categorical_accuracy: 0.9331 - val_precision: 0.9331 - val_recall: 0.9331 - val_auc: 0.9935 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1889 - tp: 3898.0000 - fp: 318.0000 - tn: 12330.0000 - fn: 318.0000 - categorical_accuracy: 0.9246 - precision: 0.9246 - recall: 0.9246 - auc: 0.9927 - val_loss: 0.1601 - val_tp: 1704.0000 - val_fp: 104.0000 - val_tn: 5320.0000 - val_fn: 104.0000 - val_categorical_accuracy: 0.9425 - val_precision: 0.9425 - val_recall: 0.9425 - val_auc: 0.9949 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1920 - tp: 3897.0000 - fp: 319.0000 - tn: 12329.0000 - fn: 319.0000 - categorical_accuracy: 0.9243 - precision: 0.9243 - recall: 0.9243 - auc: 0.9924 - val_loss: 0.1300 - val_tp: 1729.0000 - val_fp: 79.0000 - val_tn: 5345.0000 - val_fn: 79.0000 - val_categorical_accuracy: 0.9563 - val_precision: 0.9563 - val_recall: 0.9563 - val_auc: 0.9959 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2135 - tp: 3860.0000 - fp: 356.0000 - tn: 12292.0000 - fn: 356.0000 - categorical_accuracy: 0.9156 - precision: 0.9156 - recall: 0.9156 - auc: 0.9904 - val_loss: 0.1383 - val_tp: 1727.0000 - val_fp: 81.0000 - val_tn: 5343.0000 - val_fn: 81.0000 - val_categorical_accuracy: 0.9552 - val_precision: 0.9552 - val_recall: 0.9552 - val_auc: 0.9959 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1766 - tp: 3932.0000 - fp: 284.0000 - tn: 12364.0000 - fn: 284.0000 - categorical_accuracy: 0.9326 - precision: 0.9326 - recall: 0.9326 - auc: 0.9934 - val_loss: 0.1510 - val_tp: 1706.0000 - val_fp: 102.0000 - val_tn: 5322.0000 - val_fn: 102.0000 - val_categorical_accuracy: 0.9436 - val_precision: 0.9436 - val_recall: 0.9436 - val_auc: 0.9949 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2109 - tp: 3871.0000 - fp: 345.0000 - tn: 12303.0000 - fn: 345.0000 - categorical_accuracy: 0.9182 - precision: 0.9182 - recall: 0.9182 - auc: 0.9907 - val_loss: 0.1657 - val_tp: 1706.0000 - val_fp: 102.0000 - val_tn: 5322.0000 - val_fn: 102.0000 - val_categorical_accuracy: 0.9436 - val_precision: 0.9436 - val_recall: 0.9436 - val_auc: 0.9941 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1746 - tp: 3938.0000 - fp: 276.0000 - tn: 12372.0000 - fn: 278.0000 - categorical_accuracy: 0.9341 - precision: 0.9345 - recall: 0.9341 - auc: 0.9936 - val_loss: 0.1348 - val_tp: 1736.0000 - val_fp: 72.0000 - val_tn: 5352.0000 - val_fn: 72.0000 - val_categorical_accuracy: 0.9602 - val_precision: 0.9602 - val_recall: 0.9602 - val_auc: 0.9960 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1574 - tp: 3962.0000 - fp: 254.0000 - tn: 12394.0000 - fn: 254.0000 - categorical_accuracy: 0.9398 - precision: 0.9398 - recall: 0.9398 - auc: 0.9948 - val_loss: 0.1319 - val_tp: 1726.0000 - val_fp: 82.0000 - val_tn: 5342.0000 - val_fn: 82.0000 - val_categorical_accuracy: 0.9546 - val_precision: 0.9546 - val_recall: 0.9546 - val_auc: 0.9958 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1591 - tp: 3978.0000 - fp: 238.0000 - tn: 12410.0000 - fn: 238.0000 - categorical_accuracy: 0.9435 - precision: 0.9435 - recall: 0.9435 - auc: 0.9943 - val_loss: 0.1340 - val_tp: 1728.0000 - val_fp: 80.0000 - val_tn: 5344.0000 - val_fn: 80.0000 - val_categorical_accuracy: 0.9558 - val_precision: 0.9558 - val_recall: 0.9558 - val_auc: 0.9961 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1464 - tp: 3997.0000 - fp: 219.0000 - tn: 12429.0000 - fn: 219.0000 - categorical_accuracy: 0.9481 - precision: 0.9481 - recall: 0.9481 - auc: 0.9954 - val_loss: 0.1472 - val_tp: 1717.0000 - val_fp: 91.0000 - val_tn: 5333.0000 - val_fn: 91.0000 - val_categorical_accuracy: 0.9497 - val_precision: 0.9497 - val_recall: 0.9497 - val_auc: 0.9950 - lr: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1560 - tp: 3982.0000 - fp: 234.0000 - tn: 12414.0000 - fn: 234.0000 - categorical_accuracy: 0.9445 - precision: 0.9445 - recall: 0.9445 - auc: 0.9947 - val_loss: 0.1443 - val_tp: 1729.0000 - val_fp: 79.0000 - val_tn: 5345.0000 - val_fn: 79.0000 - val_categorical_accuracy: 0.9563 - val_precision: 0.9563 - val_recall: 0.9563 - val_auc: 0.9947 - lr: 0.0053\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1367 - tp: 4008.0000 - fp: 208.0000 - tn: 12440.0000 - fn: 208.0000 - categorical_accuracy: 0.9507 - precision: 0.9507 - recall: 0.9507 - auc: 0.9959 - val_loss: 0.1941 - val_tp: 1674.0000 - val_fp: 133.0000 - val_tn: 5291.0000 - val_fn: 134.0000 - val_categorical_accuracy: 0.9264 - val_precision: 0.9264 - val_recall: 0.9259 - val_auc: 0.9918 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1560 - tp: 3988.0000 - fp: 228.0000 - tn: 12420.0000 - fn: 228.0000 - categorical_accuracy: 0.9459 - precision: 0.9459 - recall: 0.9459 - auc: 0.9944 - val_loss: 0.1516 - val_tp: 1718.0000 - val_fp: 90.0000 - val_tn: 5334.0000 - val_fn: 90.0000 - val_categorical_accuracy: 0.9502 - val_precision: 0.9502 - val_recall: 0.9502 - val_auc: 0.9944 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1338 - tp: 4026.0000 - fp: 190.0000 - tn: 12458.0000 - fn: 190.0000 - categorical_accuracy: 0.9549 - precision: 0.9549 - recall: 0.9549 - auc: 0.9959 - val_loss: 0.1256 - val_tp: 1733.0000 - val_fp: 75.0000 - val_tn: 5349.0000 - val_fn: 75.0000 - val_categorical_accuracy: 0.9585 - val_precision: 0.9585 - val_recall: 0.9585 - val_auc: 0.9958 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1364 - tp: 4006.0000 - fp: 210.0000 - tn: 12438.0000 - fn: 210.0000 - categorical_accuracy: 0.9502 - precision: 0.9502 - recall: 0.9502 - auc: 0.9958 - val_loss: 0.1087 - val_tp: 1752.0000 - val_fp: 56.0000 - val_tn: 5368.0000 - val_fn: 56.0000 - val_categorical_accuracy: 0.9690 - val_precision: 0.9690 - val_recall: 0.9690 - val_auc: 0.9967 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1425 - tp: 3995.0000 - fp: 220.0000 - tn: 12428.0000 - fn: 221.0000 - categorical_accuracy: 0.9478 - precision: 0.9478 - recall: 0.9476 - auc: 0.9955 - val_loss: 0.1152 - val_tp: 1743.0000 - val_fp: 65.0000 - val_tn: 5359.0000 - val_fn: 65.0000 - val_categorical_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_auc: 0.9962 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1457 - tp: 3999.0000 - fp: 217.0000 - tn: 12431.0000 - fn: 217.0000 - categorical_accuracy: 0.9485 - precision: 0.9485 - recall: 0.9485 - auc: 0.9951 - val_loss: 0.1362 - val_tp: 1736.0000 - val_fp: 72.0000 - val_tn: 5352.0000 - val_fn: 72.0000 - val_categorical_accuracy: 0.9602 - val_precision: 0.9602 - val_recall: 0.9602 - val_auc: 0.9954 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1333 - tp: 3998.0000 - fp: 218.0000 - tn: 12430.0000 - fn: 218.0000 - categorical_accuracy: 0.9483 - precision: 0.9483 - recall: 0.9483 - auc: 0.9963 - val_loss: 0.1015 - val_tp: 1745.0000 - val_fp: 63.0000 - val_tn: 5361.0000 - val_fn: 63.0000 - val_categorical_accuracy: 0.9652 - val_precision: 0.9652 - val_recall: 0.9652 - val_auc: 0.9968 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1225 - tp: 4031.0000 - fp: 184.0000 - tn: 12464.0000 - fn: 185.0000 - categorical_accuracy: 0.9564 - precision: 0.9563 - recall: 0.9561 - auc: 0.9966 - val_loss: 0.1399 - val_tp: 1725.0000 - val_fp: 83.0000 - val_tn: 5341.0000 - val_fn: 83.0000 - val_categorical_accuracy: 0.9541 - val_precision: 0.9541 - val_recall: 0.9541 - val_auc: 0.9947 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1198 - tp: 4021.0000 - fp: 195.0000 - tn: 12453.0000 - fn: 195.0000 - categorical_accuracy: 0.9537 - precision: 0.9537 - recall: 0.9537 - auc: 0.9970 - val_loss: 0.1278 - val_tp: 1740.0000 - val_fp: 68.0000 - val_tn: 5356.0000 - val_fn: 68.0000 - val_categorical_accuracy: 0.9624 - val_precision: 0.9624 - val_recall: 0.9624 - val_auc: 0.9952 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1245 - tp: 4019.0000 - fp: 197.0000 - tn: 12451.0000 - fn: 197.0000 - categorical_accuracy: 0.9533 - precision: 0.9533 - recall: 0.9533 - auc: 0.9966 - val_loss: 0.1263 - val_tp: 1734.0000 - val_fp: 74.0000 - val_tn: 5350.0000 - val_fn: 74.0000 - val_categorical_accuracy: 0.9591 - val_precision: 0.9591 - val_recall: 0.9591 - val_auc: 0.9958 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1098 - tp: 4044.0000 - fp: 172.0000 - tn: 12476.0000 - fn: 172.0000 - categorical_accuracy: 0.9592 - precision: 0.9592 - recall: 0.9592 - auc: 0.9971 - val_loss: 0.1222 - val_tp: 1739.0000 - val_fp: 69.0000 - val_tn: 5355.0000 - val_fn: 69.0000 - val_categorical_accuracy: 0.9618 - val_precision: 0.9618 - val_recall: 0.9618 - val_auc: 0.9954 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1327 - tp: 4009.0000 - fp: 207.0000 - tn: 12441.0000 - fn: 207.0000 - categorical_accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - auc: 0.9962 - val_loss: 0.1200 - val_tp: 1747.0000 - val_fp: 60.0000 - val_tn: 5364.0000 - val_fn: 61.0000 - val_categorical_accuracy: 0.9668 - val_precision: 0.9668 - val_recall: 0.9663 - val_auc: 0.9962 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1415 - tp: 3995.0000 - fp: 221.0000 - tn: 12427.0000 - fn: 221.0000 - categorical_accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - auc: 0.9952 - val_loss: 0.1477 - val_tp: 1721.0000 - val_fp: 87.0000 - val_tn: 5337.0000 - val_fn: 87.0000 - val_categorical_accuracy: 0.9519 - val_precision: 0.9519 - val_recall: 0.9519 - val_auc: 0.9946 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1321 - tp: 4024.0000 - fp: 192.0000 - tn: 12456.0000 - fn: 192.0000 - categorical_accuracy: 0.9545 - precision: 0.9545 - recall: 0.9545 - auc: 0.9960 - val_loss: 0.1339 - val_tp: 1726.0000 - val_fp: 82.0000 - val_tn: 5342.0000 - val_fn: 82.0000 - val_categorical_accuracy: 0.9546 - val_precision: 0.9546 - val_recall: 0.9546 - val_auc: 0.9954 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1195 - tp: 4036.0000 - fp: 180.0000 - tn: 12468.0000 - fn: 180.0000 - categorical_accuracy: 0.9573 - precision: 0.9573 - recall: 0.9573 - auc: 0.9966 - val_loss: 0.1153 - val_tp: 1746.0000 - val_fp: 62.0000 - val_tn: 5362.0000 - val_fn: 62.0000 - val_categorical_accuracy: 0.9657 - val_precision: 0.9657 - val_recall: 0.9657 - val_auc: 0.9964 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1183 - tp: 4045.0000 - fp: 171.0000 - tn: 12477.0000 - fn: 171.0000 - categorical_accuracy: 0.9594 - precision: 0.9594 - recall: 0.9594 - auc: 0.9966 - val_loss: 0.1209 - val_tp: 1737.0000 - val_fp: 71.0000 - val_tn: 5353.0000 - val_fn: 71.0000 - val_categorical_accuracy: 0.9607 - val_precision: 0.9607 - val_recall: 0.9607 - val_auc: 0.9964 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1112 - tp: 4041.0000 - fp: 175.0000 - tn: 12473.0000 - fn: 175.0000 - categorical_accuracy: 0.9585 - precision: 0.9585 - recall: 0.9585 - auc: 0.9972 - val_loss: 0.1122 - val_tp: 1739.0000 - val_fp: 69.0000 - val_tn: 5355.0000 - val_fn: 69.0000 - val_categorical_accuracy: 0.9618 - val_precision: 0.9618 - val_recall: 0.9618 - val_auc: 0.9969 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0971 - tp: 4066.0000 - fp: 150.0000 - tn: 12498.0000 - fn: 150.0000 - categorical_accuracy: 0.9644 - precision: 0.9644 - recall: 0.9644 - auc: 0.9977 - val_loss: 0.1032 - val_tp: 1750.0000 - val_fp: 58.0000 - val_tn: 5366.0000 - val_fn: 58.0000 - val_categorical_accuracy: 0.9679 - val_precision: 0.9679 - val_recall: 0.9679 - val_auc: 0.9970 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1066 - tp: 4065.0000 - fp: 151.0000 - tn: 12497.0000 - fn: 151.0000 - categorical_accuracy: 0.9642 - precision: 0.9642 - recall: 0.9642 - auc: 0.9967 - val_loss: 0.1391 - val_tp: 1723.0000 - val_fp: 85.0000 - val_tn: 5339.0000 - val_fn: 85.0000 - val_categorical_accuracy: 0.9530 - val_precision: 0.9530 - val_recall: 0.9530 - val_auc: 0.9949 - lr: 0.0022\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1301 - tp: 4012.0000 - fp: 204.0000 - tn: 12444.0000 - fn: 204.0000 - categorical_accuracy: 0.9516 - precision: 0.9516 - recall: 0.9516 - auc: 0.9964 - val_loss: 0.1134 - val_tp: 1745.0000 - val_fp: 63.0000 - val_tn: 5361.0000 - val_fn: 63.0000 - val_categorical_accuracy: 0.9652 - val_precision: 0.9652 - val_recall: 0.9652 - val_auc: 0.9963 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0841 - tp: 4088.0000 - fp: 128.0000 - tn: 12520.0000 - fn: 128.0000 - categorical_accuracy: 0.9696 - precision: 0.9696 - recall: 0.9696 - auc: 0.9985 - val_loss: 0.0971 - val_tp: 1753.0000 - val_fp: 55.0000 - val_tn: 5369.0000 - val_fn: 55.0000 - val_categorical_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_auc: 0.9967 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1073 - tp: 4060.0000 - fp: 156.0000 - tn: 12492.0000 - fn: 156.0000 - categorical_accuracy: 0.9630 - precision: 0.9630 - recall: 0.9630 - auc: 0.9972 - val_loss: 0.1240 - val_tp: 1736.0000 - val_fp: 72.0000 - val_tn: 5352.0000 - val_fn: 72.0000 - val_categorical_accuracy: 0.9602 - val_precision: 0.9602 - val_recall: 0.9602 - val_auc: 0.9961 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1011 - tp: 4066.0000 - fp: 150.0000 - tn: 12498.0000 - fn: 150.0000 - categorical_accuracy: 0.9644 - precision: 0.9644 - recall: 0.9644 - auc: 0.9977 - val_loss: 0.1072 - val_tp: 1746.0000 - val_fp: 62.0000 - val_tn: 5362.0000 - val_fn: 62.0000 - val_categorical_accuracy: 0.9657 - val_precision: 0.9657 - val_recall: 0.9657 - val_auc: 0.9969 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1030 - tp: 4061.0000 - fp: 155.0000 - tn: 12493.0000 - fn: 155.0000 - categorical_accuracy: 0.9632 - precision: 0.9632 - recall: 0.9632 - auc: 0.9975 - val_loss: 0.1210 - val_tp: 1737.0000 - val_fp: 71.0000 - val_tn: 5353.0000 - val_fn: 71.0000 - val_categorical_accuracy: 0.9607 - val_precision: 0.9607 - val_recall: 0.9607 - val_auc: 0.9963 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0958 - tp: 4074.0000 - fp: 142.0000 - tn: 12506.0000 - fn: 142.0000 - categorical_accuracy: 0.9663 - precision: 0.9663 - recall: 0.9663 - auc: 0.9980 - val_loss: 0.0981 - val_tp: 1754.0000 - val_fp: 54.0000 - val_tn: 5370.0000 - val_fn: 54.0000 - val_categorical_accuracy: 0.9701 - val_precision: 0.9701 - val_recall: 0.9701 - val_auc: 0.9974 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0904 - tp: 4073.0000 - fp: 143.0000 - tn: 12505.0000 - fn: 143.0000 - categorical_accuracy: 0.9661 - precision: 0.9661 - recall: 0.9661 - auc: 0.9981 - val_loss: 0.1047 - val_tp: 1750.0000 - val_fp: 58.0000 - val_tn: 5366.0000 - val_fn: 58.0000 - val_categorical_accuracy: 0.9679 - val_precision: 0.9679 - val_recall: 0.9679 - val_auc: 0.9970 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0913 - tp: 4086.0000 - fp: 130.0000 - tn: 12518.0000 - fn: 130.0000 - categorical_accuracy: 0.9692 - precision: 0.9692 - recall: 0.9692 - auc: 0.9980 - val_loss: 0.1036 - val_tp: 1749.0000 - val_fp: 59.0000 - val_tn: 5365.0000 - val_fn: 59.0000 - val_categorical_accuracy: 0.9674 - val_precision: 0.9674 - val_recall: 0.9674 - val_auc: 0.9969 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0793 - tp: 4095.0000 - fp: 121.0000 - tn: 12527.0000 - fn: 121.0000 - categorical_accuracy: 0.9713 - precision: 0.9713 - recall: 0.9713 - auc: 0.9987 - val_loss: 0.1074 - val_tp: 1743.0000 - val_fp: 65.0000 - val_tn: 5359.0000 - val_fn: 65.0000 - val_categorical_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_auc: 0.9970 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0893 - tp: 4085.0000 - fp: 131.0000 - tn: 12517.0000 - fn: 131.0000 - categorical_accuracy: 0.9689 - precision: 0.9689 - recall: 0.9689 - auc: 0.9981 - val_loss: 0.1026 - val_tp: 1751.0000 - val_fp: 57.0000 - val_tn: 5367.0000 - val_fn: 57.0000 - val_categorical_accuracy: 0.9685 - val_precision: 0.9685 - val_recall: 0.9685 - val_auc: 0.9970 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0738 - tp: 4108.0000 - fp: 108.0000 - tn: 12540.0000 - fn: 108.0000 - categorical_accuracy: 0.9744 - precision: 0.9744 - recall: 0.9744 - auc: 0.9987 - val_loss: 0.0959 - val_tp: 1755.0000 - val_fp: 53.0000 - val_tn: 5371.0000 - val_fn: 53.0000 - val_categorical_accuracy: 0.9707 - val_precision: 0.9707 - val_recall: 0.9707 - val_auc: 0.9975 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0720 - tp: 4116.0000 - fp: 100.0000 - tn: 12548.0000 - fn: 100.0000 - categorical_accuracy: 0.9763 - precision: 0.9763 - recall: 0.9763 - auc: 0.9984 - val_loss: 0.0883 - val_tp: 1757.0000 - val_fp: 51.0000 - val_tn: 5373.0000 - val_fn: 51.0000 - val_categorical_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_auc: 0.9977 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0839 - tp: 4092.0000 - fp: 123.0000 - tn: 12525.0000 - fn: 124.0000 - categorical_accuracy: 0.9708 - precision: 0.9708 - recall: 0.9706 - auc: 0.9980 - val_loss: 0.0848 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9974 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0669 - tp: 4127.0000 - fp: 89.0000 - tn: 12559.0000 - fn: 89.0000 - categorical_accuracy: 0.9789 - precision: 0.9789 - recall: 0.9789 - auc: 0.9985 - val_loss: 0.0877 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9978 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0724 - tp: 4103.0000 - fp: 113.0000 - tn: 12535.0000 - fn: 113.0000 - categorical_accuracy: 0.9732 - precision: 0.9732 - recall: 0.9732 - auc: 0.9988 - val_loss: 0.0939 - val_tp: 1754.0000 - val_fp: 54.0000 - val_tn: 5370.0000 - val_fn: 54.0000 - val_categorical_accuracy: 0.9701 - val_precision: 0.9701 - val_recall: 0.9701 - val_auc: 0.9975 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0797 - tp: 4091.0000 - fp: 125.0000 - tn: 12523.0000 - fn: 125.0000 - categorical_accuracy: 0.9704 - precision: 0.9704 - recall: 0.9704 - auc: 0.9984 - val_loss: 0.0907 - val_tp: 1756.0000 - val_fp: 52.0000 - val_tn: 5372.0000 - val_fn: 52.0000 - val_categorical_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_auc: 0.9976 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0720 - tp: 4111.0000 - fp: 105.0000 - tn: 12543.0000 - fn: 105.0000 - categorical_accuracy: 0.9751 - precision: 0.9751 - recall: 0.9751 - auc: 0.9987 - val_loss: 0.0904 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9978 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0738 - tp: 4112.0000 - fp: 104.0000 - tn: 12544.0000 - fn: 104.0000 - categorical_accuracy: 0.9753 - precision: 0.9753 - recall: 0.9753 - auc: 0.9983 - val_loss: 0.0870 - val_tp: 1760.0000 - val_fp: 48.0000 - val_tn: 5376.0000 - val_fn: 48.0000 - val_categorical_accuracy: 0.9735 - val_precision: 0.9735 - val_recall: 0.9735 - val_auc: 0.9978 - lr: 7.0388e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0751 - tp: 4110.0000 - fp: 106.0000 - tn: 12542.0000 - fn: 106.0000 - categorical_accuracy: 0.9749 - precision: 0.9749 - recall: 0.9749 - auc: 0.9981 - val_loss: 0.0935 - val_tp: 1752.0000 - val_fp: 56.0000 - val_tn: 5368.0000 - val_fn: 56.0000 - val_categorical_accuracy: 0.9690 - val_precision: 0.9690 - val_recall: 0.9690 - val_auc: 0.9977 - lr: 6.5477e-04\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0753 - tp: 4120.0000 - fp: 96.0000 - tn: 12552.0000 - fn: 96.0000 - categorical_accuracy: 0.9772 - precision: 0.9772 - recall: 0.9772 - auc: 0.9984 - val_loss: 0.0921 - val_tp: 1753.0000 - val_fp: 54.0000 - val_tn: 5370.0000 - val_fn: 55.0000 - val_categorical_accuracy: 0.9701 - val_precision: 0.9701 - val_recall: 0.9696 - val_auc: 0.9976 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0684 - tp: 4115.0000 - fp: 101.0000 - tn: 12547.0000 - fn: 101.0000 - categorical_accuracy: 0.9760 - precision: 0.9760 - recall: 0.9760 - auc: 0.9987 - val_loss: 0.0959 - val_tp: 1754.0000 - val_fp: 54.0000 - val_tn: 5370.0000 - val_fn: 54.0000 - val_categorical_accuracy: 0.9701 - val_precision: 0.9701 - val_recall: 0.9701 - val_auc: 0.9975 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0744 - tp: 4111.0000 - fp: 105.0000 - tn: 12543.0000 - fn: 105.0000 - categorical_accuracy: 0.9751 - precision: 0.9751 - recall: 0.9751 - auc: 0.9984 - val_loss: 0.0878 - val_tp: 1761.0000 - val_fp: 47.0000 - val_tn: 5377.0000 - val_fn: 47.0000 - val_categorical_accuracy: 0.9740 - val_precision: 0.9740 - val_recall: 0.9740 - val_auc: 0.9978 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0559 - tp: 4134.0000 - fp: 82.0000 - tn: 12566.0000 - fn: 82.0000 - categorical_accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - auc: 0.9992 - val_loss: 0.0857 - val_tp: 1760.0000 - val_fp: 48.0000 - val_tn: 5376.0000 - val_fn: 48.0000 - val_categorical_accuracy: 0.9735 - val_precision: 0.9735 - val_recall: 0.9735 - val_auc: 0.9979 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.0646 - tp: 4120.0000 - fp: 96.0000 - tn: 12552.0000 - fn: 96.0000 - categorical_accuracy: 0.9772 - precision: 0.9772 - recall: 0.9772 - auc: 0.9989 - val_loss: 0.0838 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9978 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0527 - tp: 4147.0000 - fp: 69.0000 - tn: 12579.0000 - fn: 69.0000 - categorical_accuracy: 0.9836 - precision: 0.9836 - recall: 0.9836 - auc: 0.9991 - val_loss: 0.0880 - val_tp: 1759.0000 - val_fp: 49.0000 - val_tn: 5375.0000 - val_fn: 49.0000 - val_categorical_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9979 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0605 - tp: 4125.0000 - fp: 91.0000 - tn: 12557.0000 - fn: 91.0000 - categorical_accuracy: 0.9784 - precision: 0.9784 - recall: 0.9784 - auc: 0.9989 - val_loss: 0.0868 - val_tp: 1766.0000 - val_fp: 42.0000 - val_tn: 5382.0000 - val_fn: 42.0000 - val_categorical_accuracy: 0.9768 - val_precision: 0.9768 - val_recall: 0.9768 - val_auc: 0.9978 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0539 - tp: 4141.0000 - fp: 75.0000 - tn: 12573.0000 - fn: 75.0000 - categorical_accuracy: 0.9822 - precision: 0.9822 - recall: 0.9822 - auc: 0.9993 - val_loss: 0.0859 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9980 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0525 - tp: 4144.0000 - fp: 72.0000 - tn: 12576.0000 - fn: 72.0000 - categorical_accuracy: 0.9829 - precision: 0.9829 - recall: 0.9829 - auc: 0.9992 - val_loss: 0.0894 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9978 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0625 - tp: 4121.0000 - fp: 95.0000 - tn: 12553.0000 - fn: 95.0000 - categorical_accuracy: 0.9775 - precision: 0.9775 - recall: 0.9775 - auc: 0.9988 - val_loss: 0.0859 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9980 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0585 - tp: 4136.0000 - fp: 80.0000 - tn: 12568.0000 - fn: 80.0000 - categorical_accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9989 - val_loss: 0.0839 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9980 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0671 - tp: 4122.0000 - fp: 94.0000 - tn: 12554.0000 - fn: 94.0000 - categorical_accuracy: 0.9777 - precision: 0.9777 - recall: 0.9777 - auc: 0.9985 - val_loss: 0.0869 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9980 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0523 - tp: 4147.0000 - fp: 69.0000 - tn: 12579.0000 - fn: 69.0000 - categorical_accuracy: 0.9836 - precision: 0.9836 - recall: 0.9836 - auc: 0.9991 - val_loss: 0.0878 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9979 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0534 - tp: 4140.0000 - fp: 75.0000 - tn: 12573.0000 - fn: 76.0000 - categorical_accuracy: 0.9820 - precision: 0.9822 - recall: 0.9820 - auc: 0.9994 - val_loss: 0.0877 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9980 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0550 - tp: 4146.0000 - fp: 70.0000 - tn: 12578.0000 - fn: 70.0000 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9834 - auc: 0.9988 - val_loss: 0.0855 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9981 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0627 - tp: 4137.0000 - fp: 79.0000 - tn: 12569.0000 - fn: 79.0000 - categorical_accuracy: 0.9813 - precision: 0.9813 - recall: 0.9813 - auc: 0.9988 - val_loss: 0.0864 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9981 - lr: 1.8151e-04\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0521 - tp: 4145.0000 - fp: 71.0000 - tn: 12577.0000 - fn: 71.0000 - categorical_accuracy: 0.9832 - precision: 0.9832 - recall: 0.9832 - auc: 0.9993 - val_loss: 0.0875 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9980 - lr: 1.6621e-04\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0497 - tp: 4156.0000 - fp: 60.0000 - tn: 12588.0000 - fn: 60.0000 - categorical_accuracy: 0.9858 - precision: 0.9858 - recall: 0.9858 - auc: 0.9992 - val_loss: 0.0874 - val_tp: 1763.0000 - val_fp: 45.0000 - val_tn: 5379.0000 - val_fn: 45.0000 - val_categorical_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9751 - val_auc: 0.9980 - lr: 1.5207e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0537 - tp: 4139.0000 - fp: 77.0000 - tn: 12571.0000 - fn: 77.0000 - categorical_accuracy: 0.9817 - precision: 0.9817 - recall: 0.9817 - auc: 0.9993 - val_loss: 0.0880 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9980 - lr: 1.3900e-04\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0513 - tp: 4150.0000 - fp: 66.0000 - tn: 12582.0000 - fn: 66.0000 - categorical_accuracy: 0.9843 - precision: 0.9843 - recall: 0.9843 - auc: 0.9994 - val_loss: 0.0883 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9980 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0527 - tp: 4146.0000 - fp: 70.0000 - tn: 12578.0000 - fn: 70.0000 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9834 - auc: 0.9992 - val_loss: 0.0869 - val_tp: 1765.0000 - val_fp: 43.0000 - val_tn: 5381.0000 - val_fn: 43.0000 - val_categorical_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_auc: 0.9980 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0491 - tp: 4145.0000 - fp: 71.0000 - tn: 12577.0000 - fn: 71.0000 - categorical_accuracy: 0.9832 - precision: 0.9832 - recall: 0.9832 - auc: 0.9995 - val_loss: 0.0885 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9980 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0488 - tp: 4148.0000 - fp: 68.0000 - tn: 12580.0000 - fn: 68.0000 - categorical_accuracy: 0.9839 - precision: 0.9839 - recall: 0.9839 - auc: 0.9994 - val_loss: 0.0882 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9980 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.0504 - tp: 4148.0000 - fp: 68.0000 - tn: 12580.0000 - fn: 68.0000 - categorical_accuracy: 0.9839 - precision: 0.9839 - recall: 0.9839 - auc: 0.9991 - val_loss: 0.0889 - val_tp: 1764.0000 - val_fp: 44.0000 - val_tn: 5380.0000 - val_fn: 44.0000 - val_categorical_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_auc: 0.9979 - lr: 8.7498e-05\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0527 - tp: 1489.0000 - fp: 17.0000 - tn: 4501.0000 - fn: 17.0000 - categorical_accuracy: 0.9887 - precision: 0.9887 - recall: 0.9887 - auc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05269</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4501.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.99938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss      tp    fp      tn    fn  accuracy  precision    recall      auc\n",
       "0  0.05269  1489.0  17.0  4501.0  17.0  0.988712   0.988712  0.988712  0.99938"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SELECTED_CLASSES = [\"Apnea\", \"Resting\"]\n",
    "WHICH_DATA = \"radar\" # can be \"contact\" or \"radar\"\n",
    "WHICH_MODEL = \"fully_connected_small\"\n",
    "results_radar_2class = helper_functions.train_test_experiment(which_data=WHICH_DATA, which_model=WHICH_MODEL, hyperparams=HYPERPARAMS, metrics=METRICS, class_map=CLASS_MAP, selected_classes=SELECTED_CLASSES)\n",
    "display(results_radar_2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 342706), started 0:29:30 ago. (Use '!kill 342706' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9a2eba5118dd56c2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9a2eba5118dd56c2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tensorboard for visualisation, use jupyter magic to run it based on things saved during training\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir model_training_logs/radar_train_test/ --host localhost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
