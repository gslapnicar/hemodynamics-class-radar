{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Importing Jupyter notebook from helper_functions.ipynb\n",
      "Importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import gc\n",
    "import nbimporter\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import optimizers, regularizers\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "print(\"Available GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "import helper_functions as helper_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning\n",
    "Create some baseline ANNs for classification of the scenarios. Consider different inputs (contact, contact-free, both) and compare results.\n",
    "\n",
    "Initially a **fully connected multi-branch ANN** is designed, separate for contact and radar inputs. We consider a **classification problem**, where target is the scenario with **6 possible class values (Resting, Valsalva, Apnea, TiltUp, TiltDown, Other)**.\n",
    "\n",
    "Output was one-hot encoded, categorical cross-entropy used as loss, accuracy as metric. Dropout layers are added for generalization. Adam optimizer was used, and other hyperparameters are currently randomly selected based on feeling (hyperparameter optimization pending)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some (hyper)parameters needed for the training are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make some of these a dict and add hyperparam optimization\n",
    "HYPERPARAMS = {\n",
    "    \"N_CLASSES\"      : 6,\n",
    "    \"DENSE_LAYERS\"   : 3,\n",
    "    \"REGULARIZER\"    : \"l1\",\n",
    "    \"N_UNITS\"        : 128,\n",
    "    \"N_FILTERS\"      : 128,\n",
    "    \"KERNEL_SIZE\"    : 8,\n",
    "    \"Fs\"             : 64,\n",
    "    \"OPTIMIZER\"      : \"adam\",\n",
    "    \"ACTIVATION\"     : \"relu\",\n",
    "    \"LAST_ACTIVATION\": \"softmax\",\n",
    "    \"TRAIN_AMNT\" : 0.8,\n",
    "    \"BATCH_SIZE\" : 128,\n",
    "    \"N_EPOCHS\"   : 100,\n",
    "    \"LR\"         : 0.01,\n",
    "    \"DROPOUT\"    : 0.3,\n",
    "    \"REGULAR\"    : 0.001,\n",
    "    \"VALIDATION\" : 0.2,\n",
    "    \"VERBOSE\"    : 1,\n",
    "    \"N_FOLDS\"    : 5,\n",
    "    \"SHUFFLE\"    : True,\n",
    "    \"STANDARD\"   : True,\n",
    "    \"OVERSAMPLE\" : True,\n",
    "    \"FFT_ONLY\"   : False,\n",
    "    \"ADD_FFT\"    : False,\n",
    "    \"RUN_ID\"     : datetime.datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "}\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.CategoricalCrossentropy(name=\"loss\"),\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\"),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "    \n",
    "CLASS_MAP = {\n",
    "    \"Other\":    0,\n",
    "    \"Resting\":  1,\n",
    "    \"Valsalva\": 2,\n",
    "    \"Apnea\":    3,\n",
    "    \"TiltUp\":   4,\n",
    "    \"TiltDown\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run k-fold CV experiment for contact sensors [6 classes]\n",
    "\n",
    "The cell below is the equivalent of *main* function. It clears old logs and backend, reads stacked all subject data and feeds it to the models. 70% of data is taken for training, 30% of data is considered for validation, coming from the n-1 folds. The final fold is used for testing.\n",
    "\n",
    "Callbacks are added that save the model after each epoch and logs for TensorBoard (visualisation) are saved.\n",
    "\n",
    "### Attention: \n",
    "\n",
    "If you are running this on GPU, you might want to consider removing callbacks! Those take the majority of time (writing tons of things to disk)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (13312, 1280, 6) (13312,)\n",
      "Oversampling signal 0\n",
      "Oversampling signal 1\n",
      "Oversampling signal 2\n",
      "Oversampling signal 3\n",
      "Oversampling signal 4\n",
      "Oversampling signal 5\n",
      "Shapes after oversampling: (28650, 1280, 6) (28650,)\n",
      "Number of splits: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== FOLD: 0 ======================\n",
      "Train: [  955   956   957 ... 28647 28648 28649]\n",
      "Test: [    0     1     2 ... 24827 24828 24829]\n",
      "Intersection: []\n",
      "TRAIN: [  955   956   957 ... 28647 28648 28649] TEST: [    0     1     2 ... 24827 24828 24829]\n",
      "Train shapes: (22920, 1280, 6) (22920,) Test shapes: (5730, 1280, 6) (5730,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_contact_bp (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_ecg1 (InputLayer) [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_ecg2 (InputLayer) [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_icg (InputLayer)  [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_resp (InputLayer) [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_contact_z0 (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           40992       input_contact_bp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           40992       input_contact_ecg1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           40992       input_contact_ecg2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           40992       input_contact_icg[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           40992       input_contact_resp[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           40992       input_contact_z0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           272         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 56)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1824        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 252,526\n",
      "Trainable params: 252,526\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 1.6724 - tp: 597.0000 - fp: 406.0000 - tn: 91274.0000 - fn: 17739.0000 - categorical_accuracy: 0.2750 - precision: 0.5952 - recall: 0.0326 - auc: 0.6607 - val_loss: 1.4173 - val_tp: 519.0000 - val_fp: 119.0000 - val_tn: 22801.0000 - val_fn: 4065.0000 - val_categorical_accuracy: 0.3667 - val_precision: 0.8135 - val_recall: 0.1132 - val_auc: 0.7757 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3999 - tp: 2909.0000 - fp: 1136.0000 - tn: 90544.0000 - fn: 15427.0000 - categorical_accuracy: 0.4058 - precision: 0.7192 - recall: 0.1586 - auc: 0.7846 - val_loss: 1.2215 - val_tp: 1035.0000 - val_fp: 190.0000 - val_tn: 22730.0000 - val_fn: 3549.0000 - val_categorical_accuracy: 0.4959 - val_precision: 0.8449 - val_recall: 0.2258 - val_auc: 0.8472 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3017 - tp: 3821.0000 - fp: 1120.0000 - tn: 90560.0000 - fn: 14515.0000 - categorical_accuracy: 0.4554 - precision: 0.7733 - recall: 0.2084 - auc: 0.8172 - val_loss: 1.1190 - val_tp: 1155.0000 - val_fp: 126.0000 - val_tn: 22794.0000 - val_fn: 3429.0000 - val_categorical_accuracy: 0.5375 - val_precision: 0.9016 - val_recall: 0.2520 - val_auc: 0.8710 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2241 - tp: 4274.0000 - fp: 1057.0000 - tn: 90623.0000 - fn: 14062.0000 - categorical_accuracy: 0.4867 - precision: 0.8017 - recall: 0.2331 - auc: 0.8403 - val_loss: 1.0627 - val_tp: 1182.0000 - val_fp: 99.0000 - val_tn: 22821.0000 - val_fn: 3402.0000 - val_categorical_accuracy: 0.5639 - val_precision: 0.9227 - val_recall: 0.2579 - val_auc: 0.8888 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1627 - tp: 5145.0000 - fp: 1577.0000 - tn: 90103.0000 - fn: 13191.0000 - categorical_accuracy: 0.5176 - precision: 0.7654 - recall: 0.2806 - auc: 0.8585 - val_loss: 1.0318 - val_tp: 1496.0000 - val_fp: 219.0000 - val_tn: 22701.0000 - val_fn: 3088.0000 - val_categorical_accuracy: 0.5768 - val_precision: 0.8723 - val_recall: 0.3264 - val_auc: 0.8941 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1419 - tp: 5619.0000 - fp: 1755.0000 - tn: 89925.0000 - fn: 12717.0000 - categorical_accuracy: 0.5289 - precision: 0.7620 - recall: 0.3064 - auc: 0.8641 - val_loss: 1.0329 - val_tp: 1456.0000 - val_fp: 209.0000 - val_tn: 22711.0000 - val_fn: 3128.0000 - val_categorical_accuracy: 0.5836 - val_precision: 0.8745 - val_recall: 0.3176 - val_auc: 0.8978 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1268 - tp: 5745.0000 - fp: 1777.0000 - tn: 89903.0000 - fn: 12591.0000 - categorical_accuracy: 0.5295 - precision: 0.7638 - recall: 0.3133 - auc: 0.8670 - val_loss: 0.9958 - val_tp: 1439.0000 - val_fp: 182.0000 - val_tn: 22738.0000 - val_fn: 3145.0000 - val_categorical_accuracy: 0.6001 - val_precision: 0.8877 - val_recall: 0.3139 - val_auc: 0.9027 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1054 - tp: 6146.0000 - fp: 1945.0000 - tn: 89735.0000 - fn: 12190.0000 - categorical_accuracy: 0.5429 - precision: 0.7596 - recall: 0.3352 - auc: 0.8724 - val_loss: 1.0094 - val_tp: 1605.0000 - val_fp: 287.0000 - val_tn: 22633.0000 - val_fn: 2979.0000 - val_categorical_accuracy: 0.5790 - val_precision: 0.8483 - val_recall: 0.3501 - val_auc: 0.8973 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0967 - tp: 6222.0000 - fp: 1879.0000 - tn: 89801.0000 - fn: 12114.0000 - categorical_accuracy: 0.5479 - precision: 0.7681 - recall: 0.3393 - auc: 0.8756 - val_loss: 0.9774 - val_tp: 1737.0000 - val_fp: 362.0000 - val_tn: 22558.0000 - val_fn: 2847.0000 - val_categorical_accuracy: 0.5918 - val_precision: 0.8275 - val_recall: 0.3789 - val_auc: 0.9042 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1031 - tp: 6253.0000 - fp: 1970.0000 - tn: 89710.0000 - fn: 12083.0000 - categorical_accuracy: 0.5460 - precision: 0.7604 - recall: 0.3410 - auc: 0.8735 - val_loss: 0.9912 - val_tp: 1603.0000 - val_fp: 262.0000 - val_tn: 22658.0000 - val_fn: 2981.0000 - val_categorical_accuracy: 0.6067 - val_precision: 0.8595 - val_recall: 0.3497 - val_auc: 0.9054 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0917 - tp: 6375.0000 - fp: 2009.0000 - tn: 89671.0000 - fn: 11961.0000 - categorical_accuracy: 0.5531 - precision: 0.7604 - recall: 0.3477 - auc: 0.8765 - val_loss: 0.9949 - val_tp: 1771.0000 - val_fp: 398.0000 - val_tn: 22522.0000 - val_fn: 2813.0000 - val_categorical_accuracy: 0.5903 - val_precision: 0.8165 - val_recall: 0.3863 - val_auc: 0.9000 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0624 - tp: 6768.0000 - fp: 2137.0000 - tn: 89543.0000 - fn: 11568.0000 - categorical_accuracy: 0.5620 - precision: 0.7600 - recall: 0.3691 - auc: 0.8827 - val_loss: 0.9724 - val_tp: 1827.0000 - val_fp: 398.0000 - val_tn: 22522.0000 - val_fn: 2757.0000 - val_categorical_accuracy: 0.5977 - val_precision: 0.8211 - val_recall: 0.3986 - val_auc: 0.9037 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0657 - tp: 6762.0000 - fp: 2184.0000 - tn: 89496.0000 - fn: 11574.0000 - categorical_accuracy: 0.5629 - precision: 0.7559 - recall: 0.3688 - auc: 0.8824 - val_loss: 0.9532 - val_tp: 1702.0000 - val_fp: 250.0000 - val_tn: 22670.0000 - val_fn: 2882.0000 - val_categorical_accuracy: 0.6150 - val_precision: 0.8719 - val_recall: 0.3713 - val_auc: 0.9114 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "139/144 [===========================>..] - ETA: 0s - loss: 1.0501 - tp: 6698.0000 - fp: 2050.0000 - tn: 86910.0000 - fn: 11094.0000 - categorical_accuracy: 0.5685 - precision: 0.7657 - recall: 0.3765 - auc: 0.8862"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7b8f226cb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mWHICH_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"contact\"\u001b[0m \u001b[0;31m# can be \"contact\" or \"radar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mWHICH_MODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"fully_connected_small\"\u001b[0m \u001b[0;31m# can be \"fully_connected_small\" or \"1d_cnn\" (with FFT_ONLY=True, ADD_FTT=False) or \"hybrid\" (with FFT_ONLY=False, ADD_FFT=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_results_contact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfold_cv_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWHICH_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWHICH_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLASS_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"N_FOLDS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_results_contact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/IJS/radar-dataset-analysis/python/helper_functions.ipynb\u001b[0m in \u001b[0;36mkfold_cv_experiment\u001b[0;34m(which_data, which_model, hyperparams, metrics, class_map, n_folds, selected_classes)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m\"## Helper functions\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;34m\"This notebook contains a number of helper functions useful for a variety of ML experiments (train-test, kFold cross validation, leave one subject out...). They are used by the corresponding experiment notebooks.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m    ]\n\u001b[1;32m     77\u001b[0m   },\n",
      "\u001b[0;32m~/Desktop/IJS/radar-dataset-analysis/python/helper_functions.ipynb\u001b[0m in \u001b[0;36mexecute_single_fold\u001b[0;34m(which_data, which_model, train_index, test_index, X_all, Y_all, hyperparams, metrics, iteration, class_map)\u001b[0m\n\u001b[1;32m     28\u001b[0m    ],\n\u001b[1;32m     29\u001b[0m    \"source\": [\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;34m\"import os\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"import random\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"import shutil\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    860\u001b[0m           val_x, val_y, val_sample_weight = (\n\u001b[1;32m    861\u001b[0m               data_adapter.unpack_x_y_sample_weight(validation_data))\n\u001b[0;32m--> 862\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    863\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1047\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     dataset = dataset.map(\n\u001b[0m\u001b[1;32m    397\u001b[0m         grab_batch, num_parallel_calls=dataset_ops.AUTOTUNE)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1621\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m       return ParallelMapDataset(\n\u001b[0m\u001b[1;32m   1624\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4014\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4015\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4016\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4017\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m           \u001b[0mautograph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m   3204\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m   3205\u001b[0m         \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m         Function(\n\u001b[0m\u001b[1;32m   3207\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, python_function, name, input_signature, attributes, autograph, autograph_options, experimental_relax_shapes, capture_by_value, experimental_compile)\u001b[0m\n\u001b[1;32m   2396\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0mpure_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mIMPLEMENTS_ATTRIBUTE_NAME\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m     self._function_spec = FunctionSpec.from_function_and_signature(\n\u001b[0m\u001b[1;32m   2399\u001b[0m         python_function, input_signature, is_pure=pure_function)\n\u001b[1;32m   2400\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mfrom_function_and_signature\u001b[0;34m(python_function, input_signature, is_pure)\u001b[0m\n\u001b[1;32m   2075\u001b[0m             \u001b[0mkwonlydefaults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m             annotations=fullargspec.annotations)\n\u001b[0;32m-> 2077\u001b[0;31m     \u001b[0mis_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m     return FunctionSpec(fullargspec, is_method, [], {}, input_signature,\n\u001b[1;32m   2079\u001b[0m                         is_pure=is_pure)\n",
      "\u001b[0;32m~/miniconda3/envs/py38_radar/lib/python3.8/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mismethod\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0;34m\"\"\"TFDecorator-aware replacement for inspect.ismethod.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "WHICH_DATA = \"contact\" # can be \"contact\" or \"radar\"\n",
    "WHICH_MODEL = \"fully_connected_small\" # can be \"fully_connected_small\" or \"1d_cnn\" (with FFT_ONLY=True, ADD_FTT=False) or \"hybrid\" (with FFT_ONLY=False, ADD_FFT=True)\n",
    "all_results_contact = helper_functions.kfold_cv_experiment(which_data=WHICH_DATA, which_model=WHICH_MODEL, hyperparams=HYPERPARAMS, metrics=METRICS, class_map=CLASS_MAP, n_folds=HYPERPARAMS[\"N_FOLDS\"])\n",
    "display(all_results_contact)\n",
    "\n",
    "# Save results\n",
    "Path(\"results/\"+WHICH_DATA+\"_kfold/\"+HYPERPARAMS[\"RUN_ID\"]).mkdir(parents=True, exist_ok=True)\n",
    "FILENAME = \"results/\"+WHICH_DATA+\"_kfold/\"+HYPERPARAMS[\"RUN_ID\"]+\"/results_\"+WHICH_MODEL+\".xlsx\"\n",
    "all_results_contact.to_excel(FILENAME, sheet_name=\"results\")\n",
    "writer = pd.ExcelWriter(FILENAME, engine='openpyxl', mode='a')\n",
    "pd.DataFrame(data=HYPERPARAMS, index=[0]).T.to_excel(writer, sheet_name=\"hyperparams\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2c0d790f8b26ccaf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2c0d790f8b26ccaf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tensorboard for visualisation, use jupyter magic to run it based on things saved during training\n",
    "%load_ext tensorboard\n",
    "if WHICH_DATA==\"contact\":\n",
    "    path = \"model_training_logs/contact_kfold/\"+HYPERPARAMS[\"RUN_ID\"]\n",
    "    %tensorboard --logdir $path --host localhost\n",
    "else:\n",
    "    path = \"model_training_logs/radar_kfold/\"+HYPERPARAMS[\"RUN_ID\"]\n",
    "    %tensorboard --logdir $path --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training for radar sensors [6 classes]\n",
    "\n",
    "The cell below is the equivalent of *main* function. It clears old logs and backend, reads stacked all subject data and feeds it to the models. 70% of data is taken for training, 30% of data is considered for validation, coming from the n-1 folds. The final fold is used for testing.\n",
    "\n",
    "Callbacks are added that save the model after each epoch and logs for TensorBoard (visualisation) are saved.\n",
    "\n",
    "### Attention: \n",
    "\n",
    "If you are running this on GPU, you might want to consider removing callbacks! Those take the majority of time (writing tons of things to disk)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (13312, 1280, 6) (13312,)\n",
      "Oversampling signal 0\n",
      "Oversampling signal 1\n",
      "Oversampling signal 2\n",
      "Oversampling signal 3\n",
      "Oversampling signal 4\n",
      "Oversampling signal 5\n",
      "Shapes after oversampling: (28650, 1280, 6) (28650,)\n",
      "Number of splits: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== FOLD: 0 ======================\n",
      "Train: [  955   956   957 ... 28647 28648 28649]\n",
      "Test: [    0     1     2 ... 24827 24828 24829]\n",
      "Intersection: []\n",
      "TRAIN: [  955   956   957 ... 28647 28648 28649] TEST: [    0     1     2 ... 24827 24828 24829]\n",
      "Train shapes: (22920, 1280, 6) (22920,) Test shapes: (5730, 1280, 6) (5730,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_radar_i (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_q (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_dist (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_pulse (InputLayer)  [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_resp (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_heartSound (InputLa [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           40992       input_radar_i[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           40992       input_radar_q[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           40992       input_radar_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           40992       input_radar_pulse[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           40992       input_radar_resp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           40992       input_radar_heartSound[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 48)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1568        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 252,134\n",
      "Trainable params: 252,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "144/144 [==============================] - 2s 16ms/step - loss: 1.7046 - tp: 451.0000 - fp: 540.0000 - tn: 91140.0000 - fn: 17885.0000 - categorical_accuracy: 0.2810 - precision: 0.4551 - recall: 0.0246 - auc: 0.6508 - val_loss: 1.4546 - val_tp: 321.0000 - val_fp: 136.0000 - val_tn: 22784.0000 - val_fn: 4263.0000 - val_categorical_accuracy: 0.3931 - val_precision: 0.7024 - val_recall: 0.0700 - val_auc: 0.7748 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.4901 - tp: 1695.0000 - fp: 1081.0000 - tn: 90599.0000 - fn: 16641.0000 - categorical_accuracy: 0.3803 - precision: 0.6106 - recall: 0.0924 - auc: 0.7560 - val_loss: 1.3675 - val_tp: 575.0000 - val_fp: 301.0000 - val_tn: 22619.0000 - val_fn: 4009.0000 - val_categorical_accuracy: 0.4322 - val_precision: 0.6564 - val_recall: 0.1254 - val_auc: 0.8027 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.4451 - tp: 2165.0000 - fp: 1251.0000 - tn: 90429.0000 - fn: 16171.0000 - categorical_accuracy: 0.3985 - precision: 0.6338 - recall: 0.1181 - auc: 0.7724 - val_loss: 1.3528 - val_tp: 512.0000 - val_fp: 159.0000 - val_tn: 22761.0000 - val_fn: 4072.0000 - val_categorical_accuracy: 0.4450 - val_precision: 0.7630 - val_recall: 0.1117 - val_auc: 0.8088 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.4204 - tp: 2313.0000 - fp: 1203.0000 - tn: 90477.0000 - fn: 16023.0000 - categorical_accuracy: 0.4100 - precision: 0.6578 - recall: 0.1261 - auc: 0.7803 - val_loss: 1.2925 - val_tp: 625.0000 - val_fp: 189.0000 - val_tn: 22731.0000 - val_fn: 3959.0000 - val_categorical_accuracy: 0.4753 - val_precision: 0.7678 - val_recall: 0.1363 - val_auc: 0.8295 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.4125 - tp: 2660.0000 - fp: 1450.0000 - tn: 90230.0000 - fn: 15676.0000 - categorical_accuracy: 0.4210 - precision: 0.6472 - recall: 0.1451 - auc: 0.7842 - val_loss: 1.3062 - val_tp: 653.0000 - val_fp: 226.0000 - val_tn: 22694.0000 - val_fn: 3931.0000 - val_categorical_accuracy: 0.4721 - val_precision: 0.7429 - val_recall: 0.1425 - val_auc: 0.8262 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3937 - tp: 2823.0000 - fp: 1493.0000 - tn: 90187.0000 - fn: 15513.0000 - categorical_accuracy: 0.4278 - precision: 0.6541 - recall: 0.1540 - auc: 0.7904 - val_loss: 1.2743 - val_tp: 876.0000 - val_fp: 303.0000 - val_tn: 22617.0000 - val_fn: 3708.0000 - val_categorical_accuracy: 0.4771 - val_precision: 0.7430 - val_recall: 0.1911 - val_auc: 0.8319 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3705 - tp: 3382.0000 - fp: 1687.0000 - tn: 89993.0000 - fn: 14954.0000 - categorical_accuracy: 0.4435 - precision: 0.6672 - recall: 0.1844 - auc: 0.7985 - val_loss: 1.2506 - val_tp: 922.0000 - val_fp: 190.0000 - val_tn: 22730.0000 - val_fn: 3662.0000 - val_categorical_accuracy: 0.4972 - val_precision: 0.8291 - val_recall: 0.2011 - val_auc: 0.8410 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3766 - tp: 3428.0000 - fp: 1668.0000 - tn: 90012.0000 - fn: 14908.0000 - categorical_accuracy: 0.4418 - precision: 0.6727 - recall: 0.1870 - auc: 0.7956 - val_loss: 1.2702 - val_tp: 882.0000 - val_fp: 212.0000 - val_tn: 22708.0000 - val_fn: 3702.0000 - val_categorical_accuracy: 0.4867 - val_precision: 0.8062 - val_recall: 0.1924 - val_auc: 0.8351 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3570 - tp: 3584.0000 - fp: 1592.0000 - tn: 90088.0000 - fn: 14752.0000 - categorical_accuracy: 0.4462 - precision: 0.6924 - recall: 0.1955 - auc: 0.8020 - val_loss: 1.2251 - val_tp: 1098.0000 - val_fp: 279.0000 - val_tn: 22641.0000 - val_fn: 3486.0000 - val_categorical_accuracy: 0.4948 - val_precision: 0.7974 - val_recall: 0.2395 - val_auc: 0.8435 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3478 - tp: 3890.0000 - fp: 1699.0000 - tn: 89981.0000 - fn: 14446.0000 - categorical_accuracy: 0.4556 - precision: 0.6960 - recall: 0.2122 - auc: 0.8050 - val_loss: 1.2652 - val_tp: 933.0000 - val_fp: 253.0000 - val_tn: 22667.0000 - val_fn: 3651.0000 - val_categorical_accuracy: 0.4876 - val_precision: 0.7867 - val_recall: 0.2035 - val_auc: 0.8356 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3700 - tp: 3634.0000 - fp: 1693.0000 - tn: 89987.0000 - fn: 14702.0000 - categorical_accuracy: 0.4448 - precision: 0.6822 - recall: 0.1982 - auc: 0.7975 - val_loss: 1.2423 - val_tp: 1001.0000 - val_fp: 262.0000 - val_tn: 22658.0000 - val_fn: 3583.0000 - val_categorical_accuracy: 0.5039 - val_precision: 0.7926 - val_recall: 0.2184 - val_auc: 0.8419 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3770 - tp: 3454.0000 - fp: 1520.0000 - tn: 90160.0000 - fn: 14882.0000 - categorical_accuracy: 0.4433 - precision: 0.6944 - recall: 0.1884 - auc: 0.7952 - val_loss: 1.2459 - val_tp: 936.0000 - val_fp: 155.0000 - val_tn: 22765.0000 - val_fn: 3648.0000 - val_categorical_accuracy: 0.5122 - val_precision: 0.8579 - val_recall: 0.2042 - val_auc: 0.8474 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3674 - tp: 3588.0000 - fp: 1508.0000 - tn: 90172.0000 - fn: 14748.0000 - categorical_accuracy: 0.4413 - precision: 0.7041 - recall: 0.1957 - auc: 0.7968 - val_loss: 1.2395 - val_tp: 910.0000 - val_fp: 140.0000 - val_tn: 22780.0000 - val_fn: 3674.0000 - val_categorical_accuracy: 0.4889 - val_precision: 0.8667 - val_recall: 0.1985 - val_auc: 0.8389 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3576 - tp: 3773.0000 - fp: 1552.0000 - tn: 90128.0000 - fn: 14563.0000 - categorical_accuracy: 0.4502 - precision: 0.7085 - recall: 0.2058 - auc: 0.8004 - val_loss: 1.2667 - val_tp: 977.0000 - val_fp: 217.0000 - val_tn: 22703.0000 - val_fn: 3607.0000 - val_categorical_accuracy: 0.4928 - val_precision: 0.8183 - val_recall: 0.2131 - val_auc: 0.8334 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3486 - tp: 3904.0000 - fp: 1559.0000 - tn: 90121.0000 - fn: 14432.0000 - categorical_accuracy: 0.4525 - precision: 0.7146 - recall: 0.2129 - auc: 0.8035 - val_loss: 1.2292 - val_tp: 1030.0000 - val_fp: 205.0000 - val_tn: 22715.0000 - val_fn: 3554.0000 - val_categorical_accuracy: 0.5000 - val_precision: 0.8340 - val_recall: 0.2247 - val_auc: 0.8439 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3644 - tp: 3716.0000 - fp: 1620.0000 - tn: 90060.0000 - fn: 14620.0000 - categorical_accuracy: 0.4448 - precision: 0.6964 - recall: 0.2027 - auc: 0.7979 - val_loss: 1.2702 - val_tp: 1104.0000 - val_fp: 312.0000 - val_tn: 22608.0000 - val_fn: 3480.0000 - val_categorical_accuracy: 0.4937 - val_precision: 0.7797 - val_recall: 0.2408 - val_auc: 0.8324 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3643 - tp: 3766.0000 - fp: 1641.0000 - tn: 90039.0000 - fn: 14570.0000 - categorical_accuracy: 0.4479 - precision: 0.6965 - recall: 0.2054 - auc: 0.7978 - val_loss: 1.2403 - val_tp: 987.0000 - val_fp: 170.0000 - val_tn: 22750.0000 - val_fn: 3597.0000 - val_categorical_accuracy: 0.4998 - val_precision: 0.8531 - val_recall: 0.2153 - val_auc: 0.8444 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3468 - tp: 3749.0000 - fp: 1530.0000 - tn: 90150.0000 - fn: 14587.0000 - categorical_accuracy: 0.4521 - precision: 0.7102 - recall: 0.2045 - auc: 0.8040 - val_loss: 1.2474 - val_tp: 1126.0000 - val_fp: 317.0000 - val_tn: 22603.0000 - val_fn: 3458.0000 - val_categorical_accuracy: 0.5046 - val_precision: 0.7803 - val_recall: 0.2456 - val_auc: 0.8377 - lr: 0.0091\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3473 - tp: 3996.0000 - fp: 1700.0000 - tn: 89980.0000 - fn: 14340.0000 - categorical_accuracy: 0.4533 - precision: 0.7015 - recall: 0.2179 - auc: 0.8035 - val_loss: 1.2138 - val_tp: 1099.0000 - val_fp: 243.0000 - val_tn: 22677.0000 - val_fn: 3485.0000 - val_categorical_accuracy: 0.5175 - val_precision: 0.8189 - val_recall: 0.2397 - val_auc: 0.8506 - lr: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3355 - tp: 4196.0000 - fp: 1817.0000 - tn: 89863.0000 - fn: 14140.0000 - categorical_accuracy: 0.4607 - precision: 0.6978 - recall: 0.2288 - auc: 0.8083 - val_loss: 1.2208 - val_tp: 1086.0000 - val_fp: 254.0000 - val_tn: 22666.0000 - val_fn: 3498.0000 - val_categorical_accuracy: 0.5159 - val_precision: 0.8104 - val_recall: 0.2369 - val_auc: 0.8461 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3312 - tp: 4106.0000 - fp: 1725.0000 - tn: 89955.0000 - fn: 14230.0000 - categorical_accuracy: 0.4592 - precision: 0.7042 - recall: 0.2239 - auc: 0.8091 - val_loss: 1.2365 - val_tp: 1027.0000 - val_fp: 210.0000 - val_tn: 22710.0000 - val_fn: 3557.0000 - val_categorical_accuracy: 0.5033 - val_precision: 0.8302 - val_recall: 0.2240 - val_auc: 0.8424 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3567 - tp: 3898.0000 - fp: 1735.0000 - tn: 89945.0000 - fn: 14438.0000 - categorical_accuracy: 0.4520 - precision: 0.6920 - recall: 0.2126 - auc: 0.8004 - val_loss: 1.2246 - val_tp: 1093.0000 - val_fp: 232.0000 - val_tn: 22688.0000 - val_fn: 3491.0000 - val_categorical_accuracy: 0.4965 - val_precision: 0.8249 - val_recall: 0.2384 - val_auc: 0.8434 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3651 - tp: 3781.0000 - fp: 1727.0000 - tn: 89953.0000 - fn: 14555.0000 - categorical_accuracy: 0.4437 - precision: 0.6865 - recall: 0.2062 - auc: 0.7978 - val_loss: 1.2479 - val_tp: 1033.0000 - val_fp: 200.0000 - val_tn: 22720.0000 - val_fn: 3551.0000 - val_categorical_accuracy: 0.4950 - val_precision: 0.8378 - val_recall: 0.2253 - val_auc: 0.8388 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3476 - tp: 3865.0000 - fp: 1688.0000 - tn: 89992.0000 - fn: 14471.0000 - categorical_accuracy: 0.4540 - precision: 0.6960 - recall: 0.2108 - auc: 0.8040 - val_loss: 1.2514 - val_tp: 1120.0000 - val_fp: 339.0000 - val_tn: 22581.0000 - val_fn: 3464.0000 - val_categorical_accuracy: 0.4941 - val_precision: 0.7676 - val_recall: 0.2443 - val_auc: 0.8390 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3583 - tp: 3799.0000 - fp: 1840.0000 - tn: 89840.0000 - fn: 14537.0000 - categorical_accuracy: 0.4538 - precision: 0.6737 - recall: 0.2072 - auc: 0.8012 - val_loss: 1.2168 - val_tp: 1092.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 3492.0000 - val_categorical_accuracy: 0.5087 - val_precision: 0.8311 - val_recall: 0.2382 - val_auc: 0.8482 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3196 - tp: 4233.0000 - fp: 1667.0000 - tn: 90013.0000 - fn: 14103.0000 - categorical_accuracy: 0.4667 - precision: 0.7175 - recall: 0.2309 - auc: 0.8128 - val_loss: 1.1990 - val_tp: 1151.0000 - val_fp: 249.0000 - val_tn: 22671.0000 - val_fn: 3433.0000 - val_categorical_accuracy: 0.5092 - val_precision: 0.8221 - val_recall: 0.2511 - val_auc: 0.8508 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3265 - tp: 4208.0000 - fp: 1677.0000 - tn: 90003.0000 - fn: 14128.0000 - categorical_accuracy: 0.4617 - precision: 0.7150 - recall: 0.2295 - auc: 0.8107 - val_loss: 1.1915 - val_tp: 1191.0000 - val_fp: 217.0000 - val_tn: 22703.0000 - val_fn: 3393.0000 - val_categorical_accuracy: 0.5142 - val_precision: 0.8459 - val_recall: 0.2598 - val_auc: 0.8536 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2951 - tp: 4465.0000 - fp: 1761.0000 - tn: 89919.0000 - fn: 13871.0000 - categorical_accuracy: 0.4753 - precision: 0.7172 - recall: 0.2435 - auc: 0.8206 - val_loss: 1.1850 - val_tp: 1135.0000 - val_fp: 176.0000 - val_tn: 22744.0000 - val_fn: 3449.0000 - val_categorical_accuracy: 0.5249 - val_precision: 0.8658 - val_recall: 0.2476 - val_auc: 0.8588 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2964 - tp: 4422.0000 - fp: 1723.0000 - tn: 89957.0000 - fn: 13914.0000 - categorical_accuracy: 0.4755 - precision: 0.7196 - recall: 0.2412 - auc: 0.8204 - val_loss: 1.2118 - val_tp: 1096.0000 - val_fp: 221.0000 - val_tn: 22699.0000 - val_fn: 3488.0000 - val_categorical_accuracy: 0.5076 - val_precision: 0.8322 - val_recall: 0.2391 - val_auc: 0.8487 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2896 - tp: 4481.0000 - fp: 1705.0000 - tn: 89975.0000 - fn: 13855.0000 - categorical_accuracy: 0.4723 - precision: 0.7244 - recall: 0.2444 - auc: 0.8222 - val_loss: 1.1828 - val_tp: 1176.0000 - val_fp: 254.0000 - val_tn: 22666.0000 - val_fn: 3408.0000 - val_categorical_accuracy: 0.5201 - val_precision: 0.8224 - val_recall: 0.2565 - val_auc: 0.8560 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2961 - tp: 4523.0000 - fp: 1806.0000 - tn: 89874.0000 - fn: 13813.0000 - categorical_accuracy: 0.4738 - precision: 0.7146 - recall: 0.2467 - auc: 0.8201 - val_loss: 1.1699 - val_tp: 1260.0000 - val_fp: 293.0000 - val_tn: 22627.0000 - val_fn: 3324.0000 - val_categorical_accuracy: 0.5229 - val_precision: 0.8113 - val_recall: 0.2749 - val_auc: 0.8599 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2871 - tp: 4591.0000 - fp: 1777.0000 - tn: 89903.0000 - fn: 13745.0000 - categorical_accuracy: 0.4782 - precision: 0.7209 - recall: 0.2504 - auc: 0.8230 - val_loss: 1.1817 - val_tp: 1241.0000 - val_fp: 274.0000 - val_tn: 22646.0000 - val_fn: 3343.0000 - val_categorical_accuracy: 0.5286 - val_precision: 0.8191 - val_recall: 0.2707 - val_auc: 0.8596 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2868 - tp: 4608.0000 - fp: 1831.0000 - tn: 89849.0000 - fn: 13728.0000 - categorical_accuracy: 0.4787 - precision: 0.7156 - recall: 0.2513 - auc: 0.8232 - val_loss: 1.1586 - val_tp: 1265.0000 - val_fp: 314.0000 - val_tn: 22606.0000 - val_fn: 3319.0000 - val_categorical_accuracy: 0.5305 - val_precision: 0.8011 - val_recall: 0.2760 - val_auc: 0.8615 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3076 - tp: 4440.0000 - fp: 1864.0000 - tn: 89816.0000 - fn: 13896.0000 - categorical_accuracy: 0.4696 - precision: 0.7043 - recall: 0.2421 - auc: 0.8170 - val_loss: 1.1555 - val_tp: 1174.0000 - val_fp: 185.0000 - val_tn: 22735.0000 - val_fn: 3410.0000 - val_categorical_accuracy: 0.5353 - val_precision: 0.8639 - val_recall: 0.2561 - val_auc: 0.8651 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2564 - tp: 4751.0000 - fp: 1716.0000 - tn: 89964.0000 - fn: 13585.0000 - categorical_accuracy: 0.4893 - precision: 0.7347 - recall: 0.2591 - auc: 0.8315 - val_loss: 1.1604 - val_tp: 1301.0000 - val_fp: 361.0000 - val_tn: 22559.0000 - val_fn: 3283.0000 - val_categorical_accuracy: 0.5281 - val_precision: 0.7828 - val_recall: 0.2838 - val_auc: 0.8599 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2522 - tp: 4813.0000 - fp: 1746.0000 - tn: 89934.0000 - fn: 13523.0000 - categorical_accuracy: 0.4901 - precision: 0.7338 - recall: 0.2625 - auc: 0.8331 - val_loss: 1.1427 - val_tp: 1199.0000 - val_fp: 179.0000 - val_tn: 22741.0000 - val_fn: 3385.0000 - val_categorical_accuracy: 0.5314 - val_precision: 0.8701 - val_recall: 0.2616 - val_auc: 0.8648 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2381 - tp: 4896.0000 - fp: 1697.0000 - tn: 89983.0000 - fn: 13440.0000 - categorical_accuracy: 0.4972 - precision: 0.7426 - recall: 0.2670 - auc: 0.8376 - val_loss: 1.1248 - val_tp: 1233.0000 - val_fp: 199.0000 - val_tn: 22721.0000 - val_fn: 3351.0000 - val_categorical_accuracy: 0.5443 - val_precision: 0.8610 - val_recall: 0.2690 - val_auc: 0.8718 - lr: 0.0055\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2412 - tp: 4943.0000 - fp: 1678.0000 - tn: 90002.0000 - fn: 13393.0000 - categorical_accuracy: 0.4913 - precision: 0.7466 - recall: 0.2696 - auc: 0.8358 - val_loss: 1.1126 - val_tp: 1278.0000 - val_fp: 197.0000 - val_tn: 22723.0000 - val_fn: 3306.0000 - val_categorical_accuracy: 0.5425 - val_precision: 0.8664 - val_recall: 0.2788 - val_auc: 0.8727 - lr: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2488 - tp: 4818.0000 - fp: 1672.0000 - tn: 90008.0000 - fn: 13518.0000 - categorical_accuracy: 0.4906 - precision: 0.7424 - recall: 0.2628 - auc: 0.8337 - val_loss: 1.1290 - val_tp: 1277.0000 - val_fp: 242.0000 - val_tn: 22678.0000 - val_fn: 3307.0000 - val_categorical_accuracy: 0.5314 - val_precision: 0.8407 - val_recall: 0.2786 - val_auc: 0.8689 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2378 - tp: 4937.0000 - fp: 1693.0000 - tn: 89987.0000 - fn: 13399.0000 - categorical_accuracy: 0.4961 - precision: 0.7446 - recall: 0.2693 - auc: 0.8368 - val_loss: 1.1293 - val_tp: 1273.0000 - val_fp: 241.0000 - val_tn: 22679.0000 - val_fn: 3311.0000 - val_categorical_accuracy: 0.5321 - val_precision: 0.8408 - val_recall: 0.2777 - val_auc: 0.8673 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2189 - tp: 5031.0000 - fp: 1684.0000 - tn: 89996.0000 - fn: 13305.0000 - categorical_accuracy: 0.5015 - precision: 0.7492 - recall: 0.2744 - auc: 0.8427 - val_loss: 1.1120 - val_tp: 1204.0000 - val_fp: 160.0000 - val_tn: 22760.0000 - val_fn: 3380.0000 - val_categorical_accuracy: 0.5469 - val_precision: 0.8827 - val_recall: 0.2627 - val_auc: 0.8722 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2173 - tp: 5088.0000 - fp: 1708.0000 - tn: 89972.0000 - fn: 13248.0000 - categorical_accuracy: 0.5054 - precision: 0.7487 - recall: 0.2775 - auc: 0.8431 - val_loss: 1.1064 - val_tp: 1316.0000 - val_fp: 254.0000 - val_tn: 22666.0000 - val_fn: 3268.0000 - val_categorical_accuracy: 0.5486 - val_precision: 0.8382 - val_recall: 0.2871 - val_auc: 0.8733 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2106 - tp: 4992.0000 - fp: 1579.0000 - tn: 90101.0000 - fn: 13344.0000 - categorical_accuracy: 0.5071 - precision: 0.7597 - recall: 0.2723 - auc: 0.8449 - val_loss: 1.0869 - val_tp: 1323.0000 - val_fp: 220.0000 - val_tn: 22700.0000 - val_fn: 3261.0000 - val_categorical_accuracy: 0.5521 - val_precision: 0.8574 - val_recall: 0.2886 - val_auc: 0.8770 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1880 - tp: 5268.0000 - fp: 1640.0000 - tn: 90040.0000 - fn: 13068.0000 - categorical_accuracy: 0.5109 - precision: 0.7626 - recall: 0.2873 - auc: 0.8505 - val_loss: 1.0628 - val_tp: 1368.0000 - val_fp: 217.0000 - val_tn: 22703.0000 - val_fn: 3216.0000 - val_categorical_accuracy: 0.5543 - val_precision: 0.8631 - val_recall: 0.2984 - val_auc: 0.8823 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1735 - tp: 5370.0000 - fp: 1586.0000 - tn: 90094.0000 - fn: 12966.0000 - categorical_accuracy: 0.5195 - precision: 0.7720 - recall: 0.2929 - auc: 0.8541 - val_loss: 1.0746 - val_tp: 1328.0000 - val_fp: 185.0000 - val_tn: 22735.0000 - val_fn: 3256.0000 - val_categorical_accuracy: 0.5532 - val_precision: 0.8777 - val_recall: 0.2897 - val_auc: 0.8801 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1725 - tp: 5431.0000 - fp: 1638.0000 - tn: 90042.0000 - fn: 12905.0000 - categorical_accuracy: 0.5189 - precision: 0.7683 - recall: 0.2962 - auc: 0.8547 - val_loss: 1.0765 - val_tp: 1356.0000 - val_fp: 232.0000 - val_tn: 22688.0000 - val_fn: 3228.0000 - val_categorical_accuracy: 0.5493 - val_precision: 0.8539 - val_recall: 0.2958 - val_auc: 0.8788 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1725 - tp: 5391.0000 - fp: 1660.0000 - tn: 90020.0000 - fn: 12945.0000 - categorical_accuracy: 0.5196 - precision: 0.7646 - recall: 0.2940 - auc: 0.8544 - val_loss: 1.0610 - val_tp: 1362.0000 - val_fp: 205.0000 - val_tn: 22715.0000 - val_fn: 3222.0000 - val_categorical_accuracy: 0.5617 - val_precision: 0.8692 - val_recall: 0.2971 - val_auc: 0.8830 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1600 - tp: 5515.0000 - fp: 1650.0000 - tn: 90030.0000 - fn: 12821.0000 - categorical_accuracy: 0.5236 - precision: 0.7697 - recall: 0.3008 - auc: 0.8576 - val_loss: 1.0547 - val_tp: 1297.0000 - val_fp: 134.0000 - val_tn: 22786.0000 - val_fn: 3287.0000 - val_categorical_accuracy: 0.5650 - val_precision: 0.9064 - val_recall: 0.2829 - val_auc: 0.8855 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1407 - tp: 5597.0000 - fp: 1523.0000 - tn: 90157.0000 - fn: 12739.0000 - categorical_accuracy: 0.5281 - precision: 0.7861 - recall: 0.3052 - auc: 0.8625 - val_loss: 1.0443 - val_tp: 1418.0000 - val_fp: 214.0000 - val_tn: 22706.0000 - val_fn: 3166.0000 - val_categorical_accuracy: 0.5650 - val_precision: 0.8689 - val_recall: 0.3093 - val_auc: 0.8857 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1399 - tp: 5577.0000 - fp: 1509.0000 - tn: 90171.0000 - fn: 12759.0000 - categorical_accuracy: 0.5305 - precision: 0.7870 - recall: 0.3042 - auc: 0.8629 - val_loss: 1.0366 - val_tp: 1356.0000 - val_fp: 181.0000 - val_tn: 22739.0000 - val_fn: 3228.0000 - val_categorical_accuracy: 0.5635 - val_precision: 0.8822 - val_recall: 0.2958 - val_auc: 0.8887 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1315 - tp: 5761.0000 - fp: 1655.0000 - tn: 90025.0000 - fn: 12575.0000 - categorical_accuracy: 0.5339 - precision: 0.7768 - recall: 0.3142 - auc: 0.8650 - val_loss: 1.0364 - val_tp: 1438.0000 - val_fp: 221.0000 - val_tn: 22699.0000 - val_fn: 3146.0000 - val_categorical_accuracy: 0.5652 - val_precision: 0.8668 - val_recall: 0.3137 - val_auc: 0.8884 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1365 - tp: 5682.0000 - fp: 1652.0000 - tn: 90028.0000 - fn: 12654.0000 - categorical_accuracy: 0.5299 - precision: 0.7747 - recall: 0.3099 - auc: 0.8639 - val_loss: 1.0350 - val_tp: 1412.0000 - val_fp: 218.0000 - val_tn: 22702.0000 - val_fn: 3172.0000 - val_categorical_accuracy: 0.5713 - val_precision: 0.8663 - val_recall: 0.3080 - val_auc: 0.8888 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1232 - tp: 5775.0000 - fp: 1604.0000 - tn: 90076.0000 - fn: 12561.0000 - categorical_accuracy: 0.5352 - precision: 0.7826 - recall: 0.3150 - auc: 0.8668 - val_loss: 1.0211 - val_tp: 1425.0000 - val_fp: 184.0000 - val_tn: 22736.0000 - val_fn: 3159.0000 - val_categorical_accuracy: 0.5733 - val_precision: 0.8856 - val_recall: 0.3109 - val_auc: 0.8914 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1131 - tp: 5711.0000 - fp: 1496.0000 - tn: 90184.0000 - fn: 12625.0000 - categorical_accuracy: 0.5361 - precision: 0.7924 - recall: 0.3115 - auc: 0.8689 - val_loss: 1.0170 - val_tp: 1511.0000 - val_fp: 257.0000 - val_tn: 22663.0000 - val_fn: 3073.0000 - val_categorical_accuracy: 0.5689 - val_precision: 0.8546 - val_recall: 0.3296 - val_auc: 0.8910 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1017 - tp: 5978.0000 - fp: 1625.0000 - tn: 90055.0000 - fn: 12358.0000 - categorical_accuracy: 0.5426 - precision: 0.7863 - recall: 0.3260 - auc: 0.8712 - val_loss: 1.0181 - val_tp: 1396.0000 - val_fp: 168.0000 - val_tn: 22752.0000 - val_fn: 3188.0000 - val_categorical_accuracy: 0.5731 - val_precision: 0.8926 - val_recall: 0.3045 - val_auc: 0.8902 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1026 - tp: 5825.0000 - fp: 1538.0000 - tn: 90142.0000 - fn: 12511.0000 - categorical_accuracy: 0.5446 - precision: 0.7911 - recall: 0.3177 - auc: 0.8717 - val_loss: 0.9929 - val_tp: 1488.0000 - val_fp: 204.0000 - val_tn: 22716.0000 - val_fn: 3096.0000 - val_categorical_accuracy: 0.5764 - val_precision: 0.8794 - val_recall: 0.3246 - val_auc: 0.8964 - lr: 0.0023\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0998 - tp: 5783.0000 - fp: 1515.0000 - tn: 90165.0000 - fn: 12553.0000 - categorical_accuracy: 0.5458 - precision: 0.7924 - recall: 0.3154 - auc: 0.8725 - val_loss: 1.0105 - val_tp: 1425.0000 - val_fp: 177.0000 - val_tn: 22743.0000 - val_fn: 3159.0000 - val_categorical_accuracy: 0.5785 - val_precision: 0.8895 - val_recall: 0.3109 - val_auc: 0.8928 - lr: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0915 - tp: 5845.0000 - fp: 1454.0000 - tn: 90226.0000 - fn: 12491.0000 - categorical_accuracy: 0.5436 - precision: 0.8008 - recall: 0.3188 - auc: 0.8741 - val_loss: 1.0063 - val_tp: 1416.0000 - val_fp: 167.0000 - val_tn: 22753.0000 - val_fn: 3168.0000 - val_categorical_accuracy: 0.5759 - val_precision: 0.8945 - val_recall: 0.3089 - val_auc: 0.8936 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0880 - tp: 5851.0000 - fp: 1480.0000 - tn: 90200.0000 - fn: 12485.0000 - categorical_accuracy: 0.5468 - precision: 0.7981 - recall: 0.3191 - auc: 0.8752 - val_loss: 0.9985 - val_tp: 1446.0000 - val_fp: 157.0000 - val_tn: 22763.0000 - val_fn: 3138.0000 - val_categorical_accuracy: 0.5798 - val_precision: 0.9021 - val_recall: 0.3154 - val_auc: 0.8947 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0665 - tp: 5918.0000 - fp: 1348.0000 - tn: 90332.0000 - fn: 12418.0000 - categorical_accuracy: 0.5561 - precision: 0.8145 - recall: 0.3228 - auc: 0.8797 - val_loss: 0.9789 - val_tp: 1534.0000 - val_fp: 206.0000 - val_tn: 22714.0000 - val_fn: 3050.0000 - val_categorical_accuracy: 0.5831 - val_precision: 0.8816 - val_recall: 0.3346 - val_auc: 0.8980 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0703 - tp: 6024.0000 - fp: 1462.0000 - tn: 90218.0000 - fn: 12312.0000 - categorical_accuracy: 0.5566 - precision: 0.8047 - recall: 0.3285 - auc: 0.8792 - val_loss: 0.9833 - val_tp: 1446.0000 - val_fp: 131.0000 - val_tn: 22789.0000 - val_fn: 3138.0000 - val_categorical_accuracy: 0.5812 - val_precision: 0.9169 - val_recall: 0.3154 - val_auc: 0.8980 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0671 - tp: 6013.0000 - fp: 1375.0000 - tn: 90305.0000 - fn: 12323.0000 - categorical_accuracy: 0.5535 - precision: 0.8139 - recall: 0.3279 - auc: 0.8793 - val_loss: 0.9764 - val_tp: 1521.0000 - val_fp: 188.0000 - val_tn: 22732.0000 - val_fn: 3063.0000 - val_categorical_accuracy: 0.5866 - val_precision: 0.8900 - val_recall: 0.3318 - val_auc: 0.8985 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0688 - tp: 6112.0000 - fp: 1578.0000 - tn: 90102.0000 - fn: 12224.0000 - categorical_accuracy: 0.5519 - precision: 0.7948 - recall: 0.3333 - auc: 0.8794 - val_loss: 0.9883 - val_tp: 1476.0000 - val_fp: 187.0000 - val_tn: 22733.0000 - val_fn: 3108.0000 - val_categorical_accuracy: 0.5844 - val_precision: 0.8876 - val_recall: 0.3220 - val_auc: 0.8967 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0645 - tp: 6155.0000 - fp: 1524.0000 - tn: 90156.0000 - fn: 12181.0000 - categorical_accuracy: 0.5584 - precision: 0.8015 - recall: 0.3357 - auc: 0.8804 - val_loss: 0.9796 - val_tp: 1537.0000 - val_fp: 214.0000 - val_tn: 22706.0000 - val_fn: 3047.0000 - val_categorical_accuracy: 0.5901 - val_precision: 0.8778 - val_recall: 0.3353 - val_auc: 0.8980 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0521 - tp: 6259.0000 - fp: 1538.0000 - tn: 90142.0000 - fn: 12077.0000 - categorical_accuracy: 0.5634 - precision: 0.8027 - recall: 0.3414 - auc: 0.8834 - val_loss: 0.9714 - val_tp: 1572.0000 - val_fp: 235.0000 - val_tn: 22685.0000 - val_fn: 3012.0000 - val_categorical_accuracy: 0.5908 - val_precision: 0.8700 - val_recall: 0.3429 - val_auc: 0.8994 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0364 - tp: 6361.0000 - fp: 1511.0000 - tn: 90169.0000 - fn: 11975.0000 - categorical_accuracy: 0.5668 - precision: 0.8081 - recall: 0.3469 - auc: 0.8866 - val_loss: 0.9656 - val_tp: 1528.0000 - val_fp: 195.0000 - val_tn: 22725.0000 - val_fn: 3056.0000 - val_categorical_accuracy: 0.5881 - val_precision: 0.8868 - val_recall: 0.3333 - val_auc: 0.9002 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0491 - tp: 6161.0000 - fp: 1433.0000 - tn: 90247.0000 - fn: 12175.0000 - categorical_accuracy: 0.5642 - precision: 0.8113 - recall: 0.3360 - auc: 0.8839 - val_loss: 0.9761 - val_tp: 1501.0000 - val_fp: 186.0000 - val_tn: 22734.0000 - val_fn: 3083.0000 - val_categorical_accuracy: 0.5862 - val_precision: 0.8897 - val_recall: 0.3274 - val_auc: 0.8984 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0397 - tp: 6297.0000 - fp: 1504.0000 - tn: 90176.0000 - fn: 12039.0000 - categorical_accuracy: 0.5652 - precision: 0.8072 - recall: 0.3434 - auc: 0.8858 - val_loss: 0.9662 - val_tp: 1531.0000 - val_fp: 197.0000 - val_tn: 22723.0000 - val_fn: 3053.0000 - val_categorical_accuracy: 0.5918 - val_precision: 0.8860 - val_recall: 0.3340 - val_auc: 0.9004 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0412 - tp: 6284.0000 - fp: 1523.0000 - tn: 90157.0000 - fn: 12052.0000 - categorical_accuracy: 0.5696 - precision: 0.8049 - recall: 0.3427 - auc: 0.8858 - val_loss: 0.9716 - val_tp: 1527.0000 - val_fp: 223.0000 - val_tn: 22697.0000 - val_fn: 3057.0000 - val_categorical_accuracy: 0.5860 - val_precision: 0.8726 - val_recall: 0.3331 - val_auc: 0.8988 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0341 - tp: 6298.0000 - fp: 1547.0000 - tn: 90133.0000 - fn: 12038.0000 - categorical_accuracy: 0.5672 - precision: 0.8028 - recall: 0.3435 - auc: 0.8869 - val_loss: 0.9615 - val_tp: 1537.0000 - val_fp: 196.0000 - val_tn: 22724.0000 - val_fn: 3047.0000 - val_categorical_accuracy: 0.5881 - val_precision: 0.8869 - val_recall: 0.3353 - val_auc: 0.9011 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0306 - tp: 6347.0000 - fp: 1518.0000 - tn: 90162.0000 - fn: 11989.0000 - categorical_accuracy: 0.5702 - precision: 0.8070 - recall: 0.3461 - auc: 0.8880 - val_loss: 0.9518 - val_tp: 1570.0000 - val_fp: 189.0000 - val_tn: 22731.0000 - val_fn: 3014.0000 - val_categorical_accuracy: 0.5940 - val_precision: 0.8926 - val_recall: 0.3425 - val_auc: 0.9031 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0221 - tp: 6479.0000 - fp: 1517.0000 - tn: 90163.0000 - fn: 11857.0000 - categorical_accuracy: 0.5721 - precision: 0.8103 - recall: 0.3533 - auc: 0.8897 - val_loss: 0.9558 - val_tp: 1552.0000 - val_fp: 204.0000 - val_tn: 22716.0000 - val_fn: 3032.0000 - val_categorical_accuracy: 0.5918 - val_precision: 0.8838 - val_recall: 0.3386 - val_auc: 0.9023 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0184 - tp: 6344.0000 - fp: 1458.0000 - tn: 90222.0000 - fn: 11992.0000 - categorical_accuracy: 0.5715 - precision: 0.8131 - recall: 0.3460 - auc: 0.8902 - val_loss: 0.9562 - val_tp: 1603.0000 - val_fp: 201.0000 - val_tn: 22719.0000 - val_fn: 2981.0000 - val_categorical_accuracy: 0.5912 - val_precision: 0.8886 - val_recall: 0.3497 - val_auc: 0.9021 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0234 - tp: 6445.0000 - fp: 1538.0000 - tn: 90142.0000 - fn: 11891.0000 - categorical_accuracy: 0.5689 - precision: 0.8073 - recall: 0.3515 - auc: 0.8894 - val_loss: 0.9574 - val_tp: 1543.0000 - val_fp: 180.0000 - val_tn: 22740.0000 - val_fn: 3041.0000 - val_categorical_accuracy: 0.5916 - val_precision: 0.8955 - val_recall: 0.3366 - val_auc: 0.9022 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0132 - tp: 6469.0000 - fp: 1448.0000 - tn: 90232.0000 - fn: 11867.0000 - categorical_accuracy: 0.5770 - precision: 0.8171 - recall: 0.3528 - auc: 0.8917 - val_loss: 0.9522 - val_tp: 1598.0000 - val_fp: 211.0000 - val_tn: 22709.0000 - val_fn: 2986.0000 - val_categorical_accuracy: 0.5927 - val_precision: 0.8834 - val_recall: 0.3486 - val_auc: 0.9029 - lr: 7.0388e-04\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0147 - tp: 6558.0000 - fp: 1512.0000 - tn: 90168.0000 - fn: 11778.0000 - categorical_accuracy: 0.5768 - precision: 0.8126 - recall: 0.3577 - auc: 0.8913 - val_loss: 0.9511 - val_tp: 1556.0000 - val_fp: 188.0000 - val_tn: 22732.0000 - val_fn: 3028.0000 - val_categorical_accuracy: 0.5949 - val_precision: 0.8922 - val_recall: 0.3394 - val_auc: 0.9035 - lr: 6.5477e-04\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0092 - tp: 6571.0000 - fp: 1517.0000 - tn: 90163.0000 - fn: 11765.0000 - categorical_accuracy: 0.5791 - precision: 0.8124 - recall: 0.3584 - auc: 0.8924 - val_loss: 0.9517 - val_tp: 1573.0000 - val_fp: 192.0000 - val_tn: 22728.0000 - val_fn: 3011.0000 - val_categorical_accuracy: 0.5918 - val_precision: 0.8912 - val_recall: 0.3432 - val_auc: 0.9029 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0116 - tp: 6550.0000 - fp: 1529.0000 - tn: 90151.0000 - fn: 11786.0000 - categorical_accuracy: 0.5747 - precision: 0.8107 - recall: 0.3572 - auc: 0.8919 - val_loss: 0.9449 - val_tp: 1597.0000 - val_fp: 207.0000 - val_tn: 22713.0000 - val_fn: 2987.0000 - val_categorical_accuracy: 0.5940 - val_precision: 0.8853 - val_recall: 0.3484 - val_auc: 0.9038 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0081 - tp: 6639.0000 - fp: 1554.0000 - tn: 90126.0000 - fn: 11697.0000 - categorical_accuracy: 0.5748 - precision: 0.8103 - recall: 0.3621 - auc: 0.8925 - val_loss: 0.9496 - val_tp: 1563.0000 - val_fp: 184.0000 - val_tn: 22736.0000 - val_fn: 3021.0000 - val_categorical_accuracy: 0.5929 - val_precision: 0.8947 - val_recall: 0.3410 - val_auc: 0.9033 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0089 - tp: 6502.0000 - fp: 1501.0000 - tn: 90179.0000 - fn: 11834.0000 - categorical_accuracy: 0.5789 - precision: 0.8124 - recall: 0.3546 - auc: 0.8925 - val_loss: 0.9549 - val_tp: 1647.0000 - val_fp: 250.0000 - val_tn: 22670.0000 - val_fn: 2937.0000 - val_categorical_accuracy: 0.5914 - val_precision: 0.8682 - val_recall: 0.3593 - val_auc: 0.9022 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0004 - tp: 6662.0000 - fp: 1592.0000 - tn: 90088.0000 - fn: 11674.0000 - categorical_accuracy: 0.5814 - precision: 0.8071 - recall: 0.3633 - auc: 0.8942 - val_loss: 0.9501 - val_tp: 1616.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 2968.0000 - val_categorical_accuracy: 0.5942 - val_precision: 0.8792 - val_recall: 0.3525 - val_auc: 0.9030 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0004 - tp: 6672.0000 - fp: 1617.0000 - tn: 90063.0000 - fn: 11664.0000 - categorical_accuracy: 0.5801 - precision: 0.8049 - recall: 0.3639 - auc: 0.8939 - val_loss: 0.9469 - val_tp: 1623.0000 - val_fp: 216.0000 - val_tn: 22704.0000 - val_fn: 2961.0000 - val_categorical_accuracy: 0.5971 - val_precision: 0.8825 - val_recall: 0.3541 - val_auc: 0.9040 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9906 - tp: 6729.0000 - fp: 1545.0000 - tn: 90135.0000 - fn: 11607.0000 - categorical_accuracy: 0.5860 - precision: 0.8133 - recall: 0.3670 - auc: 0.8963 - val_loss: 0.9438 - val_tp: 1656.0000 - val_fp: 245.0000 - val_tn: 22675.0000 - val_fn: 2928.0000 - val_categorical_accuracy: 0.5958 - val_precision: 0.8711 - val_recall: 0.3613 - val_auc: 0.9043 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9932 - tp: 6794.0000 - fp: 1609.0000 - tn: 90071.0000 - fn: 11542.0000 - categorical_accuracy: 0.5810 - precision: 0.8085 - recall: 0.3705 - auc: 0.8956 - val_loss: 0.9430 - val_tp: 1659.0000 - val_fp: 235.0000 - val_tn: 22685.0000 - val_fn: 2925.0000 - val_categorical_accuracy: 0.5966 - val_precision: 0.8759 - val_recall: 0.3619 - val_auc: 0.9045 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9907 - tp: 6826.0000 - fp: 1690.0000 - tn: 89990.0000 - fn: 11510.0000 - categorical_accuracy: 0.5871 - precision: 0.8016 - recall: 0.3723 - auc: 0.8964 - val_loss: 0.9373 - val_tp: 1676.0000 - val_fp: 238.0000 - val_tn: 22682.0000 - val_fn: 2908.0000 - val_categorical_accuracy: 0.5982 - val_precision: 0.8757 - val_recall: 0.3656 - val_auc: 0.9057 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9844 - tp: 6831.0000 - fp: 1600.0000 - tn: 90080.0000 - fn: 11505.0000 - categorical_accuracy: 0.5874 - precision: 0.8102 - recall: 0.3725 - auc: 0.8975 - val_loss: 0.9346 - val_tp: 1686.0000 - val_fp: 256.0000 - val_tn: 22664.0000 - val_fn: 2898.0000 - val_categorical_accuracy: 0.5990 - val_precision: 0.8682 - val_recall: 0.3678 - val_auc: 0.9062 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9819 - tp: 6839.0000 - fp: 1616.0000 - tn: 90064.0000 - fn: 11497.0000 - categorical_accuracy: 0.5844 - precision: 0.8089 - recall: 0.3730 - auc: 0.8978 - val_loss: 0.9336 - val_tp: 1674.0000 - val_fp: 237.0000 - val_tn: 22683.0000 - val_fn: 2910.0000 - val_categorical_accuracy: 0.6001 - val_precision: 0.8760 - val_recall: 0.3652 - val_auc: 0.9063 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9834 - tp: 6834.0000 - fp: 1520.0000 - tn: 90160.0000 - fn: 11502.0000 - categorical_accuracy: 0.5894 - precision: 0.8181 - recall: 0.3727 - auc: 0.8978 - val_loss: 0.9319 - val_tp: 1665.0000 - val_fp: 225.0000 - val_tn: 22695.0000 - val_fn: 2919.0000 - val_categorical_accuracy: 0.5997 - val_precision: 0.8810 - val_recall: 0.3632 - val_auc: 0.9069 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9832 - tp: 6824.0000 - fp: 1583.0000 - tn: 90097.0000 - fn: 11512.0000 - categorical_accuracy: 0.5870 - precision: 0.8117 - recall: 0.3722 - auc: 0.8979 - val_loss: 0.9307 - val_tp: 1652.0000 - val_fp: 214.0000 - val_tn: 22706.0000 - val_fn: 2932.0000 - val_categorical_accuracy: 0.6010 - val_precision: 0.8853 - val_recall: 0.3604 - val_auc: 0.9070 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9854 - tp: 6889.0000 - fp: 1617.0000 - tn: 90063.0000 - fn: 11447.0000 - categorical_accuracy: 0.5864 - precision: 0.8099 - recall: 0.3757 - auc: 0.8971 - val_loss: 0.9297 - val_tp: 1662.0000 - val_fp: 217.0000 - val_tn: 22703.0000 - val_fn: 2922.0000 - val_categorical_accuracy: 0.6019 - val_precision: 0.8845 - val_recall: 0.3626 - val_auc: 0.9074 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9809 - tp: 6791.0000 - fp: 1555.0000 - tn: 90125.0000 - fn: 11545.0000 - categorical_accuracy: 0.5851 - precision: 0.8137 - recall: 0.3704 - auc: 0.8984 - val_loss: 0.9295 - val_tp: 1655.0000 - val_fp: 215.0000 - val_tn: 22705.0000 - val_fn: 2929.0000 - val_categorical_accuracy: 0.6008 - val_precision: 0.8850 - val_recall: 0.3610 - val_auc: 0.9073 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9824 - tp: 6869.0000 - fp: 1652.0000 - tn: 90028.0000 - fn: 11467.0000 - categorical_accuracy: 0.5874 - precision: 0.8061 - recall: 0.3746 - auc: 0.8981 - val_loss: 0.9274 - val_tp: 1688.0000 - val_fp: 226.0000 - val_tn: 22694.0000 - val_fn: 2896.0000 - val_categorical_accuracy: 0.6003 - val_precision: 0.8819 - val_recall: 0.3682 - val_auc: 0.9078 - lr: 1.8151e-04\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9736 - tp: 6900.0000 - fp: 1564.0000 - tn: 90116.0000 - fn: 11436.0000 - categorical_accuracy: 0.5876 - precision: 0.8152 - recall: 0.3763 - auc: 0.8998 - val_loss: 0.9295 - val_tp: 1658.0000 - val_fp: 219.0000 - val_tn: 22701.0000 - val_fn: 2926.0000 - val_categorical_accuracy: 0.6008 - val_precision: 0.8833 - val_recall: 0.3617 - val_auc: 0.9074 - lr: 1.6621e-04\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9733 - tp: 6903.0000 - fp: 1650.0000 - tn: 90030.0000 - fn: 11433.0000 - categorical_accuracy: 0.5872 - precision: 0.8071 - recall: 0.3765 - auc: 0.8994 - val_loss: 0.9297 - val_tp: 1664.0000 - val_fp: 223.0000 - val_tn: 22697.0000 - val_fn: 2920.0000 - val_categorical_accuracy: 0.5973 - val_precision: 0.8818 - val_recall: 0.3630 - val_auc: 0.9071 - lr: 1.5207e-04\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9753 - tp: 6871.0000 - fp: 1609.0000 - tn: 90071.0000 - fn: 11465.0000 - categorical_accuracy: 0.5914 - precision: 0.8103 - recall: 0.3747 - auc: 0.8992 - val_loss: 0.9299 - val_tp: 1651.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 2933.0000 - val_categorical_accuracy: 0.5971 - val_precision: 0.8815 - val_recall: 0.3602 - val_auc: 0.9071 - lr: 1.3900e-04\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9747 - tp: 6881.0000 - fp: 1603.0000 - tn: 90077.0000 - fn: 11455.0000 - categorical_accuracy: 0.5901 - precision: 0.8111 - recall: 0.3753 - auc: 0.8997 - val_loss: 0.9300 - val_tp: 1664.0000 - val_fp: 228.0000 - val_tn: 22692.0000 - val_fn: 2920.0000 - val_categorical_accuracy: 0.6001 - val_precision: 0.8795 - val_recall: 0.3630 - val_auc: 0.9072 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9750 - tp: 6913.0000 - fp: 1558.0000 - tn: 90122.0000 - fn: 11423.0000 - categorical_accuracy: 0.5877 - precision: 0.8161 - recall: 0.3770 - auc: 0.8992 - val_loss: 0.9290 - val_tp: 1665.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 2919.0000 - val_categorical_accuracy: 0.5997 - val_precision: 0.8824 - val_recall: 0.3632 - val_auc: 0.9075 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9798 - tp: 6808.0000 - fp: 1619.0000 - tn: 90061.0000 - fn: 11528.0000 - categorical_accuracy: 0.5863 - precision: 0.8079 - recall: 0.3713 - auc: 0.8984 - val_loss: 0.9294 - val_tp: 1663.0000 - val_fp: 226.0000 - val_tn: 22694.0000 - val_fn: 2921.0000 - val_categorical_accuracy: 0.5999 - val_precision: 0.8804 - val_recall: 0.3628 - val_auc: 0.9074 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9706 - tp: 6892.0000 - fp: 1537.0000 - tn: 90143.0000 - fn: 11444.0000 - categorical_accuracy: 0.5922 - precision: 0.8177 - recall: 0.3759 - auc: 0.9004 - val_loss: 0.9280 - val_tp: 1673.0000 - val_fp: 226.0000 - val_tn: 22694.0000 - val_fn: 2911.0000 - val_categorical_accuracy: 0.6006 - val_precision: 0.8810 - val_recall: 0.3650 - val_auc: 0.9076 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9692 - tp: 6879.0000 - fp: 1579.0000 - tn: 90101.0000 - fn: 11457.0000 - categorical_accuracy: 0.5901 - precision: 0.8133 - recall: 0.3752 - auc: 0.9001 - val_loss: 0.9275 - val_tp: 1671.0000 - val_fp: 230.0000 - val_tn: 22690.0000 - val_fn: 2913.0000 - val_categorical_accuracy: 0.6006 - val_precision: 0.8790 - val_recall: 0.3645 - val_auc: 0.9076 - lr: 8.7498e-05\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.8572 - tp: 2275.0000 - fp: 246.0000 - tn: 28404.0000 - fn: 3455.0000 - categorical_accuracy: 0.6415 - precision: 0.9024 - recall: 0.3970 - auc: 0.9263\n",
      "====================== FOLD: 1 ======================\n",
      "Train: [    0     1     2 ... 28647 28648 28649]\n",
      "Test: [  955   956   957 ... 25782 25783 25784]\n",
      "Intersection: []\n",
      "TRAIN: [    0     1     2 ... 28647 28648 28649] TEST: [  955   956   957 ... 25782 25783 25784]\n",
      "Train shapes: (22920, 1280, 6) (22920,) Test shapes: (5730, 1280, 6) (5730,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_radar_i (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_q (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_dist (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_pulse (InputLayer)  [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_resp (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_heartSound (InputLa [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           40992       input_radar_i[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           40992       input_radar_q[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           40992       input_radar_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           40992       input_radar_pulse[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           40992       input_radar_resp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           40992       input_radar_heartSound[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 48)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1568        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 252,134\n",
      "Trainable params: 252,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/144 [..............................] - ETA: 20s - loss: 0.9944 - tp: 1678.0000 - fp: 267.0000 - tn: 23933.0000 - fn: 3162.0000 - categorical_accuracy: 0.5775 - precision: 0.8627 - recall: 0.3467 - auc: 0.8946WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.139608). Check your callbacks.\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 1.5254 - tp: 2270.0000 - fp: 794.0000 - tn: 113806.0000 - fn: 20650.0000 - categorical_accuracy: 0.3609 - precision: 0.7409 - recall: 0.0990 - auc: 0.7277 - val_loss: 1.4537 - val_tp: 256.0000 - val_fp: 66.0000 - val_tn: 22854.0000 - val_fn: 4328.0000 - val_categorical_accuracy: 0.3805 - val_precision: 0.7950 - val_recall: 0.0558 - val_auc: 0.7765 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.4775 - tp: 2047.0000 - fp: 1150.0000 - tn: 90530.0000 - fn: 16289.0000 - categorical_accuracy: 0.3853 - precision: 0.6403 - recall: 0.1116 - auc: 0.7603 - val_loss: 1.3785 - val_tp: 408.0000 - val_fp: 103.0000 - val_tn: 22817.0000 - val_fn: 4176.0000 - val_categorical_accuracy: 0.4396 - val_precision: 0.7984 - val_recall: 0.0890 - val_auc: 0.8097 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.4279 - tp: 2418.0000 - fp: 1198.0000 - tn: 90482.0000 - fn: 15918.0000 - categorical_accuracy: 0.4130 - precision: 0.6687 - recall: 0.1319 - auc: 0.7785 - val_loss: 1.3356 - val_tp: 548.0000 - val_fp: 158.0000 - val_tn: 22762.0000 - val_fn: 4036.0000 - val_categorical_accuracy: 0.4620 - val_precision: 0.7762 - val_recall: 0.1195 - val_auc: 0.8176 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3989 - tp: 2873.0000 - fp: 1391.0000 - tn: 90289.0000 - fn: 15463.0000 - categorical_accuracy: 0.4281 - precision: 0.6738 - recall: 0.1567 - auc: 0.7879 - val_loss: 1.2773 - val_tp: 991.0000 - val_fp: 357.0000 - val_tn: 22563.0000 - val_fn: 3593.0000 - val_categorical_accuracy: 0.4791 - val_precision: 0.7352 - val_recall: 0.2162 - val_auc: 0.8277 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3752 - tp: 3279.0000 - fp: 1558.0000 - tn: 90122.0000 - fn: 15057.0000 - categorical_accuracy: 0.4360 - precision: 0.6779 - recall: 0.1788 - auc: 0.7961 - val_loss: 1.2231 - val_tp: 1019.0000 - val_fp: 272.0000 - val_tn: 22648.0000 - val_fn: 3565.0000 - val_categorical_accuracy: 0.5009 - val_precision: 0.7893 - val_recall: 0.2223 - val_auc: 0.8474 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3589 - tp: 3455.0000 - fp: 1583.0000 - tn: 90097.0000 - fn: 14881.0000 - categorical_accuracy: 0.4446 - precision: 0.6858 - recall: 0.1884 - auc: 0.8002 - val_loss: 1.2455 - val_tp: 970.0000 - val_fp: 204.0000 - val_tn: 22716.0000 - val_fn: 3614.0000 - val_categorical_accuracy: 0.5022 - val_precision: 0.8262 - val_recall: 0.2116 - val_auc: 0.8390 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3519 - tp: 3715.0000 - fp: 1662.0000 - tn: 90018.0000 - fn: 14621.0000 - categorical_accuracy: 0.4541 - precision: 0.6909 - recall: 0.2026 - auc: 0.8046 - val_loss: 1.2956 - val_tp: 733.0000 - val_fp: 136.0000 - val_tn: 22784.0000 - val_fn: 3851.0000 - val_categorical_accuracy: 0.4902 - val_precision: 0.8435 - val_recall: 0.1599 - val_auc: 0.8255 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3689 - tp: 3453.0000 - fp: 1468.0000 - tn: 90212.0000 - fn: 14883.0000 - categorical_accuracy: 0.4457 - precision: 0.7017 - recall: 0.1883 - auc: 0.7970 - val_loss: 1.2118 - val_tp: 1015.0000 - val_fp: 193.0000 - val_tn: 22727.0000 - val_fn: 3569.0000 - val_categorical_accuracy: 0.5286 - val_precision: 0.8402 - val_recall: 0.2214 - val_auc: 0.8526 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.3458 - tp: 3880.0000 - fp: 1598.0000 - tn: 90082.0000 - fn: 14456.0000 - categorical_accuracy: 0.4521 - precision: 0.7083 - recall: 0.2116 - auc: 0.8039 - val_loss: 1.2450 - val_tp: 1146.0000 - val_fp: 268.0000 - val_tn: 22652.0000 - val_fn: 3438.0000 - val_categorical_accuracy: 0.5094 - val_precision: 0.8105 - val_recall: 0.2500 - val_auc: 0.8390 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3630 - tp: 3596.0000 - fp: 1450.0000 - tn: 90230.0000 - fn: 14740.0000 - categorical_accuracy: 0.4420 - precision: 0.7126 - recall: 0.1961 - auc: 0.7979 - val_loss: 1.2304 - val_tp: 950.0000 - val_fp: 204.0000 - val_tn: 22716.0000 - val_fn: 3634.0000 - val_categorical_accuracy: 0.5100 - val_precision: 0.8232 - val_recall: 0.2072 - val_auc: 0.8417 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3590 - tp: 3725.0000 - fp: 1634.0000 - tn: 90046.0000 - fn: 14611.0000 - categorical_accuracy: 0.4475 - precision: 0.6951 - recall: 0.2032 - auc: 0.7993 - val_loss: 1.2194 - val_tp: 951.0000 - val_fp: 194.0000 - val_tn: 22726.0000 - val_fn: 3633.0000 - val_categorical_accuracy: 0.5131 - val_precision: 0.8306 - val_recall: 0.2075 - val_auc: 0.8455 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3415 - tp: 4051.0000 - fp: 1715.0000 - tn: 89965.0000 - fn: 14285.0000 - categorical_accuracy: 0.4581 - precision: 0.7026 - recall: 0.2209 - auc: 0.8057 - val_loss: 1.2075 - val_tp: 982.0000 - val_fp: 179.0000 - val_tn: 22741.0000 - val_fn: 3602.0000 - val_categorical_accuracy: 0.5209 - val_precision: 0.8458 - val_recall: 0.2142 - val_auc: 0.8491 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3306 - tp: 4081.0000 - fp: 1689.0000 - tn: 89991.0000 - fn: 14255.0000 - categorical_accuracy: 0.4594 - precision: 0.7073 - recall: 0.2226 - auc: 0.8090 - val_loss: 1.2153 - val_tp: 1071.0000 - val_fp: 207.0000 - val_tn: 22713.0000 - val_fn: 3513.0000 - val_categorical_accuracy: 0.5177 - val_precision: 0.8380 - val_recall: 0.2336 - val_auc: 0.8472 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3572 - tp: 3796.0000 - fp: 1703.0000 - tn: 89977.0000 - fn: 14540.0000 - categorical_accuracy: 0.4484 - precision: 0.6903 - recall: 0.2070 - auc: 0.8009 - val_loss: 1.2282 - val_tp: 1032.0000 - val_fp: 227.0000 - val_tn: 22693.0000 - val_fn: 3552.0000 - val_categorical_accuracy: 0.5266 - val_precision: 0.8197 - val_recall: 0.2251 - val_auc: 0.8491 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3678 - tp: 3754.0000 - fp: 1613.0000 - tn: 90067.0000 - fn: 14582.0000 - categorical_accuracy: 0.4495 - precision: 0.6995 - recall: 0.2047 - auc: 0.7970 - val_loss: 1.2414 - val_tp: 1019.0000 - val_fp: 241.0000 - val_tn: 22679.0000 - val_fn: 3565.0000 - val_categorical_accuracy: 0.5120 - val_precision: 0.8087 - val_recall: 0.2223 - val_auc: 0.8440 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3877 - tp: 3435.0000 - fp: 1369.0000 - tn: 90311.0000 - fn: 14901.0000 - categorical_accuracy: 0.4352 - precision: 0.7150 - recall: 0.1873 - auc: 0.7888 - val_loss: 1.2799 - val_tp: 713.0000 - val_fp: 75.0000 - val_tn: 22845.0000 - val_fn: 3871.0000 - val_categorical_accuracy: 0.5020 - val_precision: 0.9048 - val_recall: 0.1555 - val_auc: 0.8330 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3647 - tp: 3606.0000 - fp: 1449.0000 - tn: 90231.0000 - fn: 14730.0000 - categorical_accuracy: 0.4434 - precision: 0.7134 - recall: 0.1967 - auc: 0.7979 - val_loss: 1.2426 - val_tp: 1046.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 3538.0000 - val_categorical_accuracy: 0.5161 - val_precision: 0.8249 - val_recall: 0.2282 - val_auc: 0.8405 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3278 - tp: 4163.0000 - fp: 1684.0000 - tn: 89996.0000 - fn: 14173.0000 - categorical_accuracy: 0.4643 - precision: 0.7120 - recall: 0.2270 - auc: 0.8099 - val_loss: 1.2255 - val_tp: 1044.0000 - val_fp: 243.0000 - val_tn: 22677.0000 - val_fn: 3540.0000 - val_categorical_accuracy: 0.5275 - val_precision: 0.8112 - val_recall: 0.2277 - val_auc: 0.8496 - lr: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3225 - tp: 4127.0000 - fp: 1650.0000 - tn: 90030.0000 - fn: 14209.0000 - categorical_accuracy: 0.4619 - precision: 0.7144 - recall: 0.2251 - auc: 0.8113 - val_loss: 1.2060 - val_tp: 978.0000 - val_fp: 176.0000 - val_tn: 22744.0000 - val_fn: 3606.0000 - val_categorical_accuracy: 0.5164 - val_precision: 0.8475 - val_recall: 0.2134 - val_auc: 0.8488 - lr: 0.0089\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3150 - tp: 4370.0000 - fp: 1787.0000 - tn: 89893.0000 - fn: 13966.0000 - categorical_accuracy: 0.4626 - precision: 0.7098 - recall: 0.2383 - auc: 0.8136 - val_loss: 1.2225 - val_tp: 999.0000 - val_fp: 211.0000 - val_tn: 22709.0000 - val_fn: 3585.0000 - val_categorical_accuracy: 0.5220 - val_precision: 0.8256 - val_recall: 0.2179 - val_auc: 0.8476 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3412 - tp: 3886.0000 - fp: 1635.0000 - tn: 90045.0000 - fn: 14450.0000 - categorical_accuracy: 0.4565 - precision: 0.7039 - recall: 0.2119 - auc: 0.8060 - val_loss: 1.2277 - val_tp: 1107.0000 - val_fp: 263.0000 - val_tn: 22657.0000 - val_fn: 3477.0000 - val_categorical_accuracy: 0.5070 - val_precision: 0.8080 - val_recall: 0.2415 - val_auc: 0.8456 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3274 - tp: 4053.0000 - fp: 1611.0000 - tn: 90069.0000 - fn: 14283.0000 - categorical_accuracy: 0.4620 - precision: 0.7156 - recall: 0.2210 - auc: 0.8096 - val_loss: 1.2285 - val_tp: 1016.0000 - val_fp: 227.0000 - val_tn: 22693.0000 - val_fn: 3568.0000 - val_categorical_accuracy: 0.5218 - val_precision: 0.8174 - val_recall: 0.2216 - val_auc: 0.8474 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3268 - tp: 4266.0000 - fp: 1677.0000 - tn: 90003.0000 - fn: 14070.0000 - categorical_accuracy: 0.4614 - precision: 0.7178 - recall: 0.2327 - auc: 0.8092 - val_loss: 1.1970 - val_tp: 1035.0000 - val_fp: 178.0000 - val_tn: 22742.0000 - val_fn: 3549.0000 - val_categorical_accuracy: 0.5273 - val_precision: 0.8533 - val_recall: 0.2258 - val_auc: 0.8538 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2854 - tp: 4574.0000 - fp: 1724.0000 - tn: 89956.0000 - fn: 13762.0000 - categorical_accuracy: 0.4779 - precision: 0.7263 - recall: 0.2495 - auc: 0.8224 - val_loss: 1.1641 - val_tp: 1187.0000 - val_fp: 212.0000 - val_tn: 22708.0000 - val_fn: 3397.0000 - val_categorical_accuracy: 0.5388 - val_precision: 0.8485 - val_recall: 0.2589 - val_auc: 0.8610 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2803 - tp: 4662.0000 - fp: 1783.0000 - tn: 89897.0000 - fn: 13674.0000 - categorical_accuracy: 0.4819 - precision: 0.7234 - recall: 0.2543 - auc: 0.8244 - val_loss: 1.2305 - val_tp: 1136.0000 - val_fp: 247.0000 - val_tn: 22673.0000 - val_fn: 3448.0000 - val_categorical_accuracy: 0.5020 - val_precision: 0.8214 - val_recall: 0.2478 - val_auc: 0.8423 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3073 - tp: 4369.0000 - fp: 1723.0000 - tn: 89957.0000 - fn: 13967.0000 - categorical_accuracy: 0.4726 - precision: 0.7172 - recall: 0.2383 - auc: 0.8165 - val_loss: 1.1659 - val_tp: 1212.0000 - val_fp: 233.0000 - val_tn: 22687.0000 - val_fn: 3372.0000 - val_categorical_accuracy: 0.5299 - val_precision: 0.8388 - val_recall: 0.2644 - val_auc: 0.8607 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2822 - tp: 4698.0000 - fp: 1854.0000 - tn: 89826.0000 - fn: 13638.0000 - categorical_accuracy: 0.4834 - precision: 0.7170 - recall: 0.2562 - auc: 0.8244 - val_loss: 1.1639 - val_tp: 1162.0000 - val_fp: 190.0000 - val_tn: 22730.0000 - val_fn: 3422.0000 - val_categorical_accuracy: 0.5410 - val_precision: 0.8595 - val_recall: 0.2535 - val_auc: 0.8638 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2629 - tp: 4836.0000 - fp: 1763.0000 - tn: 89917.0000 - fn: 13500.0000 - categorical_accuracy: 0.4870 - precision: 0.7328 - recall: 0.2637 - auc: 0.8293 - val_loss: 1.1326 - val_tp: 1314.0000 - val_fp: 253.0000 - val_tn: 22667.0000 - val_fn: 3270.0000 - val_categorical_accuracy: 0.5471 - val_precision: 0.8385 - val_recall: 0.2866 - val_auc: 0.8695 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2446 - tp: 5020.0000 - fp: 1932.0000 - tn: 89748.0000 - fn: 13316.0000 - categorical_accuracy: 0.4937 - precision: 0.7221 - recall: 0.2738 - auc: 0.8347 - val_loss: 1.1369 - val_tp: 1158.0000 - val_fp: 174.0000 - val_tn: 22746.0000 - val_fn: 3426.0000 - val_categorical_accuracy: 0.5528 - val_precision: 0.8694 - val_recall: 0.2526 - val_auc: 0.8694 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2443 - tp: 5107.0000 - fp: 1869.0000 - tn: 89811.0000 - fn: 13229.0000 - categorical_accuracy: 0.4983 - precision: 0.7321 - recall: 0.2785 - auc: 0.8354 - val_loss: 1.1394 - val_tp: 1336.0000 - val_fp: 256.0000 - val_tn: 22664.0000 - val_fn: 3248.0000 - val_categorical_accuracy: 0.5428 - val_precision: 0.8392 - val_recall: 0.2914 - val_auc: 0.8683 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2631 - tp: 4878.0000 - fp: 1843.0000 - tn: 89837.0000 - fn: 13458.0000 - categorical_accuracy: 0.4910 - precision: 0.7258 - recall: 0.2660 - auc: 0.8296 - val_loss: 1.1810 - val_tp: 1370.0000 - val_fp: 320.0000 - val_tn: 22600.0000 - val_fn: 3214.0000 - val_categorical_accuracy: 0.5281 - val_precision: 0.8107 - val_recall: 0.2989 - val_auc: 0.8546 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2499 - tp: 4987.0000 - fp: 1744.0000 - tn: 89936.0000 - fn: 13349.0000 - categorical_accuracy: 0.4893 - precision: 0.7409 - recall: 0.2720 - auc: 0.8328 - val_loss: 1.1403 - val_tp: 1267.0000 - val_fp: 233.0000 - val_tn: 22687.0000 - val_fn: 3317.0000 - val_categorical_accuracy: 0.5445 - val_precision: 0.8447 - val_recall: 0.2764 - val_auc: 0.8662 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2413 - tp: 5032.0000 - fp: 1711.0000 - tn: 89969.0000 - fn: 13304.0000 - categorical_accuracy: 0.4939 - precision: 0.7463 - recall: 0.2744 - auc: 0.8356 - val_loss: 1.1332 - val_tp: 1286.0000 - val_fp: 230.0000 - val_tn: 22690.0000 - val_fn: 3298.0000 - val_categorical_accuracy: 0.5482 - val_precision: 0.8483 - val_recall: 0.2805 - val_auc: 0.8693 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2381 - tp: 5128.0000 - fp: 1803.0000 - tn: 89877.0000 - fn: 13208.0000 - categorical_accuracy: 0.4979 - precision: 0.7399 - recall: 0.2797 - auc: 0.8365 - val_loss: 1.1269 - val_tp: 1371.0000 - val_fp: 231.0000 - val_tn: 22689.0000 - val_fn: 3213.0000 - val_categorical_accuracy: 0.5510 - val_precision: 0.8558 - val_recall: 0.2991 - val_auc: 0.8718 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2224 - tp: 5206.0000 - fp: 1769.0000 - tn: 89911.0000 - fn: 13130.0000 - categorical_accuracy: 0.5058 - precision: 0.7464 - recall: 0.2839 - auc: 0.8413 - val_loss: 1.1086 - val_tp: 1387.0000 - val_fp: 261.0000 - val_tn: 22659.0000 - val_fn: 3197.0000 - val_categorical_accuracy: 0.5517 - val_precision: 0.8416 - val_recall: 0.3026 - val_auc: 0.8745 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2080 - tp: 5491.0000 - fp: 1855.0000 - tn: 89825.0000 - fn: 12845.0000 - categorical_accuracy: 0.5097 - precision: 0.7475 - recall: 0.2995 - auc: 0.8456 - val_loss: 1.0961 - val_tp: 1460.0000 - val_fp: 276.0000 - val_tn: 22644.0000 - val_fn: 3124.0000 - val_categorical_accuracy: 0.5615 - val_precision: 0.8410 - val_recall: 0.3185 - val_auc: 0.8769 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2013 - tp: 5501.0000 - fp: 1784.0000 - tn: 89896.0000 - fn: 12835.0000 - categorical_accuracy: 0.5115 - precision: 0.7551 - recall: 0.3000 - auc: 0.8474 - val_loss: 1.1093 - val_tp: 1293.0000 - val_fp: 158.0000 - val_tn: 22762.0000 - val_fn: 3291.0000 - val_categorical_accuracy: 0.5569 - val_precision: 0.8911 - val_recall: 0.2821 - val_auc: 0.8765 - lr: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1919 - tp: 5482.0000 - fp: 1709.0000 - tn: 89971.0000 - fn: 12854.0000 - categorical_accuracy: 0.5147 - precision: 0.7623 - recall: 0.2990 - auc: 0.8491 - val_loss: 1.1077 - val_tp: 1447.0000 - val_fp: 320.0000 - val_tn: 22600.0000 - val_fn: 3137.0000 - val_categorical_accuracy: 0.5543 - val_precision: 0.8189 - val_recall: 0.3157 - val_auc: 0.8732 - lr: 0.0053\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1938 - tp: 5474.0000 - fp: 1679.0000 - tn: 90001.0000 - fn: 12862.0000 - categorical_accuracy: 0.5137 - precision: 0.7653 - recall: 0.2985 - auc: 0.8484 - val_loss: 1.0761 - val_tp: 1409.0000 - val_fp: 178.0000 - val_tn: 22742.0000 - val_fn: 3175.0000 - val_categorical_accuracy: 0.5606 - val_precision: 0.8878 - val_recall: 0.3074 - val_auc: 0.8809 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1785 - tp: 5622.0000 - fp: 1683.0000 - tn: 89997.0000 - fn: 12714.0000 - categorical_accuracy: 0.5226 - precision: 0.7696 - recall: 0.3066 - auc: 0.8525 - val_loss: 1.0697 - val_tp: 1521.0000 - val_fp: 267.0000 - val_tn: 22653.0000 - val_fn: 3063.0000 - val_categorical_accuracy: 0.5707 - val_precision: 0.8507 - val_recall: 0.3318 - val_auc: 0.8834 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1655 - tp: 5769.0000 - fp: 1728.0000 - tn: 89952.0000 - fn: 12567.0000 - categorical_accuracy: 0.5248 - precision: 0.7695 - recall: 0.3146 - auc: 0.8558 - val_loss: 1.0452 - val_tp: 1542.0000 - val_fp: 250.0000 - val_tn: 22670.0000 - val_fn: 3042.0000 - val_categorical_accuracy: 0.5724 - val_precision: 0.8605 - val_recall: 0.3364 - val_auc: 0.8878 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1693 - tp: 5700.0000 - fp: 1726.0000 - tn: 89954.0000 - fn: 12636.0000 - categorical_accuracy: 0.5234 - precision: 0.7676 - recall: 0.3109 - auc: 0.8557 - val_loss: 1.0610 - val_tp: 1594.0000 - val_fp: 308.0000 - val_tn: 22612.0000 - val_fn: 2990.0000 - val_categorical_accuracy: 0.5683 - val_precision: 0.8381 - val_recall: 0.3477 - val_auc: 0.8843 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1688 - tp: 5751.0000 - fp: 1703.0000 - tn: 89977.0000 - fn: 12585.0000 - categorical_accuracy: 0.5228 - precision: 0.7715 - recall: 0.3136 - auc: 0.8551 - val_loss: 1.0556 - val_tp: 1551.0000 - val_fp: 270.0000 - val_tn: 22650.0000 - val_fn: 3033.0000 - val_categorical_accuracy: 0.5768 - val_precision: 0.8517 - val_recall: 0.3384 - val_auc: 0.8859 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1459 - tp: 5854.0000 - fp: 1628.0000 - tn: 90052.0000 - fn: 12482.0000 - categorical_accuracy: 0.5312 - precision: 0.7824 - recall: 0.3193 - auc: 0.8606 - val_loss: 1.0231 - val_tp: 1604.0000 - val_fp: 241.0000 - val_tn: 22679.0000 - val_fn: 2980.0000 - val_categorical_accuracy: 0.5842 - val_precision: 0.8694 - val_recall: 0.3499 - val_auc: 0.8920 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1439 - tp: 6008.0000 - fp: 1797.0000 - tn: 89883.0000 - fn: 12328.0000 - categorical_accuracy: 0.5327 - precision: 0.7698 - recall: 0.3277 - auc: 0.8617 - val_loss: 1.0314 - val_tp: 1525.0000 - val_fp: 211.0000 - val_tn: 22709.0000 - val_fn: 3059.0000 - val_categorical_accuracy: 0.5803 - val_precision: 0.8785 - val_recall: 0.3327 - val_auc: 0.8911 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1542 - tp: 5754.0000 - fp: 1648.0000 - tn: 90032.0000 - fn: 12582.0000 - categorical_accuracy: 0.5279 - precision: 0.7774 - recall: 0.3138 - auc: 0.8587 - val_loss: 1.0428 - val_tp: 1524.0000 - val_fp: 200.0000 - val_tn: 22720.0000 - val_fn: 3060.0000 - val_categorical_accuracy: 0.5746 - val_precision: 0.8840 - val_recall: 0.3325 - val_auc: 0.8887 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1272 - tp: 6018.0000 - fp: 1672.0000 - tn: 90008.0000 - fn: 12318.0000 - categorical_accuracy: 0.5399 - precision: 0.7826 - recall: 0.3282 - auc: 0.8656 - val_loss: 1.0123 - val_tp: 1580.0000 - val_fp: 210.0000 - val_tn: 22710.0000 - val_fn: 3004.0000 - val_categorical_accuracy: 0.5790 - val_precision: 0.8827 - val_recall: 0.3447 - val_auc: 0.8944 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1442 - tp: 5887.0000 - fp: 1656.0000 - tn: 90024.0000 - fn: 12449.0000 - categorical_accuracy: 0.5295 - precision: 0.7805 - recall: 0.3211 - auc: 0.8610 - val_loss: 1.0336 - val_tp: 1599.0000 - val_fp: 256.0000 - val_tn: 22664.0000 - val_fn: 2985.0000 - val_categorical_accuracy: 0.5831 - val_precision: 0.8620 - val_recall: 0.3488 - val_auc: 0.8910 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1204 - tp: 6124.0000 - fp: 1707.0000 - tn: 89973.0000 - fn: 12212.0000 - categorical_accuracy: 0.5412 - precision: 0.7820 - recall: 0.3340 - auc: 0.8675 - val_loss: 1.0093 - val_tp: 1646.0000 - val_fp: 218.0000 - val_tn: 22702.0000 - val_fn: 2938.0000 - val_categorical_accuracy: 0.5934 - val_precision: 0.8830 - val_recall: 0.3591 - val_auc: 0.8970 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1099 - tp: 6250.0000 - fp: 1736.0000 - tn: 89944.0000 - fn: 12086.0000 - categorical_accuracy: 0.5501 - precision: 0.7826 - recall: 0.3409 - auc: 0.8703 - val_loss: 1.0006 - val_tp: 1668.0000 - val_fp: 268.0000 - val_tn: 22652.0000 - val_fn: 2916.0000 - val_categorical_accuracy: 0.5890 - val_precision: 0.8616 - val_recall: 0.3639 - val_auc: 0.8971 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1075 - tp: 6238.0000 - fp: 1705.0000 - tn: 89975.0000 - fn: 12098.0000 - categorical_accuracy: 0.5501 - precision: 0.7853 - recall: 0.3402 - auc: 0.8702 - val_loss: 1.0076 - val_tp: 1640.0000 - val_fp: 274.0000 - val_tn: 22646.0000 - val_fn: 2944.0000 - val_categorical_accuracy: 0.5942 - val_precision: 0.8568 - val_recall: 0.3578 - val_auc: 0.8977 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1006 - tp: 6316.0000 - fp: 1774.0000 - tn: 89906.0000 - fn: 12020.0000 - categorical_accuracy: 0.5497 - precision: 0.7807 - recall: 0.3445 - auc: 0.8718 - val_loss: 1.0086 - val_tp: 1584.0000 - val_fp: 232.0000 - val_tn: 22688.0000 - val_fn: 3000.0000 - val_categorical_accuracy: 0.5925 - val_precision: 0.8722 - val_recall: 0.3455 - val_auc: 0.8967 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0977 - tp: 6302.0000 - fp: 1704.0000 - tn: 89976.0000 - fn: 12034.0000 - categorical_accuracy: 0.5504 - precision: 0.7872 - recall: 0.3437 - auc: 0.8728 - val_loss: 0.9881 - val_tp: 1649.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 2935.0000 - val_categorical_accuracy: 0.5925 - val_precision: 0.8813 - val_recall: 0.3597 - val_auc: 0.8995 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0820 - tp: 6579.0000 - fp: 1838.0000 - tn: 89842.0000 - fn: 11757.0000 - categorical_accuracy: 0.5544 - precision: 0.7816 - recall: 0.3588 - auc: 0.8763 - val_loss: 0.9916 - val_tp: 1618.0000 - val_fp: 196.0000 - val_tn: 22724.0000 - val_fn: 2966.0000 - val_categorical_accuracy: 0.5977 - val_precision: 0.8920 - val_recall: 0.3530 - val_auc: 0.8997 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0835 - tp: 6453.0000 - fp: 1749.0000 - tn: 89931.0000 - fn: 11883.0000 - categorical_accuracy: 0.5573 - precision: 0.7868 - recall: 0.3519 - auc: 0.8759 - val_loss: 0.9744 - val_tp: 1709.0000 - val_fp: 266.0000 - val_tn: 22654.0000 - val_fn: 2875.0000 - val_categorical_accuracy: 0.6047 - val_precision: 0.8653 - val_recall: 0.3728 - val_auc: 0.9030 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0612 - tp: 6691.0000 - fp: 1732.0000 - tn: 89948.0000 - fn: 11645.0000 - categorical_accuracy: 0.5667 - precision: 0.7944 - recall: 0.3649 - auc: 0.8810 - val_loss: 0.9642 - val_tp: 1713.0000 - val_fp: 243.0000 - val_tn: 22677.0000 - val_fn: 2871.0000 - val_categorical_accuracy: 0.6080 - val_precision: 0.8758 - val_recall: 0.3737 - val_auc: 0.9048 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0564 - tp: 6672.0000 - fp: 1718.0000 - tn: 89962.0000 - fn: 11664.0000 - categorical_accuracy: 0.5645 - precision: 0.7952 - recall: 0.3639 - auc: 0.8820 - val_loss: 0.9561 - val_tp: 1791.0000 - val_fp: 319.0000 - val_tn: 22601.0000 - val_fn: 2793.0000 - val_categorical_accuracy: 0.6014 - val_precision: 0.8488 - val_recall: 0.3907 - val_auc: 0.9050 - lr: 0.0022\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0535 - tp: 6781.0000 - fp: 1730.0000 - tn: 89950.0000 - fn: 11555.0000 - categorical_accuracy: 0.5683 - precision: 0.7967 - recall: 0.3698 - auc: 0.8826 - val_loss: 0.9633 - val_tp: 1777.0000 - val_fp: 272.0000 - val_tn: 22648.0000 - val_fn: 2807.0000 - val_categorical_accuracy: 0.6045 - val_precision: 0.8673 - val_recall: 0.3877 - val_auc: 0.9054 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0371 - tp: 6878.0000 - fp: 1688.0000 - tn: 89992.0000 - fn: 11458.0000 - categorical_accuracy: 0.5723 - precision: 0.8029 - recall: 0.3751 - auc: 0.8862 - val_loss: 0.9598 - val_tp: 1763.0000 - val_fp: 296.0000 - val_tn: 22624.0000 - val_fn: 2821.0000 - val_categorical_accuracy: 0.5962 - val_precision: 0.8562 - val_recall: 0.3846 - val_auc: 0.9040 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0340 - tp: 6838.0000 - fp: 1662.0000 - tn: 90018.0000 - fn: 11498.0000 - categorical_accuracy: 0.5750 - precision: 0.8045 - recall: 0.3729 - auc: 0.8873 - val_loss: 0.9671 - val_tp: 1822.0000 - val_fp: 374.0000 - val_tn: 22546.0000 - val_fn: 2762.0000 - val_categorical_accuracy: 0.5990 - val_precision: 0.8297 - val_recall: 0.3975 - val_auc: 0.9026 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0417 - tp: 6944.0000 - fp: 1762.0000 - tn: 89918.0000 - fn: 11392.0000 - categorical_accuracy: 0.5708 - precision: 0.7976 - recall: 0.3787 - auc: 0.8857 - val_loss: 0.9648 - val_tp: 1753.0000 - val_fp: 271.0000 - val_tn: 22649.0000 - val_fn: 2831.0000 - val_categorical_accuracy: 0.6038 - val_precision: 0.8661 - val_recall: 0.3824 - val_auc: 0.9035 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0291 - tp: 6912.0000 - fp: 1709.0000 - tn: 89971.0000 - fn: 11424.0000 - categorical_accuracy: 0.5761 - precision: 0.8018 - recall: 0.3770 - auc: 0.8884 - val_loss: 0.9591 - val_tp: 1766.0000 - val_fp: 258.0000 - val_tn: 22662.0000 - val_fn: 2818.0000 - val_categorical_accuracy: 0.6041 - val_precision: 0.8725 - val_recall: 0.3853 - val_auc: 0.9064 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0203 - tp: 6946.0000 - fp: 1625.0000 - tn: 90055.0000 - fn: 11390.0000 - categorical_accuracy: 0.5798 - precision: 0.8104 - recall: 0.3788 - auc: 0.8904 - val_loss: 0.9513 - val_tp: 1861.0000 - val_fp: 325.0000 - val_tn: 22595.0000 - val_fn: 2723.0000 - val_categorical_accuracy: 0.6051 - val_precision: 0.8513 - val_recall: 0.4060 - val_auc: 0.9064 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0159 - tp: 7009.0000 - fp: 1642.0000 - tn: 90038.0000 - fn: 11327.0000 - categorical_accuracy: 0.5764 - precision: 0.8102 - recall: 0.3823 - auc: 0.8909 - val_loss: 0.9534 - val_tp: 1777.0000 - val_fp: 280.0000 - val_tn: 22640.0000 - val_fn: 2807.0000 - val_categorical_accuracy: 0.5969 - val_precision: 0.8639 - val_recall: 0.3877 - val_auc: 0.9051 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0149 - tp: 7006.0000 - fp: 1599.0000 - tn: 90081.0000 - fn: 11330.0000 - categorical_accuracy: 0.5803 - precision: 0.8142 - recall: 0.3821 - auc: 0.8913 - val_loss: 0.9546 - val_tp: 1782.0000 - val_fp: 281.0000 - val_tn: 22639.0000 - val_fn: 2802.0000 - val_categorical_accuracy: 0.6030 - val_precision: 0.8638 - val_recall: 0.3887 - val_auc: 0.9059 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0139 - tp: 7095.0000 - fp: 1625.0000 - tn: 90055.0000 - fn: 11241.0000 - categorical_accuracy: 0.5815 - precision: 0.8136 - recall: 0.3869 - auc: 0.8918 - val_loss: 0.9443 - val_tp: 1856.0000 - val_fp: 311.0000 - val_tn: 22609.0000 - val_fn: 2728.0000 - val_categorical_accuracy: 0.6054 - val_precision: 0.8565 - val_recall: 0.4049 - val_auc: 0.9075 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0003 - tp: 7346.0000 - fp: 1898.0000 - tn: 89782.0000 - fn: 10990.0000 - categorical_accuracy: 0.5877 - precision: 0.7947 - recall: 0.4006 - auc: 0.8947 - val_loss: 0.9370 - val_tp: 1860.0000 - val_fp: 337.0000 - val_tn: 22583.0000 - val_fn: 2724.0000 - val_categorical_accuracy: 0.6139 - val_precision: 0.8466 - val_recall: 0.4058 - val_auc: 0.9095 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9882 - tp: 7270.0000 - fp: 1720.0000 - tn: 89960.0000 - fn: 11066.0000 - categorical_accuracy: 0.5898 - precision: 0.8087 - recall: 0.3965 - auc: 0.8966 - val_loss: 0.9329 - val_tp: 1793.0000 - val_fp: 247.0000 - val_tn: 22673.0000 - val_fn: 2791.0000 - val_categorical_accuracy: 0.6126 - val_precision: 0.8789 - val_recall: 0.3911 - val_auc: 0.9095 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9854 - tp: 7252.0000 - fp: 1633.0000 - tn: 90047.0000 - fn: 11084.0000 - categorical_accuracy: 0.5943 - precision: 0.8162 - recall: 0.3955 - auc: 0.8980 - val_loss: 0.9386 - val_tp: 1818.0000 - val_fp: 273.0000 - val_tn: 22647.0000 - val_fn: 2766.0000 - val_categorical_accuracy: 0.6093 - val_precision: 0.8694 - val_recall: 0.3966 - val_auc: 0.9086 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9845 - tp: 7274.0000 - fp: 1633.0000 - tn: 90047.0000 - fn: 11062.0000 - categorical_accuracy: 0.5922 - precision: 0.8167 - recall: 0.3967 - auc: 0.8973 - val_loss: 0.9281 - val_tp: 1897.0000 - val_fp: 328.0000 - val_tn: 22592.0000 - val_fn: 2687.0000 - val_categorical_accuracy: 0.6106 - val_precision: 0.8526 - val_recall: 0.4138 - val_auc: 0.9101 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9774 - tp: 7359.0000 - fp: 1710.0000 - tn: 89970.0000 - fn: 10977.0000 - categorical_accuracy: 0.5982 - precision: 0.8114 - recall: 0.4013 - auc: 0.8997 - val_loss: 0.9286 - val_tp: 1871.0000 - val_fp: 289.0000 - val_tn: 22631.0000 - val_fn: 2713.0000 - val_categorical_accuracy: 0.6169 - val_precision: 0.8662 - val_recall: 0.4082 - val_auc: 0.9105 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9792 - tp: 7436.0000 - fp: 1755.0000 - tn: 89925.0000 - fn: 10900.0000 - categorical_accuracy: 0.5923 - precision: 0.8091 - recall: 0.4055 - auc: 0.8993 - val_loss: 0.9347 - val_tp: 1838.0000 - val_fp: 295.0000 - val_tn: 22625.0000 - val_fn: 2746.0000 - val_categorical_accuracy: 0.6132 - val_precision: 0.8617 - val_recall: 0.4010 - val_auc: 0.9095 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9741 - tp: 7407.0000 - fp: 1745.0000 - tn: 89935.0000 - fn: 10929.0000 - categorical_accuracy: 0.5998 - precision: 0.8093 - recall: 0.4040 - auc: 0.9006 - val_loss: 0.9254 - val_tp: 1824.0000 - val_fp: 259.0000 - val_tn: 22661.0000 - val_fn: 2760.0000 - val_categorical_accuracy: 0.6156 - val_precision: 0.8757 - val_recall: 0.3979 - val_auc: 0.9110 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9618 - tp: 7419.0000 - fp: 1556.0000 - tn: 90124.0000 - fn: 10917.0000 - categorical_accuracy: 0.6013 - precision: 0.8266 - recall: 0.4046 - auc: 0.9026 - val_loss: 0.9262 - val_tp: 1854.0000 - val_fp: 273.0000 - val_tn: 22647.0000 - val_fn: 2730.0000 - val_categorical_accuracy: 0.6134 - val_precision: 0.8717 - val_recall: 0.4045 - val_auc: 0.9103 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9682 - tp: 7425.0000 - fp: 1633.0000 - tn: 90047.0000 - fn: 10911.0000 - categorical_accuracy: 0.5979 - precision: 0.8197 - recall: 0.4049 - auc: 0.9012 - val_loss: 0.9244 - val_tp: 1861.0000 - val_fp: 270.0000 - val_tn: 22650.0000 - val_fn: 2723.0000 - val_categorical_accuracy: 0.6141 - val_precision: 0.8733 - val_recall: 0.4060 - val_auc: 0.9116 - lr: 7.0388e-04\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9583 - tp: 7444.0000 - fp: 1615.0000 - tn: 90065.0000 - fn: 10892.0000 - categorical_accuracy: 0.5999 - precision: 0.8217 - recall: 0.4060 - auc: 0.9033 - val_loss: 0.9194 - val_tp: 1918.0000 - val_fp: 328.0000 - val_tn: 22592.0000 - val_fn: 2666.0000 - val_categorical_accuracy: 0.6154 - val_precision: 0.8540 - val_recall: 0.4184 - val_auc: 0.9117 - lr: 6.5477e-04\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9524 - tp: 7576.0000 - fp: 1702.0000 - tn: 89978.0000 - fn: 10760.0000 - categorical_accuracy: 0.6026 - precision: 0.8166 - recall: 0.4132 - auc: 0.9042 - val_loss: 0.9128 - val_tp: 1893.0000 - val_fp: 286.0000 - val_tn: 22634.0000 - val_fn: 2691.0000 - val_categorical_accuracy: 0.6185 - val_precision: 0.8687 - val_recall: 0.4130 - val_auc: 0.9131 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9474 - tp: 7614.0000 - fp: 1637.0000 - tn: 90043.0000 - fn: 10722.0000 - categorical_accuracy: 0.6080 - precision: 0.8230 - recall: 0.4152 - auc: 0.9057 - val_loss: 0.9161 - val_tp: 1957.0000 - val_fp: 368.0000 - val_tn: 22552.0000 - val_fn: 2627.0000 - val_categorical_accuracy: 0.6191 - val_precision: 0.8417 - val_recall: 0.4269 - val_auc: 0.9125 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9525 - tp: 7681.0000 - fp: 1792.0000 - tn: 89888.0000 - fn: 10655.0000 - categorical_accuracy: 0.6050 - precision: 0.8108 - recall: 0.4189 - auc: 0.9041 - val_loss: 0.9180 - val_tp: 1942.0000 - val_fp: 353.0000 - val_tn: 22567.0000 - val_fn: 2642.0000 - val_categorical_accuracy: 0.6243 - val_precision: 0.8462 - val_recall: 0.4236 - val_auc: 0.9121 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9415 - tp: 7746.0000 - fp: 1768.0000 - tn: 89912.0000 - fn: 10590.0000 - categorical_accuracy: 0.6064 - precision: 0.8142 - recall: 0.4224 - auc: 0.9065 - val_loss: 0.9121 - val_tp: 1935.0000 - val_fp: 320.0000 - val_tn: 22600.0000 - val_fn: 2649.0000 - val_categorical_accuracy: 0.6206 - val_precision: 0.8581 - val_recall: 0.4221 - val_auc: 0.9130 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9289 - tp: 7904.0000 - fp: 1685.0000 - tn: 89995.0000 - fn: 10432.0000 - categorical_accuracy: 0.6135 - precision: 0.8243 - recall: 0.4311 - auc: 0.9092 - val_loss: 0.9101 - val_tp: 1965.0000 - val_fp: 364.0000 - val_tn: 22556.0000 - val_fn: 2619.0000 - val_categorical_accuracy: 0.6202 - val_precision: 0.8437 - val_recall: 0.4287 - val_auc: 0.9130 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9344 - tp: 7828.0000 - fp: 1767.0000 - tn: 89913.0000 - fn: 10508.0000 - categorical_accuracy: 0.6042 - precision: 0.8158 - recall: 0.4269 - auc: 0.9073 - val_loss: 0.9132 - val_tp: 1935.0000 - val_fp: 335.0000 - val_tn: 22585.0000 - val_fn: 2649.0000 - val_categorical_accuracy: 0.6235 - val_precision: 0.8524 - val_recall: 0.4221 - val_auc: 0.9130 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9398 - tp: 7804.0000 - fp: 1721.0000 - tn: 89959.0000 - fn: 10532.0000 - categorical_accuracy: 0.6093 - precision: 0.8193 - recall: 0.4256 - auc: 0.9072 - val_loss: 0.9104 - val_tp: 1974.0000 - val_fp: 375.0000 - val_tn: 22545.0000 - val_fn: 2610.0000 - val_categorical_accuracy: 0.6265 - val_precision: 0.8404 - val_recall: 0.4306 - val_auc: 0.9133 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9279 - tp: 7882.0000 - fp: 1730.0000 - tn: 89950.0000 - fn: 10454.0000 - categorical_accuracy: 0.6158 - precision: 0.8200 - recall: 0.4299 - auc: 0.9094 - val_loss: 0.9082 - val_tp: 1966.0000 - val_fp: 369.0000 - val_tn: 22551.0000 - val_fn: 2618.0000 - val_categorical_accuracy: 0.6287 - val_precision: 0.8420 - val_recall: 0.4289 - val_auc: 0.9137 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9320 - tp: 7830.0000 - fp: 1730.0000 - tn: 89950.0000 - fn: 10506.0000 - categorical_accuracy: 0.6129 - precision: 0.8190 - recall: 0.4270 - auc: 0.9088 - val_loss: 0.9068 - val_tp: 1939.0000 - val_fp: 355.0000 - val_tn: 22565.0000 - val_fn: 2645.0000 - val_categorical_accuracy: 0.6233 - val_precision: 0.8452 - val_recall: 0.4230 - val_auc: 0.9139 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9250 - tp: 7926.0000 - fp: 1697.0000 - tn: 89983.0000 - fn: 10410.0000 - categorical_accuracy: 0.6149 - precision: 0.8237 - recall: 0.4323 - auc: 0.9098 - val_loss: 0.8999 - val_tp: 1985.0000 - val_fp: 356.0000 - val_tn: 22564.0000 - val_fn: 2599.0000 - val_categorical_accuracy: 0.6291 - val_precision: 0.8479 - val_recall: 0.4330 - val_auc: 0.9156 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9247 - tp: 7876.0000 - fp: 1665.0000 - tn: 90015.0000 - fn: 10460.0000 - categorical_accuracy: 0.6139 - precision: 0.8255 - recall: 0.4295 - auc: 0.9099 - val_loss: 0.9008 - val_tp: 1969.0000 - val_fp: 331.0000 - val_tn: 22589.0000 - val_fn: 2615.0000 - val_categorical_accuracy: 0.6291 - val_precision: 0.8561 - val_recall: 0.4295 - val_auc: 0.9155 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9216 - tp: 7926.0000 - fp: 1712.0000 - tn: 89968.0000 - fn: 10410.0000 - categorical_accuracy: 0.6174 - precision: 0.8224 - recall: 0.4323 - auc: 0.9106 - val_loss: 0.8987 - val_tp: 1972.0000 - val_fp: 342.0000 - val_tn: 22578.0000 - val_fn: 2612.0000 - val_categorical_accuracy: 0.6305 - val_precision: 0.8522 - val_recall: 0.4302 - val_auc: 0.9157 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9260 - tp: 7915.0000 - fp: 1714.0000 - tn: 89966.0000 - fn: 10421.0000 - categorical_accuracy: 0.6125 - precision: 0.8220 - recall: 0.4317 - auc: 0.9094 - val_loss: 0.9010 - val_tp: 2010.0000 - val_fp: 369.0000 - val_tn: 22551.0000 - val_fn: 2574.0000 - val_categorical_accuracy: 0.6324 - val_precision: 0.8449 - val_recall: 0.4385 - val_auc: 0.9155 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9264 - tp: 7995.0000 - fp: 1789.0000 - tn: 89891.0000 - fn: 10341.0000 - categorical_accuracy: 0.6128 - precision: 0.8172 - recall: 0.4360 - auc: 0.9097 - val_loss: 0.8983 - val_tp: 1996.0000 - val_fp: 369.0000 - val_tn: 22551.0000 - val_fn: 2588.0000 - val_categorical_accuracy: 0.6294 - val_precision: 0.8440 - val_recall: 0.4354 - val_auc: 0.9160 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9180 - tp: 7996.0000 - fp: 1669.0000 - tn: 90011.0000 - fn: 10340.0000 - categorical_accuracy: 0.6185 - precision: 0.8273 - recall: 0.4361 - auc: 0.9114 - val_loss: 0.8972 - val_tp: 2000.0000 - val_fp: 354.0000 - val_tn: 22566.0000 - val_fn: 2584.0000 - val_categorical_accuracy: 0.6252 - val_precision: 0.8496 - val_recall: 0.4363 - val_auc: 0.9159 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9161 - tp: 7920.0000 - fp: 1716.0000 - tn: 89964.0000 - fn: 10416.0000 - categorical_accuracy: 0.6181 - precision: 0.8219 - recall: 0.4319 - auc: 0.9118 - val_loss: 0.8964 - val_tp: 2023.0000 - val_fp: 377.0000 - val_tn: 22543.0000 - val_fn: 2561.0000 - val_categorical_accuracy: 0.6252 - val_precision: 0.8429 - val_recall: 0.4413 - val_auc: 0.9160 - lr: 1.8151e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9117 - tp: 8102.0000 - fp: 1726.0000 - tn: 89954.0000 - fn: 10234.0000 - categorical_accuracy: 0.6216 - precision: 0.8244 - recall: 0.4419 - auc: 0.9130 - val_loss: 0.8978 - val_tp: 2032.0000 - val_fp: 395.0000 - val_tn: 22525.0000 - val_fn: 2552.0000 - val_categorical_accuracy: 0.6291 - val_precision: 0.8372 - val_recall: 0.4433 - val_auc: 0.9158 - lr: 1.6621e-04\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9164 - tp: 8097.0000 - fp: 1760.0000 - tn: 89920.0000 - fn: 10239.0000 - categorical_accuracy: 0.6219 - precision: 0.8214 - recall: 0.4416 - auc: 0.9121 - val_loss: 0.8962 - val_tp: 2029.0000 - val_fp: 395.0000 - val_tn: 22525.0000 - val_fn: 2555.0000 - val_categorical_accuracy: 0.6278 - val_precision: 0.8370 - val_recall: 0.4426 - val_auc: 0.9159 - lr: 1.5207e-04\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9122 - tp: 8043.0000 - fp: 1758.0000 - tn: 89922.0000 - fn: 10293.0000 - categorical_accuracy: 0.6247 - precision: 0.8206 - recall: 0.4386 - auc: 0.9126 - val_loss: 0.8948 - val_tp: 2033.0000 - val_fp: 384.0000 - val_tn: 22536.0000 - val_fn: 2551.0000 - val_categorical_accuracy: 0.6281 - val_precision: 0.8411 - val_recall: 0.4435 - val_auc: 0.9163 - lr: 1.3900e-04\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9110 - tp: 8079.0000 - fp: 1707.0000 - tn: 89973.0000 - fn: 10257.0000 - categorical_accuracy: 0.6167 - precision: 0.8256 - recall: 0.4406 - auc: 0.9125 - val_loss: 0.8960 - val_tp: 2038.0000 - val_fp: 388.0000 - val_tn: 22532.0000 - val_fn: 2546.0000 - val_categorical_accuracy: 0.6294 - val_precision: 0.8401 - val_recall: 0.4446 - val_auc: 0.9163 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9037 - tp: 8112.0000 - fp: 1746.0000 - tn: 89934.0000 - fn: 10224.0000 - categorical_accuracy: 0.6252 - precision: 0.8229 - recall: 0.4424 - auc: 0.9138 - val_loss: 0.8952 - val_tp: 2041.0000 - val_fp: 390.0000 - val_tn: 22530.0000 - val_fn: 2543.0000 - val_categorical_accuracy: 0.6300 - val_precision: 0.8396 - val_recall: 0.4452 - val_auc: 0.9163 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9201 - tp: 8045.0000 - fp: 1829.0000 - tn: 89851.0000 - fn: 10291.0000 - categorical_accuracy: 0.6150 - precision: 0.8148 - recall: 0.4388 - auc: 0.9108 - val_loss: 0.8963 - val_tp: 2045.0000 - val_fp: 389.0000 - val_tn: 22531.0000 - val_fn: 2539.0000 - val_categorical_accuracy: 0.6294 - val_precision: 0.8402 - val_recall: 0.4461 - val_auc: 0.9163 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9020 - tp: 8076.0000 - fp: 1693.0000 - tn: 89987.0000 - fn: 10260.0000 - categorical_accuracy: 0.6252 - precision: 0.8267 - recall: 0.4404 - auc: 0.9146 - val_loss: 0.8964 - val_tp: 2057.0000 - val_fp: 400.0000 - val_tn: 22520.0000 - val_fn: 2527.0000 - val_categorical_accuracy: 0.6294 - val_precision: 0.8372 - val_recall: 0.4487 - val_auc: 0.9164 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9077 - tp: 8104.0000 - fp: 1736.0000 - tn: 89944.0000 - fn: 10232.0000 - categorical_accuracy: 0.6213 - precision: 0.8236 - recall: 0.4420 - auc: 0.9135 - val_loss: 0.8964 - val_tp: 2056.0000 - val_fp: 407.0000 - val_tn: 22513.0000 - val_fn: 2528.0000 - val_categorical_accuracy: 0.6313 - val_precision: 0.8348 - val_recall: 0.4485 - val_auc: 0.9163 - lr: 8.7498e-05\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 0.8569 - tp: 2468.0000 - fp: 456.0000 - tn: 28194.0000 - fn: 3262.0000 - categorical_accuracy: 0.6351 - precision: 0.8440 - recall: 0.4307 - auc: 0.9244\n",
      "====================== FOLD: 2 ======================\n",
      "Train: [    0     1     2 ... 28647 28648 28649]\n",
      "Test: [ 1910  1911  1912 ... 26737 26738 26739]\n",
      "Intersection: []\n",
      "TRAIN: [    0     1     2 ... 28647 28648 28649] TEST: [ 1910  1911  1912 ... 26737 26738 26739]\n",
      "Train shapes: (22920, 1280, 6) (22920,) Test shapes: (5730, 1280, 6) (5730,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_radar_i (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_q (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_dist (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_pulse (InputLayer)  [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_resp (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_heartSound (InputLa [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           40992       input_radar_i[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           40992       input_radar_q[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           40992       input_radar_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           40992       input_radar_pulse[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           40992       input_radar_resp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           40992       input_radar_heartSound[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 48)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1568        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 252,134\n",
      "Trainable params: 252,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/144 [..............................] - ETA: 19s - loss: 0.9693 - tp: 2068.0000 - fp: 459.0000 - tn: 23741.0000 - fn: 2772.0000 - categorical_accuracy: 0.6054 - precision: 0.8184 - recall: 0.4273 - auc: 0.9024WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.133115). Check your callbacks.\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 1.5396 - tp: 2667.0000 - fp: 1094.0000 - tn: 113506.0000 - fn: 20253.0000 - categorical_accuracy: 0.3636 - precision: 0.7091 - recall: 0.1164 - auc: 0.7249 - val_loss: 1.5237 - val_tp: 134.0000 - val_fp: 21.0000 - val_tn: 22899.0000 - val_fn: 4450.0000 - val_categorical_accuracy: 0.3857 - val_precision: 0.8645 - val_recall: 0.0292 - val_auc: 0.7548 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.5003 - tp: 1925.0000 - fp: 1136.0000 - tn: 90544.0000 - fn: 16411.0000 - categorical_accuracy: 0.3794 - precision: 0.6289 - recall: 0.1050 - auc: 0.7523 - val_loss: 1.3862 - val_tp: 666.0000 - val_fp: 345.0000 - val_tn: 22575.0000 - val_fn: 3918.0000 - val_categorical_accuracy: 0.4162 - val_precision: 0.6588 - val_recall: 0.1453 - val_auc: 0.7949 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.4276 - tp: 2368.0000 - fp: 1361.0000 - tn: 90319.0000 - fn: 15968.0000 - categorical_accuracy: 0.4096 - precision: 0.6350 - recall: 0.1291 - auc: 0.7815 - val_loss: 1.2939 - val_tp: 745.0000 - val_fp: 262.0000 - val_tn: 22658.0000 - val_fn: 3839.0000 - val_categorical_accuracy: 0.4588 - val_precision: 0.7398 - val_recall: 0.1625 - val_auc: 0.8243 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.4060 - tp: 2780.0000 - fp: 1468.0000 - tn: 90212.0000 - fn: 15556.0000 - categorical_accuracy: 0.4189 - precision: 0.6544 - recall: 0.1516 - auc: 0.7893 - val_loss: 1.3365 - val_tp: 595.0000 - val_fp: 208.0000 - val_tn: 22712.0000 - val_fn: 3989.0000 - val_categorical_accuracy: 0.4431 - val_precision: 0.7410 - val_recall: 0.1298 - val_auc: 0.8147 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3866 - tp: 2955.0000 - fp: 1483.0000 - tn: 90197.0000 - fn: 15381.0000 - categorical_accuracy: 0.4287 - precision: 0.6658 - recall: 0.1612 - auc: 0.7950 - val_loss: 1.2881 - val_tp: 685.0000 - val_fp: 226.0000 - val_tn: 22694.0000 - val_fn: 3899.0000 - val_categorical_accuracy: 0.4620 - val_precision: 0.7519 - val_recall: 0.1494 - val_auc: 0.8298 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.3652 - tp: 3067.0000 - fp: 1372.0000 - tn: 90308.0000 - fn: 15269.0000 - categorical_accuracy: 0.4364 - precision: 0.6909 - recall: 0.1673 - auc: 0.8014 - val_loss: 1.2623 - val_tp: 724.0000 - val_fp: 205.0000 - val_tn: 22715.0000 - val_fn: 3860.0000 - val_categorical_accuracy: 0.4764 - val_precision: 0.7793 - val_recall: 0.1579 - val_auc: 0.8358 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3814 - tp: 3160.0000 - fp: 1368.0000 - tn: 90312.0000 - fn: 15176.0000 - categorical_accuracy: 0.4359 - precision: 0.6979 - recall: 0.1723 - auc: 0.7955 - val_loss: 1.3253 - val_tp: 664.0000 - val_fp: 122.0000 - val_tn: 22798.0000 - val_fn: 3920.0000 - val_categorical_accuracy: 0.4710 - val_precision: 0.8448 - val_recall: 0.1449 - val_auc: 0.8191 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3970 - tp: 2943.0000 - fp: 1275.0000 - tn: 90405.0000 - fn: 15393.0000 - categorical_accuracy: 0.4346 - precision: 0.6977 - recall: 0.1605 - auc: 0.7903 - val_loss: 1.3349 - val_tp: 573.0000 - val_fp: 106.0000 - val_tn: 22814.0000 - val_fn: 4011.0000 - val_categorical_accuracy: 0.4592 - val_precision: 0.8439 - val_recall: 0.1250 - val_auc: 0.8134 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3858 - tp: 3094.0000 - fp: 1401.0000 - tn: 90279.0000 - fn: 15242.0000 - categorical_accuracy: 0.4379 - precision: 0.6883 - recall: 0.1687 - auc: 0.7944 - val_loss: 1.2815 - val_tp: 715.0000 - val_fp: 182.0000 - val_tn: 22738.0000 - val_fn: 3869.0000 - val_categorical_accuracy: 0.4935 - val_precision: 0.7971 - val_recall: 0.1560 - val_auc: 0.8315 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3339 - tp: 3680.0000 - fp: 1565.0000 - tn: 90115.0000 - fn: 14656.0000 - categorical_accuracy: 0.4654 - precision: 0.7016 - recall: 0.2007 - auc: 0.8112 - val_loss: 1.2719 - val_tp: 850.0000 - val_fp: 204.0000 - val_tn: 22716.0000 - val_fn: 3734.0000 - val_categorical_accuracy: 0.4919 - val_precision: 0.8065 - val_recall: 0.1854 - val_auc: 0.8333 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3841 - tp: 3343.0000 - fp: 1590.0000 - tn: 90090.0000 - fn: 14993.0000 - categorical_accuracy: 0.4512 - precision: 0.6777 - recall: 0.1823 - auc: 0.7967 - val_loss: 1.3162 - val_tp: 601.0000 - val_fp: 114.0000 - val_tn: 22806.0000 - val_fn: 3983.0000 - val_categorical_accuracy: 0.4858 - val_precision: 0.8406 - val_recall: 0.1311 - val_auc: 0.8217 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3816 - tp: 3182.0000 - fp: 1300.0000 - tn: 90380.0000 - fn: 15154.0000 - categorical_accuracy: 0.4521 - precision: 0.7100 - recall: 0.1735 - auc: 0.7967 - val_loss: 1.3221 - val_tp: 573.0000 - val_fp: 112.0000 - val_tn: 22808.0000 - val_fn: 4011.0000 - val_categorical_accuracy: 0.4815 - val_precision: 0.8365 - val_recall: 0.1250 - val_auc: 0.8207 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.3617 - tp: 3400.0000 - fp: 1466.0000 - tn: 90214.0000 - fn: 14936.0000 - categorical_accuracy: 0.4545 - precision: 0.6987 - recall: 0.1854 - auc: 0.8023 - val_loss: 1.2227 - val_tp: 839.0000 - val_fp: 126.0000 - val_tn: 22794.0000 - val_fn: 3745.0000 - val_categorical_accuracy: 0.5205 - val_precision: 0.8694 - val_recall: 0.1830 - val_auc: 0.8500 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3296 - tp: 3679.0000 - fp: 1553.0000 - tn: 90127.0000 - fn: 14657.0000 - categorical_accuracy: 0.4722 - precision: 0.7032 - recall: 0.2006 - auc: 0.8129 - val_loss: 1.1837 - val_tp: 1227.0000 - val_fp: 310.0000 - val_tn: 22610.0000 - val_fn: 3357.0000 - val_categorical_accuracy: 0.5271 - val_precision: 0.7983 - val_recall: 0.2677 - val_auc: 0.8592 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3353 - tp: 3705.0000 - fp: 1580.0000 - tn: 90100.0000 - fn: 14631.0000 - categorical_accuracy: 0.4709 - precision: 0.7010 - recall: 0.2021 - auc: 0.8106 - val_loss: 1.2527 - val_tp: 713.0000 - val_fp: 130.0000 - val_tn: 22790.0000 - val_fn: 3871.0000 - val_categorical_accuracy: 0.5022 - val_precision: 0.8458 - val_recall: 0.1555 - val_auc: 0.8385 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3125 - tp: 4120.0000 - fp: 1793.0000 - tn: 89887.0000 - fn: 14216.0000 - categorical_accuracy: 0.4774 - precision: 0.6968 - recall: 0.2247 - auc: 0.8180 - val_loss: 1.2157 - val_tp: 1328.0000 - val_fp: 476.0000 - val_tn: 22444.0000 - val_fn: 3256.0000 - val_categorical_accuracy: 0.5257 - val_precision: 0.7361 - val_recall: 0.2897 - val_auc: 0.8480 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3170 - tp: 4059.0000 - fp: 1802.0000 - tn: 89878.0000 - fn: 14277.0000 - categorical_accuracy: 0.4739 - precision: 0.6925 - recall: 0.2214 - auc: 0.8162 - val_loss: 1.2306 - val_tp: 1016.0000 - val_fp: 273.0000 - val_tn: 22647.0000 - val_fn: 3568.0000 - val_categorical_accuracy: 0.5057 - val_precision: 0.7882 - val_recall: 0.2216 - val_auc: 0.8463 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3465 - tp: 3838.0000 - fp: 1701.0000 - tn: 89979.0000 - fn: 14498.0000 - categorical_accuracy: 0.4617 - precision: 0.6929 - recall: 0.2093 - auc: 0.8067 - val_loss: 1.2600 - val_tp: 1192.0000 - val_fp: 427.0000 - val_tn: 22493.0000 - val_fn: 3392.0000 - val_categorical_accuracy: 0.4913 - val_precision: 0.7363 - val_recall: 0.2600 - val_auc: 0.8342 - lr: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3511 - tp: 3700.0000 - fp: 1678.0000 - tn: 90002.0000 - fn: 14636.0000 - categorical_accuracy: 0.4629 - precision: 0.6880 - recall: 0.2018 - auc: 0.8052 - val_loss: 1.2830 - val_tp: 690.0000 - val_fp: 113.0000 - val_tn: 22807.0000 - val_fn: 3894.0000 - val_categorical_accuracy: 0.4876 - val_precision: 0.8593 - val_recall: 0.1505 - val_auc: 0.8282 - lr: 0.0089\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3319 - tp: 3603.0000 - fp: 1487.0000 - tn: 90193.0000 - fn: 14733.0000 - categorical_accuracy: 0.4716 - precision: 0.7079 - recall: 0.1965 - auc: 0.8117 - val_loss: 1.2173 - val_tp: 1185.0000 - val_fp: 360.0000 - val_tn: 22560.0000 - val_fn: 3399.0000 - val_categorical_accuracy: 0.5164 - val_precision: 0.7670 - val_recall: 0.2585 - val_auc: 0.8465 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3241 - tp: 3769.0000 - fp: 1626.0000 - tn: 90054.0000 - fn: 14567.0000 - categorical_accuracy: 0.4770 - precision: 0.6986 - recall: 0.2056 - auc: 0.8148 - val_loss: 1.2174 - val_tp: 1103.0000 - val_fp: 289.0000 - val_tn: 22631.0000 - val_fn: 3481.0000 - val_categorical_accuracy: 0.5209 - val_precision: 0.7924 - val_recall: 0.2406 - val_auc: 0.8505 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3428 - tp: 3474.0000 - fp: 1387.0000 - tn: 90293.0000 - fn: 14862.0000 - categorical_accuracy: 0.4653 - precision: 0.7147 - recall: 0.1895 - auc: 0.8076 - val_loss: 1.2763 - val_tp: 670.0000 - val_fp: 78.0000 - val_tn: 22842.0000 - val_fn: 3914.0000 - val_categorical_accuracy: 0.5089 - val_precision: 0.8957 - val_recall: 0.1462 - val_auc: 0.8324 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.3323 - tp: 3400.0000 - fp: 1391.0000 - tn: 90289.0000 - fn: 14936.0000 - categorical_accuracy: 0.4699 - precision: 0.7097 - recall: 0.1854 - auc: 0.8118 - val_loss: 1.1928 - val_tp: 1082.0000 - val_fp: 291.0000 - val_tn: 22629.0000 - val_fn: 3502.0000 - val_categorical_accuracy: 0.5377 - val_precision: 0.7881 - val_recall: 0.2360 - val_auc: 0.8581 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3072 - tp: 4284.0000 - fp: 2026.0000 - tn: 89654.0000 - fn: 14052.0000 - categorical_accuracy: 0.4826 - precision: 0.6789 - recall: 0.2336 - auc: 0.8197 - val_loss: 1.2349 - val_tp: 1024.0000 - val_fp: 289.0000 - val_tn: 22631.0000 - val_fn: 3560.0000 - val_categorical_accuracy: 0.5076 - val_precision: 0.7799 - val_recall: 0.2234 - val_auc: 0.8456 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2980 - tp: 4412.0000 - fp: 2036.0000 - tn: 89644.0000 - fn: 13924.0000 - categorical_accuracy: 0.4836 - precision: 0.6842 - recall: 0.2406 - auc: 0.8228 - val_loss: 1.1957 - val_tp: 1103.0000 - val_fp: 272.0000 - val_tn: 22648.0000 - val_fn: 3481.0000 - val_categorical_accuracy: 0.5238 - val_precision: 0.8022 - val_recall: 0.2406 - val_auc: 0.8549 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2983 - tp: 4632.0000 - fp: 2138.0000 - tn: 89542.0000 - fn: 13704.0000 - categorical_accuracy: 0.4881 - precision: 0.6842 - recall: 0.2526 - auc: 0.8221 - val_loss: 1.1880 - val_tp: 1224.0000 - val_fp: 299.0000 - val_tn: 22621.0000 - val_fn: 3360.0000 - val_categorical_accuracy: 0.5266 - val_precision: 0.8037 - val_recall: 0.2670 - val_auc: 0.8573 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2978 - tp: 4630.0000 - fp: 2055.0000 - tn: 89625.0000 - fn: 13706.0000 - categorical_accuracy: 0.4863 - precision: 0.6926 - recall: 0.2525 - auc: 0.8225 - val_loss: 1.2108 - val_tp: 1065.0000 - val_fp: 251.0000 - val_tn: 22669.0000 - val_fn: 3519.0000 - val_categorical_accuracy: 0.5253 - val_precision: 0.8093 - val_recall: 0.2323 - val_auc: 0.8511 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3023 - tp: 4568.0000 - fp: 2007.0000 - tn: 89673.0000 - fn: 13768.0000 - categorical_accuracy: 0.4818 - precision: 0.6948 - recall: 0.2491 - auc: 0.8210 - val_loss: 1.2467 - val_tp: 1034.0000 - val_fp: 263.0000 - val_tn: 22657.0000 - val_fn: 3550.0000 - val_categorical_accuracy: 0.4989 - val_precision: 0.7972 - val_recall: 0.2256 - val_auc: 0.8381 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3069 - tp: 4331.0000 - fp: 1867.0000 - tn: 89813.0000 - fn: 14005.0000 - categorical_accuracy: 0.4785 - precision: 0.6988 - recall: 0.2362 - auc: 0.8185 - val_loss: 1.2141 - val_tp: 1119.0000 - val_fp: 332.0000 - val_tn: 22588.0000 - val_fn: 3465.0000 - val_categorical_accuracy: 0.5207 - val_precision: 0.7712 - val_recall: 0.2441 - val_auc: 0.8478 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2913 - tp: 4490.0000 - fp: 1941.0000 - tn: 89739.0000 - fn: 13846.0000 - categorical_accuracy: 0.4835 - precision: 0.6982 - recall: 0.2449 - auc: 0.8233 - val_loss: 1.1722 - val_tp: 1327.0000 - val_fp: 377.0000 - val_tn: 22543.0000 - val_fn: 3257.0000 - val_categorical_accuracy: 0.5432 - val_precision: 0.7788 - val_recall: 0.2895 - val_auc: 0.8596 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2784 - tp: 4617.0000 - fp: 2033.0000 - tn: 89647.0000 - fn: 13719.0000 - categorical_accuracy: 0.4865 - precision: 0.6943 - recall: 0.2518 - auc: 0.8276 - val_loss: 1.1892 - val_tp: 1243.0000 - val_fp: 355.0000 - val_tn: 22565.0000 - val_fn: 3341.0000 - val_categorical_accuracy: 0.5238 - val_precision: 0.7778 - val_recall: 0.2712 - val_auc: 0.8563 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2637 - tp: 4807.0000 - fp: 2113.0000 - tn: 89567.0000 - fn: 13529.0000 - categorical_accuracy: 0.4996 - precision: 0.6947 - recall: 0.2622 - auc: 0.8329 - val_loss: 1.1306 - val_tp: 1355.0000 - val_fp: 330.0000 - val_tn: 22590.0000 - val_fn: 3229.0000 - val_categorical_accuracy: 0.5569 - val_precision: 0.8042 - val_recall: 0.2956 - val_auc: 0.8719 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2421 - tp: 5182.0000 - fp: 2213.0000 - tn: 89467.0000 - fn: 13154.0000 - categorical_accuracy: 0.5104 - precision: 0.7007 - recall: 0.2826 - auc: 0.8388 - val_loss: 1.1561 - val_tp: 1319.0000 - val_fp: 361.0000 - val_tn: 22559.0000 - val_fn: 3265.0000 - val_categorical_accuracy: 0.5480 - val_precision: 0.7851 - val_recall: 0.2877 - val_auc: 0.8663 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2683 - tp: 4788.0000 - fp: 2055.0000 - tn: 89625.0000 - fn: 13548.0000 - categorical_accuracy: 0.4977 - precision: 0.6997 - recall: 0.2611 - auc: 0.8304 - val_loss: 1.1654 - val_tp: 1214.0000 - val_fp: 298.0000 - val_tn: 22622.0000 - val_fn: 3370.0000 - val_categorical_accuracy: 0.5480 - val_precision: 0.8029 - val_recall: 0.2648 - val_auc: 0.8634 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2683 - tp: 4785.0000 - fp: 2124.0000 - tn: 89556.0000 - fn: 13551.0000 - categorical_accuracy: 0.4978 - precision: 0.6926 - recall: 0.2610 - auc: 0.8311 - val_loss: 1.1639 - val_tp: 1289.0000 - val_fp: 355.0000 - val_tn: 22565.0000 - val_fn: 3295.0000 - val_categorical_accuracy: 0.5550 - val_precision: 0.7841 - val_recall: 0.2812 - val_auc: 0.8637 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2316 - tp: 5220.0000 - fp: 2183.0000 - tn: 89497.0000 - fn: 13116.0000 - categorical_accuracy: 0.5143 - precision: 0.7051 - recall: 0.2847 - auc: 0.8418 - val_loss: 1.1344 - val_tp: 1328.0000 - val_fp: 282.0000 - val_tn: 22638.0000 - val_fn: 3256.0000 - val_categorical_accuracy: 0.5556 - val_precision: 0.8248 - val_recall: 0.2897 - val_auc: 0.8706 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2385 - tp: 5073.0000 - fp: 1943.0000 - tn: 89737.0000 - fn: 13263.0000 - categorical_accuracy: 0.5092 - precision: 0.7231 - recall: 0.2767 - auc: 0.8393 - val_loss: 1.1238 - val_tp: 1347.0000 - val_fp: 274.0000 - val_tn: 22646.0000 - val_fn: 3237.0000 - val_categorical_accuracy: 0.5491 - val_precision: 0.8310 - val_recall: 0.2938 - val_auc: 0.8738 - lr: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2197 - tp: 5335.0000 - fp: 2137.0000 - tn: 89543.0000 - fn: 13001.0000 - categorical_accuracy: 0.5161 - precision: 0.7140 - recall: 0.2910 - auc: 0.8447 - val_loss: 1.1223 - val_tp: 1310.0000 - val_fp: 279.0000 - val_tn: 22641.0000 - val_fn: 3274.0000 - val_categorical_accuracy: 0.5578 - val_precision: 0.8244 - val_recall: 0.2858 - val_auc: 0.8742 - lr: 0.0053\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2264 - tp: 5222.0000 - fp: 2245.0000 - tn: 89435.0000 - fn: 13114.0000 - categorical_accuracy: 0.5119 - precision: 0.6993 - recall: 0.2848 - auc: 0.8427 - val_loss: 1.1357 - val_tp: 1396.0000 - val_fp: 393.0000 - val_tn: 22527.0000 - val_fn: 3188.0000 - val_categorical_accuracy: 0.5589 - val_precision: 0.7803 - val_recall: 0.3045 - val_auc: 0.8692 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2187 - tp: 5338.0000 - fp: 2162.0000 - tn: 89518.0000 - fn: 12998.0000 - categorical_accuracy: 0.5164 - precision: 0.7117 - recall: 0.2911 - auc: 0.8449 - val_loss: 1.1480 - val_tp: 1230.0000 - val_fp: 250.0000 - val_tn: 22670.0000 - val_fn: 3354.0000 - val_categorical_accuracy: 0.5591 - val_precision: 0.8311 - val_recall: 0.2683 - val_auc: 0.8685 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2226 - tp: 5341.0000 - fp: 2154.0000 - tn: 89526.0000 - fn: 12995.0000 - categorical_accuracy: 0.5197 - precision: 0.7126 - recall: 0.2913 - auc: 0.8439 - val_loss: 1.1291 - val_tp: 1332.0000 - val_fp: 256.0000 - val_tn: 22664.0000 - val_fn: 3252.0000 - val_categorical_accuracy: 0.5609 - val_precision: 0.8388 - val_recall: 0.2906 - val_auc: 0.8720 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2080 - tp: 5385.0000 - fp: 2046.0000 - tn: 89634.0000 - fn: 12951.0000 - categorical_accuracy: 0.5203 - precision: 0.7247 - recall: 0.2937 - auc: 0.8474 - val_loss: 1.1178 - val_tp: 1322.0000 - val_fp: 263.0000 - val_tn: 22657.0000 - val_fn: 3262.0000 - val_categorical_accuracy: 0.5670 - val_precision: 0.8341 - val_recall: 0.2884 - val_auc: 0.8743 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1971 - tp: 5612.0000 - fp: 2080.0000 - tn: 89600.0000 - fn: 12724.0000 - categorical_accuracy: 0.5296 - precision: 0.7296 - recall: 0.3061 - auc: 0.8513 - val_loss: 1.1426 - val_tp: 1279.0000 - val_fp: 300.0000 - val_tn: 22620.0000 - val_fn: 3305.0000 - val_categorical_accuracy: 0.5476 - val_precision: 0.8100 - val_recall: 0.2790 - val_auc: 0.8680 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1978 - tp: 5578.0000 - fp: 2137.0000 - tn: 89543.0000 - fn: 12758.0000 - categorical_accuracy: 0.5251 - precision: 0.7230 - recall: 0.3042 - auc: 0.8504 - val_loss: 1.1114 - val_tp: 1387.0000 - val_fp: 309.0000 - val_tn: 22611.0000 - val_fn: 3197.0000 - val_categorical_accuracy: 0.5613 - val_precision: 0.8178 - val_recall: 0.3026 - val_auc: 0.8751 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1868 - tp: 5706.0000 - fp: 2181.0000 - tn: 89499.0000 - fn: 12630.0000 - categorical_accuracy: 0.5321 - precision: 0.7235 - recall: 0.3112 - auc: 0.8541 - val_loss: 1.1295 - val_tp: 1396.0000 - val_fp: 350.0000 - val_tn: 22570.0000 - val_fn: 3188.0000 - val_categorical_accuracy: 0.5602 - val_precision: 0.7995 - val_recall: 0.3045 - val_auc: 0.8705 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1888 - tp: 5813.0000 - fp: 2384.0000 - tn: 89296.0000 - fn: 12523.0000 - categorical_accuracy: 0.5296 - precision: 0.7092 - recall: 0.3170 - auc: 0.8534 - val_loss: 1.1560 - val_tp: 1354.0000 - val_fp: 378.0000 - val_tn: 22542.0000 - val_fn: 3230.0000 - val_categorical_accuracy: 0.5495 - val_precision: 0.7818 - val_recall: 0.2954 - val_auc: 0.8641 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1761 - tp: 5726.0000 - fp: 2121.0000 - tn: 89559.0000 - fn: 12610.0000 - categorical_accuracy: 0.5357 - precision: 0.7297 - recall: 0.3123 - auc: 0.8566 - val_loss: 1.1170 - val_tp: 1323.0000 - val_fp: 278.0000 - val_tn: 22642.0000 - val_fn: 3261.0000 - val_categorical_accuracy: 0.5615 - val_precision: 0.8264 - val_recall: 0.2886 - val_auc: 0.8737 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1677 - tp: 5856.0000 - fp: 2216.0000 - tn: 89464.0000 - fn: 12480.0000 - categorical_accuracy: 0.5381 - precision: 0.7255 - recall: 0.3194 - auc: 0.8588 - val_loss: 1.0949 - val_tp: 1352.0000 - val_fp: 253.0000 - val_tn: 22667.0000 - val_fn: 3232.0000 - val_categorical_accuracy: 0.5628 - val_precision: 0.8424 - val_recall: 0.2949 - val_auc: 0.8795 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1453 - tp: 6042.0000 - fp: 2134.0000 - tn: 89546.0000 - fn: 12294.0000 - categorical_accuracy: 0.5500 - precision: 0.7390 - recall: 0.3295 - auc: 0.8648 - val_loss: 1.0903 - val_tp: 1382.0000 - val_fp: 270.0000 - val_tn: 22650.0000 - val_fn: 3202.0000 - val_categorical_accuracy: 0.5650 - val_precision: 0.8366 - val_recall: 0.3015 - val_auc: 0.8805 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1503 - tp: 5924.0000 - fp: 2024.0000 - tn: 89656.0000 - fn: 12412.0000 - categorical_accuracy: 0.5440 - precision: 0.7453 - recall: 0.3231 - auc: 0.8632 - val_loss: 1.0987 - val_tp: 1410.0000 - val_fp: 298.0000 - val_tn: 22622.0000 - val_fn: 3174.0000 - val_categorical_accuracy: 0.5639 - val_precision: 0.8255 - val_recall: 0.3076 - val_auc: 0.8772 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1391 - tp: 6260.0000 - fp: 2440.0000 - tn: 89240.0000 - fn: 12076.0000 - categorical_accuracy: 0.5506 - precision: 0.7195 - recall: 0.3414 - auc: 0.8664 - val_loss: 1.0790 - val_tp: 1454.0000 - val_fp: 319.0000 - val_tn: 22601.0000 - val_fn: 3130.0000 - val_categorical_accuracy: 0.5733 - val_precision: 0.8201 - val_recall: 0.3172 - val_auc: 0.8830 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1483 - tp: 6043.0000 - fp: 2191.0000 - tn: 89489.0000 - fn: 12293.0000 - categorical_accuracy: 0.5486 - precision: 0.7339 - recall: 0.3296 - auc: 0.8640 - val_loss: 1.0903 - val_tp: 1423.0000 - val_fp: 297.0000 - val_tn: 22623.0000 - val_fn: 3161.0000 - val_categorical_accuracy: 0.5657 - val_precision: 0.8273 - val_recall: 0.3104 - val_auc: 0.8800 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1369 - tp: 5992.0000 - fp: 2052.0000 - tn: 89628.0000 - fn: 12344.0000 - categorical_accuracy: 0.5545 - precision: 0.7449 - recall: 0.3268 - auc: 0.8666 - val_loss: 1.0561 - val_tp: 1460.0000 - val_fp: 252.0000 - val_tn: 22668.0000 - val_fn: 3124.0000 - val_categorical_accuracy: 0.5831 - val_precision: 0.8528 - val_recall: 0.3185 - val_auc: 0.8881 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1239 - tp: 6301.0000 - fp: 2157.0000 - tn: 89523.0000 - fn: 12035.0000 - categorical_accuracy: 0.5581 - precision: 0.7450 - recall: 0.3436 - auc: 0.8699 - val_loss: 1.0681 - val_tp: 1452.0000 - val_fp: 258.0000 - val_tn: 22662.0000 - val_fn: 3132.0000 - val_categorical_accuracy: 0.5781 - val_precision: 0.8491 - val_recall: 0.3168 - val_auc: 0.8849 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1188 - tp: 6339.0000 - fp: 2138.0000 - tn: 89542.0000 - fn: 11997.0000 - categorical_accuracy: 0.5645 - precision: 0.7478 - recall: 0.3457 - auc: 0.8712 - val_loss: 1.0600 - val_tp: 1541.0000 - val_fp: 400.0000 - val_tn: 22520.0000 - val_fn: 3043.0000 - val_categorical_accuracy: 0.5801 - val_precision: 0.7939 - val_recall: 0.3362 - val_auc: 0.8868 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0955 - tp: 6479.0000 - fp: 2117.0000 - tn: 89563.0000 - fn: 11857.0000 - categorical_accuracy: 0.5670 - precision: 0.7537 - recall: 0.3533 - auc: 0.8766 - val_loss: 1.0260 - val_tp: 1535.0000 - val_fp: 289.0000 - val_tn: 22631.0000 - val_fn: 3049.0000 - val_categorical_accuracy: 0.5886 - val_precision: 0.8416 - val_recall: 0.3349 - val_auc: 0.8941 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1062 - tp: 6426.0000 - fp: 2076.0000 - tn: 89604.0000 - fn: 11910.0000 - categorical_accuracy: 0.5644 - precision: 0.7558 - recall: 0.3505 - auc: 0.8742 - val_loss: 1.0675 - val_tp: 1450.0000 - val_fp: 231.0000 - val_tn: 22689.0000 - val_fn: 3134.0000 - val_categorical_accuracy: 0.5731 - val_precision: 0.8626 - val_recall: 0.3163 - val_auc: 0.8841 - lr: 0.0022\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0833 - tp: 6564.0000 - fp: 1961.0000 - tn: 89719.0000 - fn: 11772.0000 - categorical_accuracy: 0.5742 - precision: 0.7700 - recall: 0.3580 - auc: 0.8795 - val_loss: 1.0293 - val_tp: 1508.0000 - val_fp: 244.0000 - val_tn: 22676.0000 - val_fn: 3076.0000 - val_categorical_accuracy: 0.5923 - val_precision: 0.8607 - val_recall: 0.3290 - val_auc: 0.8929 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0786 - tp: 6735.0000 - fp: 2173.0000 - tn: 89507.0000 - fn: 11601.0000 - categorical_accuracy: 0.5775 - precision: 0.7561 - recall: 0.3673 - auc: 0.8806 - val_loss: 1.0312 - val_tp: 1555.0000 - val_fp: 256.0000 - val_tn: 22664.0000 - val_fn: 3029.0000 - val_categorical_accuracy: 0.5923 - val_precision: 0.8586 - val_recall: 0.3392 - val_auc: 0.8929 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0829 - tp: 6769.0000 - fp: 2205.0000 - tn: 89475.0000 - fn: 11567.0000 - categorical_accuracy: 0.5748 - precision: 0.7543 - recall: 0.3692 - auc: 0.8794 - val_loss: 1.0259 - val_tp: 1585.0000 - val_fp: 265.0000 - val_tn: 22655.0000 - val_fn: 2999.0000 - val_categorical_accuracy: 0.5929 - val_precision: 0.8568 - val_recall: 0.3458 - val_auc: 0.8939 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0716 - tp: 6610.0000 - fp: 1982.0000 - tn: 89698.0000 - fn: 11726.0000 - categorical_accuracy: 0.5766 - precision: 0.7693 - recall: 0.3605 - auc: 0.8819 - val_loss: 1.0235 - val_tp: 1603.0000 - val_fp: 293.0000 - val_tn: 22627.0000 - val_fn: 2981.0000 - val_categorical_accuracy: 0.5962 - val_precision: 0.8455 - val_recall: 0.3497 - val_auc: 0.8946 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0625 - tp: 6840.0000 - fp: 2139.0000 - tn: 89541.0000 - fn: 11496.0000 - categorical_accuracy: 0.5783 - precision: 0.7618 - recall: 0.3730 - auc: 0.8839 - val_loss: 1.0282 - val_tp: 1538.0000 - val_fp: 242.0000 - val_tn: 22678.0000 - val_fn: 3046.0000 - val_categorical_accuracy: 0.5932 - val_precision: 0.8640 - val_recall: 0.3355 - val_auc: 0.8932 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0783 - tp: 6740.0000 - fp: 2090.0000 - tn: 89590.0000 - fn: 11596.0000 - categorical_accuracy: 0.5747 - precision: 0.7633 - recall: 0.3676 - auc: 0.8808 - val_loss: 1.0092 - val_tp: 1563.0000 - val_fp: 245.0000 - val_tn: 22675.0000 - val_fn: 3021.0000 - val_categorical_accuracy: 0.6001 - val_precision: 0.8645 - val_recall: 0.3410 - val_auc: 0.8978 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0536 - tp: 6793.0000 - fp: 1978.0000 - tn: 89702.0000 - fn: 11543.0000 - categorical_accuracy: 0.5846 - precision: 0.7745 - recall: 0.3705 - auc: 0.8863 - val_loss: 0.9943 - val_tp: 1683.0000 - val_fp: 377.0000 - val_tn: 22543.0000 - val_fn: 2901.0000 - val_categorical_accuracy: 0.6038 - val_precision: 0.8170 - val_recall: 0.3671 - val_auc: 0.9002 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0517 - tp: 7139.0000 - fp: 2255.0000 - tn: 89425.0000 - fn: 11197.0000 - categorical_accuracy: 0.5889 - precision: 0.7600 - recall: 0.3893 - auc: 0.8868 - val_loss: 1.0105 - val_tp: 1647.0000 - val_fp: 356.0000 - val_tn: 22564.0000 - val_fn: 2937.0000 - val_categorical_accuracy: 0.5953 - val_precision: 0.8223 - val_recall: 0.3593 - val_auc: 0.8967 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0504 - tp: 7095.0000 - fp: 2307.0000 - tn: 89373.0000 - fn: 11241.0000 - categorical_accuracy: 0.5865 - precision: 0.7546 - recall: 0.3869 - auc: 0.8868 - val_loss: 1.0086 - val_tp: 1649.0000 - val_fp: 349.0000 - val_tn: 22571.0000 - val_fn: 2935.0000 - val_categorical_accuracy: 0.5973 - val_precision: 0.8253 - val_recall: 0.3597 - val_auc: 0.8977 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0514 - tp: 7242.0000 - fp: 2388.0000 - tn: 89292.0000 - fn: 11094.0000 - categorical_accuracy: 0.5864 - precision: 0.7520 - recall: 0.3950 - auc: 0.8865 - val_loss: 1.0046 - val_tp: 1589.0000 - val_fp: 268.0000 - val_tn: 22652.0000 - val_fn: 2995.0000 - val_categorical_accuracy: 0.5969 - val_precision: 0.8557 - val_recall: 0.3466 - val_auc: 0.8986 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0458 - tp: 7074.0000 - fp: 2206.0000 - tn: 89474.0000 - fn: 11262.0000 - categorical_accuracy: 0.5917 - precision: 0.7623 - recall: 0.3858 - auc: 0.8881 - val_loss: 0.9919 - val_tp: 1677.0000 - val_fp: 326.0000 - val_tn: 22594.0000 - val_fn: 2907.0000 - val_categorical_accuracy: 0.6032 - val_precision: 0.8372 - val_recall: 0.3658 - val_auc: 0.9005 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0404 - tp: 7451.0000 - fp: 2474.0000 - tn: 89206.0000 - fn: 10885.0000 - categorical_accuracy: 0.5940 - precision: 0.7507 - recall: 0.4064 - auc: 0.8894 - val_loss: 0.9963 - val_tp: 1747.0000 - val_fp: 397.0000 - val_tn: 22523.0000 - val_fn: 2837.0000 - val_categorical_accuracy: 0.6045 - val_precision: 0.8148 - val_recall: 0.3811 - val_auc: 0.9000 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0350 - tp: 7432.0000 - fp: 2386.0000 - tn: 89294.0000 - fn: 10904.0000 - categorical_accuracy: 0.5947 - precision: 0.7570 - recall: 0.4053 - auc: 0.8906 - val_loss: 0.9867 - val_tp: 1731.0000 - val_fp: 392.0000 - val_tn: 22528.0000 - val_fn: 2853.0000 - val_categorical_accuracy: 0.6080 - val_precision: 0.8154 - val_recall: 0.3776 - val_auc: 0.9020 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0245 - tp: 7487.0000 - fp: 2400.0000 - tn: 89280.0000 - fn: 10849.0000 - categorical_accuracy: 0.5961 - precision: 0.7573 - recall: 0.4083 - auc: 0.8926 - val_loss: 0.9891 - val_tp: 1690.0000 - val_fp: 331.0000 - val_tn: 22589.0000 - val_fn: 2894.0000 - val_categorical_accuracy: 0.6071 - val_precision: 0.8362 - val_recall: 0.3687 - val_auc: 0.9013 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0267 - tp: 7564.0000 - fp: 2573.0000 - tn: 89107.0000 - fn: 10772.0000 - categorical_accuracy: 0.5945 - precision: 0.7462 - recall: 0.4125 - auc: 0.8922 - val_loss: 0.9825 - val_tp: 1783.0000 - val_fp: 366.0000 - val_tn: 22554.0000 - val_fn: 2801.0000 - val_categorical_accuracy: 0.6086 - val_precision: 0.8297 - val_recall: 0.3890 - val_auc: 0.9027 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0200 - tp: 7561.0000 - fp: 2534.0000 - tn: 89146.0000 - fn: 10775.0000 - categorical_accuracy: 0.6005 - precision: 0.7490 - recall: 0.4124 - auc: 0.8937 - val_loss: 0.9795 - val_tp: 1993.0000 - val_fp: 606.0000 - val_tn: 22314.0000 - val_fn: 2591.0000 - val_categorical_accuracy: 0.6089 - val_precision: 0.7668 - val_recall: 0.4348 - val_auc: 0.9027 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0003 - tp: 8011.0000 - fp: 2719.0000 - tn: 88961.0000 - fn: 10325.0000 - categorical_accuracy: 0.6063 - precision: 0.7466 - recall: 0.4369 - auc: 0.8977 - val_loss: 0.9730 - val_tp: 2055.0000 - val_fp: 674.0000 - val_tn: 22246.0000 - val_fn: 2529.0000 - val_categorical_accuracy: 0.6095 - val_precision: 0.7530 - val_recall: 0.4483 - val_auc: 0.9041 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0115 - tp: 8029.0000 - fp: 2804.0000 - tn: 88876.0000 - fn: 10307.0000 - categorical_accuracy: 0.6024 - precision: 0.7412 - recall: 0.4379 - auc: 0.8955 - val_loss: 0.9773 - val_tp: 2044.0000 - val_fp: 678.0000 - val_tn: 22242.0000 - val_fn: 2540.0000 - val_categorical_accuracy: 0.6069 - val_precision: 0.7509 - val_recall: 0.4459 - val_auc: 0.9037 - lr: 7.0388e-04\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0116 - tp: 7941.0000 - fp: 2687.0000 - tn: 88993.0000 - fn: 10395.0000 - categorical_accuracy: 0.6057 - precision: 0.7472 - recall: 0.4331 - auc: 0.8954 - val_loss: 0.9722 - val_tp: 1955.0000 - val_fp: 551.0000 - val_tn: 22369.0000 - val_fn: 2629.0000 - val_categorical_accuracy: 0.6128 - val_precision: 0.7801 - val_recall: 0.4265 - val_auc: 0.9043 - lr: 6.5477e-04\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0050 - tp: 7806.0000 - fp: 2509.0000 - tn: 89171.0000 - fn: 10530.0000 - categorical_accuracy: 0.6042 - precision: 0.7568 - recall: 0.4257 - auc: 0.8969 - val_loss: 0.9642 - val_tp: 2022.0000 - val_fp: 618.0000 - val_tn: 22302.0000 - val_fn: 2562.0000 - val_categorical_accuracy: 0.6163 - val_precision: 0.7659 - val_recall: 0.4411 - val_auc: 0.9061 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9952 - tp: 8081.0000 - fp: 2699.0000 - tn: 88981.0000 - fn: 10255.0000 - categorical_accuracy: 0.6055 - precision: 0.7496 - recall: 0.4407 - auc: 0.8989 - val_loss: 0.9715 - val_tp: 2042.0000 - val_fp: 657.0000 - val_tn: 22263.0000 - val_fn: 2542.0000 - val_categorical_accuracy: 0.6102 - val_precision: 0.7566 - val_recall: 0.4455 - val_auc: 0.9045 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9977 - tp: 7998.0000 - fp: 2642.0000 - tn: 89038.0000 - fn: 10338.0000 - categorical_accuracy: 0.6075 - precision: 0.7517 - recall: 0.4362 - auc: 0.8981 - val_loss: 0.9651 - val_tp: 1983.0000 - val_fp: 569.0000 - val_tn: 22351.0000 - val_fn: 2601.0000 - val_categorical_accuracy: 0.6145 - val_precision: 0.7770 - val_recall: 0.4326 - val_auc: 0.9059 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9927 - tp: 8066.0000 - fp: 2630.0000 - tn: 89050.0000 - fn: 10270.0000 - categorical_accuracy: 0.6084 - precision: 0.7541 - recall: 0.4399 - auc: 0.8994 - val_loss: 0.9611 - val_tp: 1995.0000 - val_fp: 556.0000 - val_tn: 22364.0000 - val_fn: 2589.0000 - val_categorical_accuracy: 0.6154 - val_precision: 0.7820 - val_recall: 0.4352 - val_auc: 0.9065 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9863 - tp: 8014.0000 - fp: 2466.0000 - tn: 89214.0000 - fn: 10322.0000 - categorical_accuracy: 0.6111 - precision: 0.7647 - recall: 0.4371 - auc: 0.9007 - val_loss: 0.9614 - val_tp: 2030.0000 - val_fp: 623.0000 - val_tn: 22297.0000 - val_fn: 2554.0000 - val_categorical_accuracy: 0.6130 - val_precision: 0.7652 - val_recall: 0.4428 - val_auc: 0.9064 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9859 - tp: 8011.0000 - fp: 2634.0000 - tn: 89046.0000 - fn: 10325.0000 - categorical_accuracy: 0.6074 - precision: 0.7526 - recall: 0.4369 - auc: 0.9004 - val_loss: 0.9580 - val_tp: 1971.0000 - val_fp: 541.0000 - val_tn: 22379.0000 - val_fn: 2613.0000 - val_categorical_accuracy: 0.6209 - val_precision: 0.7846 - val_recall: 0.4300 - val_auc: 0.9072 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9777 - tp: 8098.0000 - fp: 2468.0000 - tn: 89212.0000 - fn: 10238.0000 - categorical_accuracy: 0.6141 - precision: 0.7664 - recall: 0.4416 - auc: 0.9023 - val_loss: 0.9524 - val_tp: 2006.0000 - val_fp: 562.0000 - val_tn: 22358.0000 - val_fn: 2578.0000 - val_categorical_accuracy: 0.6217 - val_precision: 0.7812 - val_recall: 0.4376 - val_auc: 0.9083 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9792 - tp: 8095.0000 - fp: 2500.0000 - tn: 89180.0000 - fn: 10241.0000 - categorical_accuracy: 0.6119 - precision: 0.7640 - recall: 0.4415 - auc: 0.9023 - val_loss: 0.9530 - val_tp: 2011.0000 - val_fp: 588.0000 - val_tn: 22332.0000 - val_fn: 2573.0000 - val_categorical_accuracy: 0.6248 - val_precision: 0.7738 - val_recall: 0.4387 - val_auc: 0.9081 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9789 - tp: 8105.0000 - fp: 2551.0000 - tn: 89129.0000 - fn: 10231.0000 - categorical_accuracy: 0.6128 - precision: 0.7606 - recall: 0.4420 - auc: 0.9022 - val_loss: 0.9454 - val_tp: 2065.0000 - val_fp: 575.0000 - val_tn: 22345.0000 - val_fn: 2519.0000 - val_categorical_accuracy: 0.6215 - val_precision: 0.7822 - val_recall: 0.4505 - val_auc: 0.9097 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9742 - tp: 8199.0000 - fp: 2532.0000 - tn: 89148.0000 - fn: 10137.0000 - categorical_accuracy: 0.6174 - precision: 0.7640 - recall: 0.4472 - auc: 0.9033 - val_loss: 0.9413 - val_tp: 2062.0000 - val_fp: 574.0000 - val_tn: 22346.0000 - val_fn: 2522.0000 - val_categorical_accuracy: 0.6224 - val_precision: 0.7822 - val_recall: 0.4498 - val_auc: 0.9105 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9741 - tp: 8051.0000 - fp: 2472.0000 - tn: 89208.0000 - fn: 10285.0000 - categorical_accuracy: 0.6169 - precision: 0.7651 - recall: 0.4391 - auc: 0.9034 - val_loss: 0.9406 - val_tp: 2094.0000 - val_fp: 614.0000 - val_tn: 22306.0000 - val_fn: 2490.0000 - val_categorical_accuracy: 0.6233 - val_precision: 0.7733 - val_recall: 0.4568 - val_auc: 0.9105 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9730 - tp: 8228.0000 - fp: 2536.0000 - tn: 89144.0000 - fn: 10108.0000 - categorical_accuracy: 0.6179 - precision: 0.7644 - recall: 0.4487 - auc: 0.9036 - val_loss: 0.9432 - val_tp: 2077.0000 - val_fp: 617.0000 - val_tn: 22303.0000 - val_fn: 2507.0000 - val_categorical_accuracy: 0.6243 - val_precision: 0.7710 - val_recall: 0.4531 - val_auc: 0.9101 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9687 - tp: 8290.0000 - fp: 2529.0000 - tn: 89151.0000 - fn: 10046.0000 - categorical_accuracy: 0.6167 - precision: 0.7662 - recall: 0.4521 - auc: 0.9044 - val_loss: 0.9420 - val_tp: 2067.0000 - val_fp: 617.0000 - val_tn: 22303.0000 - val_fn: 2517.0000 - val_categorical_accuracy: 0.6235 - val_precision: 0.7701 - val_recall: 0.4509 - val_auc: 0.9102 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9660 - tp: 8284.0000 - fp: 2534.0000 - tn: 89146.0000 - fn: 10052.0000 - categorical_accuracy: 0.6205 - precision: 0.7658 - recall: 0.4518 - auc: 0.9049 - val_loss: 0.9416 - val_tp: 2090.0000 - val_fp: 619.0000 - val_tn: 22301.0000 - val_fn: 2494.0000 - val_categorical_accuracy: 0.6219 - val_precision: 0.7715 - val_recall: 0.4559 - val_auc: 0.9103 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9637 - tp: 8278.0000 - fp: 2557.0000 - tn: 89123.0000 - fn: 10058.0000 - categorical_accuracy: 0.6215 - precision: 0.7640 - recall: 0.4515 - auc: 0.9053 - val_loss: 0.9429 - val_tp: 2101.0000 - val_fp: 607.0000 - val_tn: 22313.0000 - val_fn: 2483.0000 - val_categorical_accuracy: 0.6204 - val_precision: 0.7758 - val_recall: 0.4583 - val_auc: 0.9101 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9606 - tp: 8314.0000 - fp: 2538.0000 - tn: 89142.0000 - fn: 10022.0000 - categorical_accuracy: 0.6212 - precision: 0.7661 - recall: 0.4534 - auc: 0.9058 - val_loss: 0.9422 - val_tp: 2111.0000 - val_fp: 629.0000 - val_tn: 22291.0000 - val_fn: 2473.0000 - val_categorical_accuracy: 0.6230 - val_precision: 0.7704 - val_recall: 0.4605 - val_auc: 0.9099 - lr: 1.8151e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9628 - tp: 8375.0000 - fp: 2554.0000 - tn: 89126.0000 - fn: 9961.0000 - categorical_accuracy: 0.6216 - precision: 0.7663 - recall: 0.4568 - auc: 0.9053 - val_loss: 0.9427 - val_tp: 2097.0000 - val_fp: 622.0000 - val_tn: 22298.0000 - val_fn: 2487.0000 - val_categorical_accuracy: 0.6246 - val_precision: 0.7712 - val_recall: 0.4575 - val_auc: 0.9101 - lr: 1.6621e-04\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9618 - tp: 8376.0000 - fp: 2563.0000 - tn: 89117.0000 - fn: 9960.0000 - categorical_accuracy: 0.6228 - precision: 0.7657 - recall: 0.4568 - auc: 0.9056 - val_loss: 0.9397 - val_tp: 2100.0000 - val_fp: 621.0000 - val_tn: 22299.0000 - val_fn: 2484.0000 - val_categorical_accuracy: 0.6243 - val_precision: 0.7718 - val_recall: 0.4581 - val_auc: 0.9107 - lr: 1.5207e-04\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9623 - tp: 8330.0000 - fp: 2665.0000 - tn: 89015.0000 - fn: 10006.0000 - categorical_accuracy: 0.6217 - precision: 0.7576 - recall: 0.4543 - auc: 0.9058 - val_loss: 0.9401 - val_tp: 2124.0000 - val_fp: 648.0000 - val_tn: 22272.0000 - val_fn: 2460.0000 - val_categorical_accuracy: 0.6241 - val_precision: 0.7662 - val_recall: 0.4634 - val_auc: 0.9105 - lr: 1.3900e-04\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9605 - tp: 8322.0000 - fp: 2573.0000 - tn: 89107.0000 - fn: 10014.0000 - categorical_accuracy: 0.6195 - precision: 0.7638 - recall: 0.4539 - auc: 0.9058 - val_loss: 0.9374 - val_tp: 2120.0000 - val_fp: 620.0000 - val_tn: 22300.0000 - val_fn: 2464.0000 - val_categorical_accuracy: 0.6224 - val_precision: 0.7737 - val_recall: 0.4625 - val_auc: 0.9112 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9558 - tp: 8447.0000 - fp: 2626.0000 - tn: 89054.0000 - fn: 9889.0000 - categorical_accuracy: 0.6215 - precision: 0.7628 - recall: 0.4607 - auc: 0.9069 - val_loss: 0.9358 - val_tp: 2110.0000 - val_fp: 617.0000 - val_tn: 22303.0000 - val_fn: 2474.0000 - val_categorical_accuracy: 0.6246 - val_precision: 0.7737 - val_recall: 0.4603 - val_auc: 0.9115 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9526 - tp: 8431.0000 - fp: 2587.0000 - tn: 89093.0000 - fn: 9905.0000 - categorical_accuracy: 0.6227 - precision: 0.7652 - recall: 0.4598 - auc: 0.9076 - val_loss: 0.9377 - val_tp: 2098.0000 - val_fp: 616.0000 - val_tn: 22304.0000 - val_fn: 2486.0000 - val_categorical_accuracy: 0.6230 - val_precision: 0.7730 - val_recall: 0.4577 - val_auc: 0.9111 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9497 - tp: 8384.0000 - fp: 2504.0000 - tn: 89176.0000 - fn: 9952.0000 - categorical_accuracy: 0.6282 - precision: 0.7700 - recall: 0.4572 - auc: 0.9081 - val_loss: 0.9367 - val_tp: 2097.0000 - val_fp: 610.0000 - val_tn: 22310.0000 - val_fn: 2487.0000 - val_categorical_accuracy: 0.6237 - val_precision: 0.7747 - val_recall: 0.4575 - val_auc: 0.9112 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9549 - tp: 8386.0000 - fp: 2576.0000 - tn: 89104.0000 - fn: 9950.0000 - categorical_accuracy: 0.6250 - precision: 0.7650 - recall: 0.4574 - auc: 0.9070 - val_loss: 0.9344 - val_tp: 2100.0000 - val_fp: 604.0000 - val_tn: 22316.0000 - val_fn: 2484.0000 - val_categorical_accuracy: 0.6252 - val_precision: 0.7766 - val_recall: 0.4581 - val_auc: 0.9117 - lr: 8.7498e-05\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 1.0115 - tp: 2410.0000 - fp: 827.0000 - tn: 27823.0000 - fn: 3320.0000 - categorical_accuracy: 0.5756 - precision: 0.7445 - recall: 0.4206 - auc: 0.8931\n",
      "====================== FOLD: 3 ======================\n",
      "Train: [    0     1     2 ... 28647 28648 28649]\n",
      "Test: [ 2865  2866  2867 ... 27692 27693 27694]\n",
      "Intersection: []\n",
      "TRAIN: [    0     1     2 ... 28647 28648 28649] TEST: [ 2865  2866  2867 ... 27692 27693 27694]\n",
      "Train shapes: (22920, 1280, 6) (22920,) Test shapes: (5730, 1280, 6) (5730,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_radar_i (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_q (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_dist (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_pulse (InputLayer)  [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_resp (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_heartSound (InputLa [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           40992       input_radar_i[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           40992       input_radar_q[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           40992       input_radar_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           40992       input_radar_pulse[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           40992       input_radar_resp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           40992       input_radar_heartSound[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 48)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1568        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 252,134\n",
      "Trainable params: 252,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/144 [..............................] - ETA: 20s - loss: 1.0337 - tp: 2122.0000 - fp: 693.0000 - tn: 23507.0000 - fn: 2718.0000 - categorical_accuracy: 0.5992 - precision: 0.7538 - recall: 0.4384 - auc: 0.8941WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.139138). Check your callbacks.\n",
      "144/144 [==============================] - 3s 20ms/step - loss: 1.5583 - tp: 2695.0000 - fp: 1119.0000 - tn: 113481.0000 - fn: 20225.0000 - categorical_accuracy: 0.3422 - precision: 0.7066 - recall: 0.1176 - auc: 0.7145 - val_loss: 1.4801 - val_tp: 542.0000 - val_fp: 177.0000 - val_tn: 22743.0000 - val_fn: 4042.0000 - val_categorical_accuracy: 0.3746 - val_precision: 0.7538 - val_recall: 0.1182 - val_auc: 0.7639 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.5154 - tp: 1753.0000 - fp: 942.0000 - tn: 90738.0000 - fn: 16583.0000 - categorical_accuracy: 0.3626 - precision: 0.6505 - recall: 0.0956 - auc: 0.7444 - val_loss: 1.3959 - val_tp: 498.0000 - val_fp: 100.0000 - val_tn: 22820.0000 - val_fn: 4086.0000 - val_categorical_accuracy: 0.4402 - val_precision: 0.8328 - val_recall: 0.1086 - val_auc: 0.7974 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.4466 - tp: 2048.0000 - fp: 1127.0000 - tn: 90553.0000 - fn: 16288.0000 - categorical_accuracy: 0.4018 - precision: 0.6450 - recall: 0.1117 - auc: 0.7747 - val_loss: 1.3118 - val_tp: 610.0000 - val_fp: 170.0000 - val_tn: 22750.0000 - val_fn: 3974.0000 - val_categorical_accuracy: 0.4682 - val_precision: 0.7821 - val_recall: 0.1331 - val_auc: 0.8209 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3931 - tp: 2477.0000 - fp: 1223.0000 - tn: 90457.0000 - fn: 15859.0000 - categorical_accuracy: 0.4264 - precision: 0.6695 - recall: 0.1351 - auc: 0.7932 - val_loss: 1.2627 - val_tp: 800.0000 - val_fp: 217.0000 - val_tn: 22703.0000 - val_fn: 3784.0000 - val_categorical_accuracy: 0.4788 - val_precision: 0.7866 - val_recall: 0.1745 - val_auc: 0.8335 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3712 - tp: 3049.0000 - fp: 1498.0000 - tn: 90182.0000 - fn: 15287.0000 - categorical_accuracy: 0.4378 - precision: 0.6706 - recall: 0.1663 - auc: 0.7991 - val_loss: 1.2907 - val_tp: 803.0000 - val_fp: 199.0000 - val_tn: 22721.0000 - val_fn: 3781.0000 - val_categorical_accuracy: 0.4884 - val_precision: 0.8014 - val_recall: 0.1752 - val_auc: 0.8291 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3756 - tp: 3088.0000 - fp: 1486.0000 - tn: 90194.0000 - fn: 15248.0000 - categorical_accuracy: 0.4418 - precision: 0.6751 - recall: 0.1684 - auc: 0.7985 - val_loss: 1.2775 - val_tp: 966.0000 - val_fp: 294.0000 - val_tn: 22626.0000 - val_fn: 3618.0000 - val_categorical_accuracy: 0.4843 - val_precision: 0.7667 - val_recall: 0.2107 - val_auc: 0.8325 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3591 - tp: 3428.0000 - fp: 1538.0000 - tn: 90142.0000 - fn: 14908.0000 - categorical_accuracy: 0.4496 - precision: 0.6903 - recall: 0.1870 - auc: 0.8023 - val_loss: 1.2095 - val_tp: 1021.0000 - val_fp: 256.0000 - val_tn: 22664.0000 - val_fn: 3563.0000 - val_categorical_accuracy: 0.4904 - val_precision: 0.7995 - val_recall: 0.2227 - val_auc: 0.8513 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3646 - tp: 3474.0000 - fp: 1676.0000 - tn: 90004.0000 - fn: 14862.0000 - categorical_accuracy: 0.4403 - precision: 0.6746 - recall: 0.1895 - auc: 0.7998 - val_loss: 1.3130 - val_tp: 753.0000 - val_fp: 184.0000 - val_tn: 22736.0000 - val_fn: 3831.0000 - val_categorical_accuracy: 0.4729 - val_precision: 0.8036 - val_recall: 0.1643 - val_auc: 0.8239 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3625 - tp: 3499.0000 - fp: 1610.0000 - tn: 90070.0000 - fn: 14837.0000 - categorical_accuracy: 0.4482 - precision: 0.6849 - recall: 0.1908 - auc: 0.8007 - val_loss: 1.2532 - val_tp: 1090.0000 - val_fp: 415.0000 - val_tn: 22505.0000 - val_fn: 3494.0000 - val_categorical_accuracy: 0.4926 - val_precision: 0.7243 - val_recall: 0.2378 - val_auc: 0.8373 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3637 - tp: 3521.0000 - fp: 1699.0000 - tn: 89981.0000 - fn: 14815.0000 - categorical_accuracy: 0.4423 - precision: 0.6745 - recall: 0.1920 - auc: 0.8010 - val_loss: 1.2511 - val_tp: 1219.0000 - val_fp: 450.0000 - val_tn: 22470.0000 - val_fn: 3365.0000 - val_categorical_accuracy: 0.4865 - val_precision: 0.7304 - val_recall: 0.2659 - val_auc: 0.8356 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3588 - tp: 3536.0000 - fp: 1555.0000 - tn: 90125.0000 - fn: 14800.0000 - categorical_accuracy: 0.4470 - precision: 0.6946 - recall: 0.1928 - auc: 0.8021 - val_loss: 1.1725 - val_tp: 1187.0000 - val_fp: 282.0000 - val_tn: 22638.0000 - val_fn: 3397.0000 - val_categorical_accuracy: 0.5133 - val_precision: 0.8080 - val_recall: 0.2589 - val_auc: 0.8594 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3364 - tp: 3714.0000 - fp: 1550.0000 - tn: 90130.0000 - fn: 14622.0000 - categorical_accuracy: 0.4568 - precision: 0.7055 - recall: 0.2026 - auc: 0.8101 - val_loss: 1.1846 - val_tp: 1227.0000 - val_fp: 278.0000 - val_tn: 22642.0000 - val_fn: 3357.0000 - val_categorical_accuracy: 0.5185 - val_precision: 0.8153 - val_recall: 0.2677 - val_auc: 0.8575 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3249 - tp: 3903.0000 - fp: 1652.0000 - tn: 90028.0000 - fn: 14433.0000 - categorical_accuracy: 0.4627 - precision: 0.7026 - recall: 0.2129 - auc: 0.8131 - val_loss: 1.2066 - val_tp: 1011.0000 - val_fp: 192.0000 - val_tn: 22728.0000 - val_fn: 3573.0000 - val_categorical_accuracy: 0.5105 - val_precision: 0.8404 - val_recall: 0.2205 - val_auc: 0.8533 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3445 - tp: 3813.0000 - fp: 1712.0000 - tn: 89968.0000 - fn: 14523.0000 - categorical_accuracy: 0.4578 - precision: 0.6901 - recall: 0.2080 - auc: 0.8073 - val_loss: 1.1919 - val_tp: 1110.0000 - val_fp: 195.0000 - val_tn: 22725.0000 - val_fn: 3474.0000 - val_categorical_accuracy: 0.5094 - val_precision: 0.8506 - val_recall: 0.2421 - val_auc: 0.8588 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3233 - tp: 3944.0000 - fp: 1706.0000 - tn: 89974.0000 - fn: 14392.0000 - categorical_accuracy: 0.4584 - precision: 0.6981 - recall: 0.2151 - auc: 0.8128 - val_loss: 1.1855 - val_tp: 1108.0000 - val_fp: 224.0000 - val_tn: 22696.0000 - val_fn: 3476.0000 - val_categorical_accuracy: 0.5039 - val_precision: 0.8318 - val_recall: 0.2417 - val_auc: 0.8586 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3212 - tp: 3977.0000 - fp: 1697.0000 - tn: 89983.0000 - fn: 14359.0000 - categorical_accuracy: 0.4576 - precision: 0.7009 - recall: 0.2169 - auc: 0.8126 - val_loss: 1.2181 - val_tp: 1152.0000 - val_fp: 292.0000 - val_tn: 22628.0000 - val_fn: 3432.0000 - val_categorical_accuracy: 0.5055 - val_precision: 0.7978 - val_recall: 0.2513 - val_auc: 0.8454 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3169 - tp: 4062.0000 - fp: 1657.0000 - tn: 90023.0000 - fn: 14274.0000 - categorical_accuracy: 0.4624 - precision: 0.7103 - recall: 0.2215 - auc: 0.8150 - val_loss: 1.2136 - val_tp: 1155.0000 - val_fp: 307.0000 - val_tn: 22613.0000 - val_fn: 3429.0000 - val_categorical_accuracy: 0.5079 - val_precision: 0.7900 - val_recall: 0.2520 - val_auc: 0.8496 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3212 - tp: 4026.0000 - fp: 1641.0000 - tn: 90039.0000 - fn: 14310.0000 - categorical_accuracy: 0.4605 - precision: 0.7104 - recall: 0.2196 - auc: 0.8133 - val_loss: 1.2159 - val_tp: 1006.0000 - val_fp: 183.0000 - val_tn: 22737.0000 - val_fn: 3578.0000 - val_categorical_accuracy: 0.5081 - val_precision: 0.8461 - val_recall: 0.2195 - val_auc: 0.8516 - lr: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3085 - tp: 4161.0000 - fp: 1685.0000 - tn: 89995.0000 - fn: 14175.0000 - categorical_accuracy: 0.4664 - precision: 0.7118 - recall: 0.2269 - auc: 0.8172 - val_loss: 1.1824 - val_tp: 1139.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 3445.0000 - val_categorical_accuracy: 0.5172 - val_precision: 0.8369 - val_recall: 0.2485 - val_auc: 0.8572 - lr: 0.0089\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3189 - tp: 3972.0000 - fp: 1679.0000 - tn: 90001.0000 - fn: 14364.0000 - categorical_accuracy: 0.4603 - precision: 0.7029 - recall: 0.2166 - auc: 0.8146 - val_loss: 1.2661 - val_tp: 883.0000 - val_fp: 160.0000 - val_tn: 22760.0000 - val_fn: 3701.0000 - val_categorical_accuracy: 0.4719 - val_precision: 0.8466 - val_recall: 0.1926 - val_auc: 0.8324 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3211 - tp: 4106.0000 - fp: 1742.0000 - tn: 89938.0000 - fn: 14230.0000 - categorical_accuracy: 0.4578 - precision: 0.7021 - recall: 0.2239 - auc: 0.8135 - val_loss: 1.2301 - val_tp: 1018.0000 - val_fp: 225.0000 - val_tn: 22695.0000 - val_fn: 3566.0000 - val_categorical_accuracy: 0.4996 - val_precision: 0.8190 - val_recall: 0.2221 - val_auc: 0.8441 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2889 - tp: 4328.0000 - fp: 1744.0000 - tn: 89936.0000 - fn: 14008.0000 - categorical_accuracy: 0.4716 - precision: 0.7128 - recall: 0.2360 - auc: 0.8237 - val_loss: 1.1459 - val_tp: 1197.0000 - val_fp: 199.0000 - val_tn: 22721.0000 - val_fn: 3387.0000 - val_categorical_accuracy: 0.5177 - val_precision: 0.8574 - val_recall: 0.2611 - val_auc: 0.8674 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2737 - tp: 4453.0000 - fp: 1784.0000 - tn: 89896.0000 - fn: 13883.0000 - categorical_accuracy: 0.4780 - precision: 0.7140 - recall: 0.2429 - auc: 0.8281 - val_loss: 1.1578 - val_tp: 1297.0000 - val_fp: 297.0000 - val_tn: 22623.0000 - val_fn: 3287.0000 - val_categorical_accuracy: 0.5153 - val_precision: 0.8137 - val_recall: 0.2829 - val_auc: 0.8624 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2794 - tp: 4441.0000 - fp: 1836.0000 - tn: 89844.0000 - fn: 13895.0000 - categorical_accuracy: 0.4728 - precision: 0.7075 - recall: 0.2422 - auc: 0.8263 - val_loss: 1.1788 - val_tp: 1163.0000 - val_fp: 226.0000 - val_tn: 22694.0000 - val_fn: 3421.0000 - val_categorical_accuracy: 0.5122 - val_precision: 0.8373 - val_recall: 0.2537 - val_auc: 0.8573 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2762 - tp: 4514.0000 - fp: 1880.0000 - tn: 89800.0000 - fn: 13822.0000 - categorical_accuracy: 0.4816 - precision: 0.7060 - recall: 0.2462 - auc: 0.8281 - val_loss: 1.1931 - val_tp: 1271.0000 - val_fp: 371.0000 - val_tn: 22549.0000 - val_fn: 3313.0000 - val_categorical_accuracy: 0.5098 - val_precision: 0.7741 - val_recall: 0.2773 - val_auc: 0.8525 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2603 - tp: 4921.0000 - fp: 2050.0000 - tn: 89630.0000 - fn: 13415.0000 - categorical_accuracy: 0.4853 - precision: 0.7059 - recall: 0.2684 - auc: 0.8317 - val_loss: 1.1395 - val_tp: 1140.0000 - val_fp: 183.0000 - val_tn: 22737.0000 - val_fn: 3444.0000 - val_categorical_accuracy: 0.5284 - val_precision: 0.8617 - val_recall: 0.2487 - val_auc: 0.8682 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2608 - tp: 4698.0000 - fp: 1878.0000 - tn: 89802.0000 - fn: 13638.0000 - categorical_accuracy: 0.4859 - precision: 0.7144 - recall: 0.2562 - auc: 0.8324 - val_loss: 1.1181 - val_tp: 1274.0000 - val_fp: 188.0000 - val_tn: 22732.0000 - val_fn: 3310.0000 - val_categorical_accuracy: 0.5314 - val_precision: 0.8714 - val_recall: 0.2779 - val_auc: 0.8730 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2432 - tp: 4875.0000 - fp: 1797.0000 - tn: 89883.0000 - fn: 13461.0000 - categorical_accuracy: 0.4912 - precision: 0.7307 - recall: 0.2659 - auc: 0.8373 - val_loss: 1.1175 - val_tp: 1215.0000 - val_fp: 166.0000 - val_tn: 22754.0000 - val_fn: 3369.0000 - val_categorical_accuracy: 0.5310 - val_precision: 0.8798 - val_recall: 0.2651 - val_auc: 0.8751 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2598 - tp: 4699.0000 - fp: 1857.0000 - tn: 89823.0000 - fn: 13637.0000 - categorical_accuracy: 0.4792 - precision: 0.7167 - recall: 0.2563 - auc: 0.8320 - val_loss: 1.1569 - val_tp: 1230.0000 - val_fp: 246.0000 - val_tn: 22674.0000 - val_fn: 3354.0000 - val_categorical_accuracy: 0.5131 - val_precision: 0.8333 - val_recall: 0.2683 - val_auc: 0.8618 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2395 - tp: 4800.0000 - fp: 1809.0000 - tn: 89871.0000 - fn: 13536.0000 - categorical_accuracy: 0.4916 - precision: 0.7263 - recall: 0.2618 - auc: 0.8379 - val_loss: 1.1147 - val_tp: 1261.0000 - val_fp: 206.0000 - val_tn: 22714.0000 - val_fn: 3323.0000 - val_categorical_accuracy: 0.5430 - val_precision: 0.8596 - val_recall: 0.2751 - val_auc: 0.8739 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2010 - tp: 5194.0000 - fp: 1833.0000 - tn: 89847.0000 - fn: 13142.0000 - categorical_accuracy: 0.5023 - precision: 0.7391 - recall: 0.2833 - auc: 0.8488 - val_loss: 1.0884 - val_tp: 1393.0000 - val_fp: 234.0000 - val_tn: 22686.0000 - val_fn: 3191.0000 - val_categorical_accuracy: 0.5377 - val_precision: 0.8562 - val_recall: 0.3039 - val_auc: 0.8790 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2164 - tp: 5174.0000 - fp: 1913.0000 - tn: 89767.0000 - fn: 13162.0000 - categorical_accuracy: 0.5011 - precision: 0.7301 - recall: 0.2822 - auc: 0.8448 - val_loss: 1.1168 - val_tp: 1309.0000 - val_fp: 216.0000 - val_tn: 22704.0000 - val_fn: 3275.0000 - val_categorical_accuracy: 0.5292 - val_precision: 0.8584 - val_recall: 0.2856 - val_auc: 0.8721 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2056 - tp: 5259.0000 - fp: 1822.0000 - tn: 89858.0000 - fn: 13077.0000 - categorical_accuracy: 0.5049 - precision: 0.7427 - recall: 0.2868 - auc: 0.8473 - val_loss: 1.0724 - val_tp: 1453.0000 - val_fp: 294.0000 - val_tn: 22626.0000 - val_fn: 3131.0000 - val_categorical_accuracy: 0.5500 - val_precision: 0.8317 - val_recall: 0.3170 - val_auc: 0.8808 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1950 - tp: 5297.0000 - fp: 1836.0000 - tn: 89844.0000 - fn: 13039.0000 - categorical_accuracy: 0.5096 - precision: 0.7426 - recall: 0.2889 - auc: 0.8505 - val_loss: 1.0593 - val_tp: 1368.0000 - val_fp: 249.0000 - val_tn: 22671.0000 - val_fn: 3216.0000 - val_categorical_accuracy: 0.5567 - val_precision: 0.8460 - val_recall: 0.2984 - val_auc: 0.8847 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1668 - tp: 5484.0000 - fp: 1804.0000 - tn: 89876.0000 - fn: 12852.0000 - categorical_accuracy: 0.5196 - precision: 0.7525 - recall: 0.2991 - auc: 0.8578 - val_loss: 1.0713 - val_tp: 1360.0000 - val_fp: 160.0000 - val_tn: 22760.0000 - val_fn: 3224.0000 - val_categorical_accuracy: 0.5530 - val_precision: 0.8947 - val_recall: 0.2967 - val_auc: 0.8833 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 14ms/step - loss: 1.1855 - tp: 5382.0000 - fp: 1843.0000 - tn: 89837.0000 - fn: 12954.0000 - categorical_accuracy: 0.5096 - precision: 0.7449 - recall: 0.2935 - auc: 0.8529 - val_loss: 1.1108 - val_tp: 1307.0000 - val_fp: 207.0000 - val_tn: 22713.0000 - val_fn: 3277.0000 - val_categorical_accuracy: 0.5454 - val_precision: 0.8633 - val_recall: 0.2851 - val_auc: 0.8748 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2070 - tp: 5217.0000 - fp: 1905.0000 - tn: 89775.0000 - fn: 13119.0000 - categorical_accuracy: 0.5021 - precision: 0.7325 - recall: 0.2845 - auc: 0.8470 - val_loss: 1.0888 - val_tp: 1336.0000 - val_fp: 186.0000 - val_tn: 22734.0000 - val_fn: 3248.0000 - val_categorical_accuracy: 0.5482 - val_precision: 0.8778 - val_recall: 0.2914 - val_auc: 0.8798 - lr: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1866 - tp: 5289.0000 - fp: 1692.0000 - tn: 89988.0000 - fn: 13047.0000 - categorical_accuracy: 0.5102 - precision: 0.7576 - recall: 0.2884 - auc: 0.8530 - val_loss: 1.0966 - val_tp: 1367.0000 - val_fp: 297.0000 - val_tn: 22623.0000 - val_fn: 3217.0000 - val_categorical_accuracy: 0.5393 - val_precision: 0.8215 - val_recall: 0.2982 - val_auc: 0.8757 - lr: 0.0053\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1847 - tp: 5476.0000 - fp: 1890.0000 - tn: 89790.0000 - fn: 12860.0000 - categorical_accuracy: 0.5120 - precision: 0.7434 - recall: 0.2986 - auc: 0.8528 - val_loss: 1.0651 - val_tp: 1281.0000 - val_fp: 162.0000 - val_tn: 22758.0000 - val_fn: 3303.0000 - val_categorical_accuracy: 0.5510 - val_precision: 0.8877 - val_recall: 0.2795 - val_auc: 0.8848 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1627 - tp: 5481.0000 - fp: 1754.0000 - tn: 89926.0000 - fn: 12855.0000 - categorical_accuracy: 0.5212 - precision: 0.7576 - recall: 0.2989 - auc: 0.8586 - val_loss: 1.0480 - val_tp: 1378.0000 - val_fp: 165.0000 - val_tn: 22755.0000 - val_fn: 3206.0000 - val_categorical_accuracy: 0.5630 - val_precision: 0.8931 - val_recall: 0.3006 - val_auc: 0.8880 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1596 - tp: 5535.0000 - fp: 1769.0000 - tn: 89911.0000 - fn: 12801.0000 - categorical_accuracy: 0.5230 - precision: 0.7578 - recall: 0.3019 - auc: 0.8593 - val_loss: 1.0598 - val_tp: 1376.0000 - val_fp: 190.0000 - val_tn: 22730.0000 - val_fn: 3208.0000 - val_categorical_accuracy: 0.5478 - val_precision: 0.8787 - val_recall: 0.3002 - val_auc: 0.8841 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1473 - tp: 5801.0000 - fp: 1870.0000 - tn: 89810.0000 - fn: 12535.0000 - categorical_accuracy: 0.5323 - precision: 0.7562 - recall: 0.3164 - auc: 0.8628 - val_loss: 1.0447 - val_tp: 1380.0000 - val_fp: 165.0000 - val_tn: 22755.0000 - val_fn: 3204.0000 - val_categorical_accuracy: 0.5670 - val_precision: 0.8932 - val_recall: 0.3010 - val_auc: 0.8882 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.1433 - tp: 5723.0000 - fp: 1797.0000 - tn: 89883.0000 - fn: 12613.0000 - categorical_accuracy: 0.5233 - precision: 0.7610 - recall: 0.3121 - auc: 0.8633 - val_loss: 1.0422 - val_tp: 1435.0000 - val_fp: 198.0000 - val_tn: 22722.0000 - val_fn: 3149.0000 - val_categorical_accuracy: 0.5602 - val_precision: 0.8788 - val_recall: 0.3130 - val_auc: 0.8882 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1273 - tp: 5875.0000 - fp: 1833.0000 - tn: 89847.0000 - fn: 12461.0000 - categorical_accuracy: 0.5314 - precision: 0.7622 - recall: 0.3204 - auc: 0.8671 - val_loss: 1.0388 - val_tp: 1401.0000 - val_fp: 181.0000 - val_tn: 22739.0000 - val_fn: 3183.0000 - val_categorical_accuracy: 0.5572 - val_precision: 0.8856 - val_recall: 0.3056 - val_auc: 0.8887 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1479 - tp: 5719.0000 - fp: 1815.0000 - tn: 89865.0000 - fn: 12617.0000 - categorical_accuracy: 0.5274 - precision: 0.7591 - recall: 0.3119 - auc: 0.8621 - val_loss: 1.0315 - val_tp: 1406.0000 - val_fp: 153.0000 - val_tn: 22767.0000 - val_fn: 3178.0000 - val_categorical_accuracy: 0.5726 - val_precision: 0.9019 - val_recall: 0.3067 - val_auc: 0.8921 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.1120 - tp: 5979.0000 - fp: 1775.0000 - tn: 89905.0000 - fn: 12357.0000 - categorical_accuracy: 0.5399 - precision: 0.7711 - recall: 0.3261 - auc: 0.8709 - val_loss: 1.0249 - val_tp: 1345.0000 - val_fp: 138.0000 - val_tn: 22782.0000 - val_fn: 3239.0000 - val_categorical_accuracy: 0.5694 - val_precision: 0.9069 - val_recall: 0.2934 - val_auc: 0.8930 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1153 - tp: 6062.0000 - fp: 1840.0000 - tn: 89840.0000 - fn: 12274.0000 - categorical_accuracy: 0.5424 - precision: 0.7671 - recall: 0.3306 - auc: 0.8701 - val_loss: 1.0186 - val_tp: 1459.0000 - val_fp: 212.0000 - val_tn: 22708.0000 - val_fn: 3125.0000 - val_categorical_accuracy: 0.5753 - val_precision: 0.8731 - val_recall: 0.3183 - val_auc: 0.8952 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0979 - tp: 6293.0000 - fp: 1917.0000 - tn: 89763.0000 - fn: 12043.0000 - categorical_accuracy: 0.5481 - precision: 0.7665 - recall: 0.3432 - auc: 0.8743 - val_loss: 1.0078 - val_tp: 1444.0000 - val_fp: 182.0000 - val_tn: 22738.0000 - val_fn: 3140.0000 - val_categorical_accuracy: 0.5694 - val_precision: 0.8881 - val_recall: 0.3150 - val_auc: 0.8947 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0990 - tp: 6301.0000 - fp: 1913.0000 - tn: 89767.0000 - fn: 12035.0000 - categorical_accuracy: 0.5481 - precision: 0.7671 - recall: 0.3436 - auc: 0.8749 - val_loss: 1.0164 - val_tp: 1518.0000 - val_fp: 259.0000 - val_tn: 22661.0000 - val_fn: 3066.0000 - val_categorical_accuracy: 0.5674 - val_precision: 0.8542 - val_recall: 0.3312 - val_auc: 0.8937 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0930 - tp: 6243.0000 - fp: 1923.0000 - tn: 89757.0000 - fn: 12093.0000 - categorical_accuracy: 0.5467 - precision: 0.7645 - recall: 0.3405 - auc: 0.8754 - val_loss: 1.0043 - val_tp: 1486.0000 - val_fp: 192.0000 - val_tn: 22728.0000 - val_fn: 3098.0000 - val_categorical_accuracy: 0.5692 - val_precision: 0.8856 - val_recall: 0.3242 - val_auc: 0.8964 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0973 - tp: 6317.0000 - fp: 2005.0000 - tn: 89675.0000 - fn: 12019.0000 - categorical_accuracy: 0.5444 - precision: 0.7591 - recall: 0.3445 - auc: 0.8747 - val_loss: 0.9972 - val_tp: 1414.0000 - val_fp: 155.0000 - val_tn: 22765.0000 - val_fn: 3170.0000 - val_categorical_accuracy: 0.5783 - val_precision: 0.9012 - val_recall: 0.3085 - val_auc: 0.8986 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0921 - tp: 6247.0000 - fp: 1919.0000 - tn: 89761.0000 - fn: 12089.0000 - categorical_accuracy: 0.5494 - precision: 0.7650 - recall: 0.3407 - auc: 0.8756 - val_loss: 0.9935 - val_tp: 1495.0000 - val_fp: 182.0000 - val_tn: 22738.0000 - val_fn: 3089.0000 - val_categorical_accuracy: 0.5748 - val_precision: 0.8915 - val_recall: 0.3261 - val_auc: 0.8992 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0762 - tp: 6360.0000 - fp: 1950.0000 - tn: 89730.0000 - fn: 11976.0000 - categorical_accuracy: 0.5476 - precision: 0.7653 - recall: 0.3469 - auc: 0.8786 - val_loss: 0.9970 - val_tp: 1566.0000 - val_fp: 280.0000 - val_tn: 22640.0000 - val_fn: 3018.0000 - val_categorical_accuracy: 0.5774 - val_precision: 0.8483 - val_recall: 0.3416 - val_auc: 0.8973 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0646 - tp: 6479.0000 - fp: 1872.0000 - tn: 89808.0000 - fn: 11857.0000 - categorical_accuracy: 0.5572 - precision: 0.7758 - recall: 0.3533 - auc: 0.8816 - val_loss: 0.9942 - val_tp: 1497.0000 - val_fp: 212.0000 - val_tn: 22708.0000 - val_fn: 3087.0000 - val_categorical_accuracy: 0.5860 - val_precision: 0.8760 - val_recall: 0.3266 - val_auc: 0.8986 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0651 - tp: 6499.0000 - fp: 1890.0000 - tn: 89790.0000 - fn: 11837.0000 - categorical_accuracy: 0.5556 - precision: 0.7747 - recall: 0.3544 - auc: 0.8818 - val_loss: 0.9885 - val_tp: 1607.0000 - val_fp: 337.0000 - val_tn: 22583.0000 - val_fn: 2977.0000 - val_categorical_accuracy: 0.5875 - val_precision: 0.8266 - val_recall: 0.3506 - val_auc: 0.8994 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0468 - tp: 6648.0000 - fp: 1989.0000 - tn: 89691.0000 - fn: 11688.0000 - categorical_accuracy: 0.5636 - precision: 0.7697 - recall: 0.3626 - auc: 0.8859 - val_loss: 0.9847 - val_tp: 1551.0000 - val_fp: 252.0000 - val_tn: 22668.0000 - val_fn: 3033.0000 - val_categorical_accuracy: 0.5884 - val_precision: 0.8602 - val_recall: 0.3384 - val_auc: 0.9002 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0394 - tp: 6749.0000 - fp: 1933.0000 - tn: 89747.0000 - fn: 11587.0000 - categorical_accuracy: 0.5688 - precision: 0.7774 - recall: 0.3681 - auc: 0.8873 - val_loss: 0.9630 - val_tp: 1583.0000 - val_fp: 223.0000 - val_tn: 22697.0000 - val_fn: 3001.0000 - val_categorical_accuracy: 0.5903 - val_precision: 0.8765 - val_recall: 0.3453 - val_auc: 0.9042 - lr: 0.0022\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0439 - tp: 6713.0000 - fp: 1959.0000 - tn: 89721.0000 - fn: 11623.0000 - categorical_accuracy: 0.5640 - precision: 0.7741 - recall: 0.3661 - auc: 0.8862 - val_loss: 0.9608 - val_tp: 1551.0000 - val_fp: 192.0000 - val_tn: 22728.0000 - val_fn: 3033.0000 - val_categorical_accuracy: 0.5927 - val_precision: 0.8898 - val_recall: 0.3384 - val_auc: 0.9048 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.0420 - tp: 6687.0000 - fp: 1874.0000 - tn: 89806.0000 - fn: 11649.0000 - categorical_accuracy: 0.5661 - precision: 0.7811 - recall: 0.3647 - auc: 0.8866 - val_loss: 0.9786 - val_tp: 1560.0000 - val_fp: 263.0000 - val_tn: 22657.0000 - val_fn: 3024.0000 - val_categorical_accuracy: 0.5744 - val_precision: 0.8557 - val_recall: 0.3403 - val_auc: 0.9001 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0388 - tp: 6677.0000 - fp: 1835.0000 - tn: 89845.0000 - fn: 11659.0000 - categorical_accuracy: 0.5671 - precision: 0.7844 - recall: 0.3641 - auc: 0.8878 - val_loss: 0.9673 - val_tp: 1625.0000 - val_fp: 272.0000 - val_tn: 22648.0000 - val_fn: 2959.0000 - val_categorical_accuracy: 0.5897 - val_precision: 0.8566 - val_recall: 0.3545 - val_auc: 0.9025 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0406 - tp: 6634.0000 - fp: 1903.0000 - tn: 89777.0000 - fn: 11702.0000 - categorical_accuracy: 0.5681 - precision: 0.7771 - recall: 0.3618 - auc: 0.8873 - val_loss: 0.9653 - val_tp: 1566.0000 - val_fp: 206.0000 - val_tn: 22714.0000 - val_fn: 3018.0000 - val_categorical_accuracy: 0.5942 - val_precision: 0.8837 - val_recall: 0.3416 - val_auc: 0.9038 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0353 - tp: 6744.0000 - fp: 1920.0000 - tn: 89760.0000 - fn: 11592.0000 - categorical_accuracy: 0.5719 - precision: 0.7784 - recall: 0.3678 - auc: 0.8885 - val_loss: 0.9537 - val_tp: 1538.0000 - val_fp: 159.0000 - val_tn: 22761.0000 - val_fn: 3046.0000 - val_categorical_accuracy: 0.5984 - val_precision: 0.9063 - val_recall: 0.3355 - val_auc: 0.9070 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0197 - tp: 6813.0000 - fp: 1818.0000 - tn: 89862.0000 - fn: 11523.0000 - categorical_accuracy: 0.5742 - precision: 0.7894 - recall: 0.3716 - auc: 0.8914 - val_loss: 0.9487 - val_tp: 1629.0000 - val_fp: 263.0000 - val_tn: 22657.0000 - val_fn: 2955.0000 - val_categorical_accuracy: 0.5923 - val_precision: 0.8610 - val_recall: 0.3554 - val_auc: 0.9066 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0176 - tp: 6788.0000 - fp: 1840.0000 - tn: 89840.0000 - fn: 11548.0000 - categorical_accuracy: 0.5760 - precision: 0.7867 - recall: 0.3702 - auc: 0.8922 - val_loss: 0.9519 - val_tp: 1633.0000 - val_fp: 276.0000 - val_tn: 22644.0000 - val_fn: 2951.0000 - val_categorical_accuracy: 0.5966 - val_precision: 0.8554 - val_recall: 0.3562 - val_auc: 0.9060 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0209 - tp: 6836.0000 - fp: 1875.0000 - tn: 89805.0000 - fn: 11500.0000 - categorical_accuracy: 0.5749 - precision: 0.7848 - recall: 0.3728 - auc: 0.8917 - val_loss: 0.9485 - val_tp: 1621.0000 - val_fp: 245.0000 - val_tn: 22675.0000 - val_fn: 2963.0000 - val_categorical_accuracy: 0.6025 - val_precision: 0.8687 - val_recall: 0.3536 - val_auc: 0.9079 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0164 - tp: 6906.0000 - fp: 1960.0000 - tn: 89720.0000 - fn: 11430.0000 - categorical_accuracy: 0.5804 - precision: 0.7789 - recall: 0.3766 - auc: 0.8931 - val_loss: 0.9355 - val_tp: 1606.0000 - val_fp: 233.0000 - val_tn: 22687.0000 - val_fn: 2978.0000 - val_categorical_accuracy: 0.6073 - val_precision: 0.8733 - val_recall: 0.3503 - val_auc: 0.9094 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0160 - tp: 6960.0000 - fp: 1931.0000 - tn: 89749.0000 - fn: 11376.0000 - categorical_accuracy: 0.5775 - precision: 0.7828 - recall: 0.3796 - auc: 0.8926 - val_loss: 0.9345 - val_tp: 1685.0000 - val_fp: 268.0000 - val_tn: 22652.0000 - val_fn: 2899.0000 - val_categorical_accuracy: 0.6067 - val_precision: 0.8628 - val_recall: 0.3676 - val_auc: 0.9097 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0092 - tp: 7093.0000 - fp: 2028.0000 - tn: 89652.0000 - fn: 11243.0000 - categorical_accuracy: 0.5837 - precision: 0.7777 - recall: 0.3868 - auc: 0.8942 - val_loss: 0.9304 - val_tp: 1626.0000 - val_fp: 204.0000 - val_tn: 22716.0000 - val_fn: 2958.0000 - val_categorical_accuracy: 0.6089 - val_precision: 0.8885 - val_recall: 0.3547 - val_auc: 0.9104 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9995 - tp: 7107.0000 - fp: 1960.0000 - tn: 89720.0000 - fn: 11229.0000 - categorical_accuracy: 0.5818 - precision: 0.7838 - recall: 0.3876 - auc: 0.8961 - val_loss: 0.9310 - val_tp: 1545.0000 - val_fp: 145.0000 - val_tn: 22775.0000 - val_fn: 3039.0000 - val_categorical_accuracy: 0.6045 - val_precision: 0.9142 - val_recall: 0.3370 - val_auc: 0.9103 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0023 - tp: 6982.0000 - fp: 1863.0000 - tn: 89817.0000 - fn: 11354.0000 - categorical_accuracy: 0.5843 - precision: 0.7894 - recall: 0.3808 - auc: 0.8955 - val_loss: 0.9244 - val_tp: 1618.0000 - val_fp: 189.0000 - val_tn: 22731.0000 - val_fn: 2966.0000 - val_categorical_accuracy: 0.6147 - val_precision: 0.8954 - val_recall: 0.3530 - val_auc: 0.9120 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9963 - tp: 7095.0000 - fp: 1941.0000 - tn: 89739.0000 - fn: 11241.0000 - categorical_accuracy: 0.5902 - precision: 0.7852 - recall: 0.3869 - auc: 0.8967 - val_loss: 0.9210 - val_tp: 1755.0000 - val_fp: 312.0000 - val_tn: 22608.0000 - val_fn: 2829.0000 - val_categorical_accuracy: 0.6137 - val_precision: 0.8491 - val_recall: 0.3829 - val_auc: 0.9127 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9884 - tp: 7209.0000 - fp: 1980.0000 - tn: 89700.0000 - fn: 11127.0000 - categorical_accuracy: 0.5872 - precision: 0.7845 - recall: 0.3932 - auc: 0.8982 - val_loss: 0.9310 - val_tp: 1686.0000 - val_fp: 283.0000 - val_tn: 22637.0000 - val_fn: 2898.0000 - val_categorical_accuracy: 0.6091 - val_precision: 0.8563 - val_recall: 0.3678 - val_auc: 0.9107 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9861 - tp: 7234.0000 - fp: 1904.0000 - tn: 89776.0000 - fn: 11102.0000 - categorical_accuracy: 0.5943 - precision: 0.7916 - recall: 0.3945 - auc: 0.8991 - val_loss: 0.9220 - val_tp: 1703.0000 - val_fp: 301.0000 - val_tn: 22619.0000 - val_fn: 2881.0000 - val_categorical_accuracy: 0.6084 - val_precision: 0.8498 - val_recall: 0.3715 - val_auc: 0.9119 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9830 - tp: 7250.0000 - fp: 1974.0000 - tn: 89706.0000 - fn: 11086.0000 - categorical_accuracy: 0.5934 - precision: 0.7860 - recall: 0.3954 - auc: 0.8992 - val_loss: 0.9166 - val_tp: 1712.0000 - val_fp: 279.0000 - val_tn: 22641.0000 - val_fn: 2872.0000 - val_categorical_accuracy: 0.6163 - val_precision: 0.8599 - val_recall: 0.3735 - val_auc: 0.9132 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9801 - tp: 7273.0000 - fp: 1945.0000 - tn: 89735.0000 - fn: 11063.0000 - categorical_accuracy: 0.5918 - precision: 0.7890 - recall: 0.3967 - auc: 0.9000 - val_loss: 0.9211 - val_tp: 1665.0000 - val_fp: 258.0000 - val_tn: 22662.0000 - val_fn: 2919.0000 - val_categorical_accuracy: 0.6180 - val_precision: 0.8658 - val_recall: 0.3632 - val_auc: 0.9127 - lr: 7.0388e-04\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9750 - tp: 7419.0000 - fp: 1995.0000 - tn: 89685.0000 - fn: 10917.0000 - categorical_accuracy: 0.5956 - precision: 0.7881 - recall: 0.4046 - auc: 0.9014 - val_loss: 0.9108 - val_tp: 1677.0000 - val_fp: 234.0000 - val_tn: 22686.0000 - val_fn: 2907.0000 - val_categorical_accuracy: 0.6209 - val_precision: 0.8776 - val_recall: 0.3658 - val_auc: 0.9147 - lr: 6.5477e-04\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9766 - tp: 7335.0000 - fp: 1987.0000 - tn: 89693.0000 - fn: 11001.0000 - categorical_accuracy: 0.6012 - precision: 0.7868 - recall: 0.4000 - auc: 0.9012 - val_loss: 0.9135 - val_tp: 1760.0000 - val_fp: 312.0000 - val_tn: 22608.0000 - val_fn: 2824.0000 - val_categorical_accuracy: 0.6204 - val_precision: 0.8494 - val_recall: 0.3839 - val_auc: 0.9139 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9687 - tp: 7478.0000 - fp: 2049.0000 - tn: 89631.0000 - fn: 10858.0000 - categorical_accuracy: 0.5945 - precision: 0.7849 - recall: 0.4078 - auc: 0.9022 - val_loss: 0.9106 - val_tp: 1733.0000 - val_fp: 286.0000 - val_tn: 22634.0000 - val_fn: 2851.0000 - val_categorical_accuracy: 0.6228 - val_precision: 0.8583 - val_recall: 0.3781 - val_auc: 0.9146 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9701 - tp: 7493.0000 - fp: 2093.0000 - tn: 89587.0000 - fn: 10843.0000 - categorical_accuracy: 0.5960 - precision: 0.7817 - recall: 0.4086 - auc: 0.9022 - val_loss: 0.9137 - val_tp: 1726.0000 - val_fp: 284.0000 - val_tn: 22636.0000 - val_fn: 2858.0000 - val_categorical_accuracy: 0.6161 - val_precision: 0.8587 - val_recall: 0.3765 - val_auc: 0.9141 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9628 - tp: 7494.0000 - fp: 2021.0000 - tn: 89659.0000 - fn: 10842.0000 - categorical_accuracy: 0.5987 - precision: 0.7876 - recall: 0.4087 - auc: 0.9039 - val_loss: 0.9056 - val_tp: 1731.0000 - val_fp: 272.0000 - val_tn: 22648.0000 - val_fn: 2853.0000 - val_categorical_accuracy: 0.6230 - val_precision: 0.8642 - val_recall: 0.3776 - val_auc: 0.9154 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9637 - tp: 7547.0000 - fp: 1990.0000 - tn: 89690.0000 - fn: 10789.0000 - categorical_accuracy: 0.6025 - precision: 0.7913 - recall: 0.4116 - auc: 0.9035 - val_loss: 0.9031 - val_tp: 1722.0000 - val_fp: 274.0000 - val_tn: 22646.0000 - val_fn: 2862.0000 - val_categorical_accuracy: 0.6213 - val_precision: 0.8627 - val_recall: 0.3757 - val_auc: 0.9160 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9594 - tp: 7555.0000 - fp: 2050.0000 - tn: 89630.0000 - fn: 10781.0000 - categorical_accuracy: 0.6035 - precision: 0.7866 - recall: 0.4120 - auc: 0.9045 - val_loss: 0.9047 - val_tp: 1747.0000 - val_fp: 298.0000 - val_tn: 22622.0000 - val_fn: 2837.0000 - val_categorical_accuracy: 0.6193 - val_precision: 0.8543 - val_recall: 0.3811 - val_auc: 0.9154 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9620 - tp: 7506.0000 - fp: 2036.0000 - tn: 89644.0000 - fn: 10830.0000 - categorical_accuracy: 0.6002 - precision: 0.7866 - recall: 0.4094 - auc: 0.9040 - val_loss: 0.9041 - val_tp: 1774.0000 - val_fp: 322.0000 - val_tn: 22598.0000 - val_fn: 2810.0000 - val_categorical_accuracy: 0.6222 - val_precision: 0.8464 - val_recall: 0.3870 - val_auc: 0.9156 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9578 - tp: 7617.0000 - fp: 2081.0000 - tn: 89599.0000 - fn: 10719.0000 - categorical_accuracy: 0.6013 - precision: 0.7854 - recall: 0.4154 - auc: 0.9047 - val_loss: 0.9033 - val_tp: 1739.0000 - val_fp: 306.0000 - val_tn: 22614.0000 - val_fn: 2845.0000 - val_categorical_accuracy: 0.6200 - val_precision: 0.8504 - val_recall: 0.3794 - val_auc: 0.9157 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9486 - tp: 7588.0000 - fp: 1961.0000 - tn: 89719.0000 - fn: 10748.0000 - categorical_accuracy: 0.6064 - precision: 0.7946 - recall: 0.4138 - auc: 0.9066 - val_loss: 0.9061 - val_tp: 1762.0000 - val_fp: 332.0000 - val_tn: 22588.0000 - val_fn: 2822.0000 - val_categorical_accuracy: 0.6224 - val_precision: 0.8415 - val_recall: 0.3844 - val_auc: 0.9151 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.9577 - tp: 7632.0000 - fp: 2071.0000 - tn: 89609.0000 - fn: 10704.0000 - categorical_accuracy: 0.6038 - precision: 0.7866 - recall: 0.4162 - auc: 0.9047 - val_loss: 0.9055 - val_tp: 1770.0000 - val_fp: 317.0000 - val_tn: 22603.0000 - val_fn: 2814.0000 - val_categorical_accuracy: 0.6254 - val_precision: 0.8481 - val_recall: 0.3861 - val_auc: 0.9157 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9539 - tp: 7640.0000 - fp: 2131.0000 - tn: 89549.0000 - fn: 10696.0000 - categorical_accuracy: 0.6013 - precision: 0.7819 - recall: 0.4167 - auc: 0.9055 - val_loss: 0.9055 - val_tp: 1766.0000 - val_fp: 317.0000 - val_tn: 22603.0000 - val_fn: 2818.0000 - val_categorical_accuracy: 0.6233 - val_precision: 0.8478 - val_recall: 0.3853 - val_auc: 0.9152 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9500 - tp: 7644.0000 - fp: 2111.0000 - tn: 89569.0000 - fn: 10692.0000 - categorical_accuracy: 0.6054 - precision: 0.7836 - recall: 0.4169 - auc: 0.9063 - val_loss: 0.9003 - val_tp: 1782.0000 - val_fp: 319.0000 - val_tn: 22601.0000 - val_fn: 2802.0000 - val_categorical_accuracy: 0.6230 - val_precision: 0.8482 - val_recall: 0.3887 - val_auc: 0.9161 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9459 - tp: 7715.0000 - fp: 2034.0000 - tn: 89646.0000 - fn: 10621.0000 - categorical_accuracy: 0.6103 - precision: 0.7914 - recall: 0.4208 - auc: 0.9073 - val_loss: 0.9030 - val_tp: 1781.0000 - val_fp: 322.0000 - val_tn: 22598.0000 - val_fn: 2803.0000 - val_categorical_accuracy: 0.6211 - val_precision: 0.8469 - val_recall: 0.3885 - val_auc: 0.9156 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9446 - tp: 7661.0000 - fp: 2025.0000 - tn: 89655.0000 - fn: 10675.0000 - categorical_accuracy: 0.6085 - precision: 0.7909 - recall: 0.4178 - auc: 0.9074 - val_loss: 0.9031 - val_tp: 1814.0000 - val_fp: 341.0000 - val_tn: 22579.0000 - val_fn: 2770.0000 - val_categorical_accuracy: 0.6222 - val_precision: 0.8418 - val_recall: 0.3957 - val_auc: 0.9155 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9391 - tp: 7861.0000 - fp: 2119.0000 - tn: 89561.0000 - fn: 10475.0000 - categorical_accuracy: 0.6111 - precision: 0.7877 - recall: 0.4287 - auc: 0.9084 - val_loss: 0.8984 - val_tp: 1806.0000 - val_fp: 332.0000 - val_tn: 22588.0000 - val_fn: 2778.0000 - val_categorical_accuracy: 0.6278 - val_precision: 0.8447 - val_recall: 0.3940 - val_auc: 0.9165 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9498 - tp: 7681.0000 - fp: 2157.0000 - tn: 89523.0000 - fn: 10655.0000 - categorical_accuracy: 0.6068 - precision: 0.7807 - recall: 0.4189 - auc: 0.9065 - val_loss: 0.9000 - val_tp: 1790.0000 - val_fp: 321.0000 - val_tn: 22599.0000 - val_fn: 2794.0000 - val_categorical_accuracy: 0.6278 - val_precision: 0.8479 - val_recall: 0.3905 - val_auc: 0.9162 - lr: 1.8151e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9368 - tp: 7771.0000 - fp: 2022.0000 - tn: 89658.0000 - fn: 10565.0000 - categorical_accuracy: 0.6106 - precision: 0.7935 - recall: 0.4238 - auc: 0.9088 - val_loss: 0.8974 - val_tp: 1821.0000 - val_fp: 341.0000 - val_tn: 22579.0000 - val_fn: 2763.0000 - val_categorical_accuracy: 0.6287 - val_precision: 0.8423 - val_recall: 0.3973 - val_auc: 0.9167 - lr: 1.6621e-04\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9418 - tp: 7803.0000 - fp: 2072.0000 - tn: 89608.0000 - fn: 10533.0000 - categorical_accuracy: 0.6103 - precision: 0.7902 - recall: 0.4256 - auc: 0.9081 - val_loss: 0.8991 - val_tp: 1833.0000 - val_fp: 337.0000 - val_tn: 22583.0000 - val_fn: 2751.0000 - val_categorical_accuracy: 0.6243 - val_precision: 0.8447 - val_recall: 0.3999 - val_auc: 0.9162 - lr: 1.5207e-04\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9404 - tp: 7876.0000 - fp: 2174.0000 - tn: 89506.0000 - fn: 10460.0000 - categorical_accuracy: 0.6132 - precision: 0.7837 - recall: 0.4295 - auc: 0.9084 - val_loss: 0.8981 - val_tp: 1807.0000 - val_fp: 321.0000 - val_tn: 22599.0000 - val_fn: 2777.0000 - val_categorical_accuracy: 0.6263 - val_precision: 0.8492 - val_recall: 0.3942 - val_auc: 0.9165 - lr: 1.3900e-04\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9408 - tp: 7798.0000 - fp: 2115.0000 - tn: 89565.0000 - fn: 10538.0000 - categorical_accuracy: 0.6132 - precision: 0.7866 - recall: 0.4253 - auc: 0.9083 - val_loss: 0.8976 - val_tp: 1828.0000 - val_fp: 329.0000 - val_tn: 22591.0000 - val_fn: 2756.0000 - val_categorical_accuracy: 0.6272 - val_precision: 0.8475 - val_recall: 0.3988 - val_auc: 0.9168 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9456 - tp: 7731.0000 - fp: 2132.0000 - tn: 89548.0000 - fn: 10605.0000 - categorical_accuracy: 0.6092 - precision: 0.7838 - recall: 0.4216 - auc: 0.9072 - val_loss: 0.8972 - val_tp: 1831.0000 - val_fp: 337.0000 - val_tn: 22583.0000 - val_fn: 2753.0000 - val_categorical_accuracy: 0.6285 - val_precision: 0.8446 - val_recall: 0.3994 - val_auc: 0.9170 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9391 - tp: 7793.0000 - fp: 2134.0000 - tn: 89546.0000 - fn: 10543.0000 - categorical_accuracy: 0.6131 - precision: 0.7850 - recall: 0.4250 - auc: 0.9085 - val_loss: 0.8967 - val_tp: 1845.0000 - val_fp: 352.0000 - val_tn: 22568.0000 - val_fn: 2739.0000 - val_categorical_accuracy: 0.6239 - val_precision: 0.8398 - val_recall: 0.4025 - val_auc: 0.9169 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9320 - tp: 7911.0000 - fp: 2124.0000 - tn: 89556.0000 - fn: 10425.0000 - categorical_accuracy: 0.6179 - precision: 0.7883 - recall: 0.4314 - auc: 0.9103 - val_loss: 0.8931 - val_tp: 1846.0000 - val_fp: 354.0000 - val_tn: 22566.0000 - val_fn: 2738.0000 - val_categorical_accuracy: 0.6285 - val_precision: 0.8391 - val_recall: 0.4027 - val_auc: 0.9176 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9487 - tp: 7775.0000 - fp: 2125.0000 - tn: 89555.0000 - fn: 10561.0000 - categorical_accuracy: 0.6069 - precision: 0.7854 - recall: 0.4240 - auc: 0.9065 - val_loss: 0.8918 - val_tp: 1846.0000 - val_fp: 349.0000 - val_tn: 22571.0000 - val_fn: 2738.0000 - val_categorical_accuracy: 0.6296 - val_precision: 0.8410 - val_recall: 0.4027 - val_auc: 0.9179 - lr: 8.7498e-05\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.9515 - tp: 2239.0000 - fp: 448.0000 - tn: 28202.0000 - fn: 3491.0000 - categorical_accuracy: 0.5794 - precision: 0.8333 - recall: 0.3908 - auc: 0.9017\n",
      "====================== FOLD: 4 ======================\n",
      "Train: [    0     1     2 ... 27692 27693 27694]\n",
      "Test: [ 3820  3821  3822 ... 28647 28648 28649]\n",
      "Intersection: []\n",
      "TRAIN: [    0     1     2 ... 27692 27693 27694] TEST: [ 3820  3821  3822 ... 28647 28648 28649]\n",
      "Train shapes: (22920, 1280, 6) (22920,) Test shapes: (5730, 1280, 6) (5730,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0      0.166667\n",
       "4.0      0.166667\n",
       "3.0      0.166667\n",
       "2.0      0.166667\n",
       "1.0      0.166667\n",
       "0.0      0.166667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling WITHIN train/test, NOT overall!\n",
      "Scaling!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_radar_i (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_q (InputLayer)      [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_dist (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_pulse (InputLayer)  [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_resp (InputLayer)   [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_radar_heartSound (InputLa [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           40992       input_radar_i[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           40992       input_radar_q[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           40992       input_radar_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           40992       input_radar_pulse[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           40992       input_radar_resp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 32)           40992       input_radar_heartSound[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           528         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           528         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            136         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            136         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            136         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 8)            136         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 48)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           1568        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           528         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            102         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 252,134\n",
      "Trainable params: 252,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/144 [..............................] - ETA: 19s - loss: 0.9482 - tp: 1854.0000 - fp: 369.0000 - tn: 23831.0000 - fn: 2986.0000 - categorical_accuracy: 0.6062 - precision: 0.8340 - recall: 0.3831 - auc: 0.9061WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.131686). Check your callbacks.\n",
      "144/144 [==============================] - 3s 18ms/step - loss: 1.5196 - tp: 2375.0000 - fp: 951.0000 - tn: 113649.0000 - fn: 20545.0000 - categorical_accuracy: 0.3671 - precision: 0.7141 - recall: 0.1036 - auc: 0.7336 - val_loss: 1.4535 - val_tp: 278.0000 - val_fp: 84.0000 - val_tn: 22836.0000 - val_fn: 4306.0000 - val_categorical_accuracy: 0.4127 - val_precision: 0.7680 - val_recall: 0.0606 - val_auc: 0.7841 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.4442 - tp: 2502.0000 - fp: 1388.0000 - tn: 90292.0000 - fn: 15834.0000 - categorical_accuracy: 0.4031 - precision: 0.6432 - recall: 0.1365 - auc: 0.7732 - val_loss: 1.2933 - val_tp: 716.0000 - val_fp: 290.0000 - val_tn: 22630.0000 - val_fn: 3868.0000 - val_categorical_accuracy: 0.4636 - val_precision: 0.7117 - val_recall: 0.1562 - val_auc: 0.8281 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3841 - tp: 2799.0000 - fp: 1561.0000 - tn: 90119.0000 - fn: 15537.0000 - categorical_accuracy: 0.4275 - precision: 0.6420 - recall: 0.1527 - auc: 0.7951 - val_loss: 1.2516 - val_tp: 856.0000 - val_fp: 278.0000 - val_tn: 22642.0000 - val_fn: 3728.0000 - val_categorical_accuracy: 0.4987 - val_precision: 0.7549 - val_recall: 0.1867 - val_auc: 0.8409 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3338 - tp: 3513.0000 - fp: 1846.0000 - tn: 89834.0000 - fn: 14823.0000 - categorical_accuracy: 0.4468 - precision: 0.6555 - recall: 0.1916 - auc: 0.8115 - val_loss: 1.2165 - val_tp: 1027.0000 - val_fp: 361.0000 - val_tn: 22559.0000 - val_fn: 3557.0000 - val_categorical_accuracy: 0.4963 - val_precision: 0.7399 - val_recall: 0.2240 - val_auc: 0.8473 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3395 - tp: 3508.0000 - fp: 1836.0000 - tn: 89844.0000 - fn: 14828.0000 - categorical_accuracy: 0.4461 - precision: 0.6564 - recall: 0.1913 - auc: 0.8095 - val_loss: 1.2015 - val_tp: 1033.0000 - val_fp: 356.0000 - val_tn: 22564.0000 - val_fn: 3551.0000 - val_categorical_accuracy: 0.5170 - val_precision: 0.7437 - val_recall: 0.2253 - val_auc: 0.8541 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3058 - tp: 3870.0000 - fp: 1977.0000 - tn: 89703.0000 - fn: 14466.0000 - categorical_accuracy: 0.4535 - precision: 0.6619 - recall: 0.2111 - auc: 0.8192 - val_loss: 1.1946 - val_tp: 1125.0000 - val_fp: 386.0000 - val_tn: 22534.0000 - val_fn: 3459.0000 - val_categorical_accuracy: 0.5048 - val_precision: 0.7445 - val_recall: 0.2454 - val_auc: 0.8532 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.3060 - tp: 4119.0000 - fp: 1935.0000 - tn: 89745.0000 - fn: 14217.0000 - categorical_accuracy: 0.4641 - precision: 0.6804 - recall: 0.2246 - auc: 0.8185 - val_loss: 1.2135 - val_tp: 1151.0000 - val_fp: 358.0000 - val_tn: 22562.0000 - val_fn: 3433.0000 - val_categorical_accuracy: 0.5002 - val_precision: 0.7628 - val_recall: 0.2511 - val_auc: 0.8474 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.3115 - tp: 3995.0000 - fp: 1925.0000 - tn: 89755.0000 - fn: 14341.0000 - categorical_accuracy: 0.4652 - precision: 0.6748 - recall: 0.2179 - auc: 0.8178 - val_loss: 1.1799 - val_tp: 1139.0000 - val_fp: 220.0000 - val_tn: 22700.0000 - val_fn: 3445.0000 - val_categorical_accuracy: 0.5238 - val_precision: 0.8381 - val_recall: 0.2485 - val_auc: 0.8601 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2900 - tp: 4117.0000 - fp: 1864.0000 - tn: 89816.0000 - fn: 14219.0000 - categorical_accuracy: 0.4691 - precision: 0.6883 - recall: 0.2245 - auc: 0.8242 - val_loss: 1.2045 - val_tp: 1181.0000 - val_fp: 394.0000 - val_tn: 22526.0000 - val_fn: 3403.0000 - val_categorical_accuracy: 0.5131 - val_precision: 0.7498 - val_recall: 0.2576 - val_auc: 0.8503 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2740 - tp: 4535.0000 - fp: 1953.0000 - tn: 89727.0000 - fn: 13801.0000 - categorical_accuracy: 0.4866 - precision: 0.6990 - recall: 0.2473 - auc: 0.8291 - val_loss: 1.2621 - val_tp: 957.0000 - val_fp: 247.0000 - val_tn: 22673.0000 - val_fn: 3627.0000 - val_categorical_accuracy: 0.4858 - val_precision: 0.7949 - val_recall: 0.2088 - val_auc: 0.8317 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2738 - tp: 4392.0000 - fp: 1748.0000 - tn: 89932.0000 - fn: 13944.0000 - categorical_accuracy: 0.4822 - precision: 0.7153 - recall: 0.2395 - auc: 0.8293 - val_loss: 1.1619 - val_tp: 1109.0000 - val_fp: 222.0000 - val_tn: 22698.0000 - val_fn: 3475.0000 - val_categorical_accuracy: 0.5408 - val_precision: 0.8332 - val_recall: 0.2419 - val_auc: 0.8636 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2562 - tp: 4580.0000 - fp: 1681.0000 - tn: 89999.0000 - fn: 13756.0000 - categorical_accuracy: 0.4914 - precision: 0.7315 - recall: 0.2498 - auc: 0.8340 - val_loss: 1.1439 - val_tp: 1181.0000 - val_fp: 229.0000 - val_tn: 22691.0000 - val_fn: 3403.0000 - val_categorical_accuracy: 0.5436 - val_precision: 0.8376 - val_recall: 0.2576 - val_auc: 0.8683 - lr: 0.0099\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2464 - tp: 4766.0000 - fp: 1796.0000 - tn: 89884.0000 - fn: 13570.0000 - categorical_accuracy: 0.4921 - precision: 0.7263 - recall: 0.2599 - auc: 0.8360 - val_loss: 1.1484 - val_tp: 1240.0000 - val_fp: 285.0000 - val_tn: 22635.0000 - val_fn: 3344.0000 - val_categorical_accuracy: 0.5312 - val_precision: 0.8131 - val_recall: 0.2705 - val_auc: 0.8657 - lr: 0.0098\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2495 - tp: 4620.0000 - fp: 1758.0000 - tn: 89922.0000 - fn: 13716.0000 - categorical_accuracy: 0.4908 - precision: 0.7244 - recall: 0.2520 - auc: 0.8354 - val_loss: 1.1001 - val_tp: 1211.0000 - val_fp: 180.0000 - val_tn: 22740.0000 - val_fn: 3373.0000 - val_categorical_accuracy: 0.5563 - val_precision: 0.8706 - val_recall: 0.2642 - val_auc: 0.8772 - lr: 0.0096\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2005 - tp: 5307.0000 - fp: 1901.0000 - tn: 89779.0000 - fn: 13029.0000 - categorical_accuracy: 0.5101 - precision: 0.7363 - recall: 0.2894 - auc: 0.8492 - val_loss: 1.0665 - val_tp: 1406.0000 - val_fp: 196.0000 - val_tn: 22724.0000 - val_fn: 3178.0000 - val_categorical_accuracy: 0.5611 - val_precision: 0.8777 - val_recall: 0.3067 - val_auc: 0.8843 - lr: 0.0095\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2399 - tp: 4862.0000 - fp: 1829.0000 - tn: 89851.0000 - fn: 13474.0000 - categorical_accuracy: 0.4975 - precision: 0.7266 - recall: 0.2652 - auc: 0.8382 - val_loss: 1.1200 - val_tp: 1414.0000 - val_fp: 337.0000 - val_tn: 22583.0000 - val_fn: 3170.0000 - val_categorical_accuracy: 0.5530 - val_precision: 0.8075 - val_recall: 0.3085 - val_auc: 0.8712 - lr: 0.0094\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2435 - tp: 4997.0000 - fp: 1881.0000 - tn: 89799.0000 - fn: 13339.0000 - categorical_accuracy: 0.4975 - precision: 0.7265 - recall: 0.2725 - auc: 0.8374 - val_loss: 1.1111 - val_tp: 1314.0000 - val_fp: 255.0000 - val_tn: 22665.0000 - val_fn: 3270.0000 - val_categorical_accuracy: 0.5515 - val_precision: 0.8375 - val_recall: 0.2866 - val_auc: 0.8740 - lr: 0.0092\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2597 - tp: 4886.0000 - fp: 1992.0000 - tn: 89688.0000 - fn: 13450.0000 - categorical_accuracy: 0.4931 - precision: 0.7104 - recall: 0.2665 - auc: 0.8331 - val_loss: 1.1215 - val_tp: 1331.0000 - val_fp: 247.0000 - val_tn: 22673.0000 - val_fn: 3253.0000 - val_categorical_accuracy: 0.5504 - val_precision: 0.8435 - val_recall: 0.2904 - val_auc: 0.8722 - lr: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.2583 - tp: 4881.0000 - fp: 1877.0000 - tn: 89803.0000 - fn: 13455.0000 - categorical_accuracy: 0.4890 - precision: 0.7223 - recall: 0.2662 - auc: 0.8332 - val_loss: 1.1000 - val_tp: 1520.0000 - val_fp: 383.0000 - val_tn: 22537.0000 - val_fn: 3064.0000 - val_categorical_accuracy: 0.5530 - val_precision: 0.7987 - val_recall: 0.3316 - val_auc: 0.8758 - lr: 0.0089\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2399 - tp: 5123.0000 - fp: 1950.0000 - tn: 89730.0000 - fn: 13213.0000 - categorical_accuracy: 0.5004 - precision: 0.7243 - recall: 0.2794 - auc: 0.8388 - val_loss: 1.0972 - val_tp: 1540.0000 - val_fp: 400.0000 - val_tn: 22520.0000 - val_fn: 3044.0000 - val_categorical_accuracy: 0.5572 - val_precision: 0.7938 - val_recall: 0.3360 - val_auc: 0.8762 - lr: 0.0087\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2243 - tp: 5173.0000 - fp: 1940.0000 - tn: 89740.0000 - fn: 13163.0000 - categorical_accuracy: 0.5010 - precision: 0.7273 - recall: 0.2821 - auc: 0.8425 - val_loss: 1.1151 - val_tp: 1401.0000 - val_fp: 314.0000 - val_tn: 22606.0000 - val_fn: 3183.0000 - val_categorical_accuracy: 0.5580 - val_precision: 0.8169 - val_recall: 0.3056 - val_auc: 0.8758 - lr: 0.0086\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2365 - tp: 5107.0000 - fp: 1970.0000 - tn: 89710.0000 - fn: 13229.0000 - categorical_accuracy: 0.5019 - precision: 0.7216 - recall: 0.2785 - auc: 0.8398 - val_loss: 1.0785 - val_tp: 1393.0000 - val_fp: 238.0000 - val_tn: 22682.0000 - val_fn: 3191.0000 - val_categorical_accuracy: 0.5591 - val_precision: 0.8541 - val_recall: 0.3039 - val_auc: 0.8815 - lr: 0.0084\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2025 - tp: 5438.0000 - fp: 1945.0000 - tn: 89735.0000 - fn: 12898.0000 - categorical_accuracy: 0.5062 - precision: 0.7366 - recall: 0.2966 - auc: 0.8483 - val_loss: 1.0636 - val_tp: 1619.0000 - val_fp: 392.0000 - val_tn: 22528.0000 - val_fn: 2965.0000 - val_categorical_accuracy: 0.5681 - val_precision: 0.8051 - val_recall: 0.3532 - val_auc: 0.8848 - lr: 0.0082\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.2049 - tp: 5431.0000 - fp: 1974.0000 - tn: 89706.0000 - fn: 12905.0000 - categorical_accuracy: 0.5089 - precision: 0.7334 - recall: 0.2962 - auc: 0.8481 - val_loss: 1.0591 - val_tp: 1507.0000 - val_fp: 260.0000 - val_tn: 22660.0000 - val_fn: 3077.0000 - val_categorical_accuracy: 0.5722 - val_precision: 0.8529 - val_recall: 0.3288 - val_auc: 0.8859 - lr: 0.0080\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.2324 - tp: 5195.0000 - fp: 2041.0000 - tn: 89639.0000 - fn: 13141.0000 - categorical_accuracy: 0.5019 - precision: 0.7179 - recall: 0.2833 - auc: 0.8410 - val_loss: 1.0763 - val_tp: 1427.0000 - val_fp: 299.0000 - val_tn: 22621.0000 - val_fn: 3157.0000 - val_categorical_accuracy: 0.5641 - val_precision: 0.8268 - val_recall: 0.3113 - val_auc: 0.8821 - lr: 0.0078\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1888 - tp: 5561.0000 - fp: 1972.0000 - tn: 89708.0000 - fn: 12775.0000 - categorical_accuracy: 0.5147 - precision: 0.7382 - recall: 0.3033 - auc: 0.8524 - val_loss: 1.0424 - val_tp: 1723.0000 - val_fp: 392.0000 - val_tn: 22528.0000 - val_fn: 2861.0000 - val_categorical_accuracy: 0.5735 - val_precision: 0.8147 - val_recall: 0.3759 - val_auc: 0.8890 - lr: 0.0077\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1782 - tp: 5851.0000 - fp: 2102.0000 - tn: 89578.0000 - fn: 12485.0000 - categorical_accuracy: 0.5195 - precision: 0.7357 - recall: 0.3191 - auc: 0.8547 - val_loss: 1.0570 - val_tp: 1441.0000 - val_fp: 198.0000 - val_tn: 22722.0000 - val_fn: 3143.0000 - val_categorical_accuracy: 0.5663 - val_precision: 0.8792 - val_recall: 0.3144 - val_auc: 0.8869 - lr: 0.0075\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1844 - tp: 5724.0000 - fp: 2100.0000 - tn: 89580.0000 - fn: 12612.0000 - categorical_accuracy: 0.5191 - precision: 0.7316 - recall: 0.3122 - auc: 0.8536 - val_loss: 1.0515 - val_tp: 1437.0000 - val_fp: 204.0000 - val_tn: 22716.0000 - val_fn: 3147.0000 - val_categorical_accuracy: 0.5720 - val_precision: 0.8757 - val_recall: 0.3135 - val_auc: 0.8889 - lr: 0.0073\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1614 - tp: 5856.0000 - fp: 2000.0000 - tn: 89680.0000 - fn: 12480.0000 - categorical_accuracy: 0.5279 - precision: 0.7454 - recall: 0.3194 - auc: 0.8592 - val_loss: 1.0492 - val_tp: 1652.0000 - val_fp: 367.0000 - val_tn: 22553.0000 - val_fn: 2932.0000 - val_categorical_accuracy: 0.5718 - val_precision: 0.8182 - val_recall: 0.3604 - val_auc: 0.8874 - lr: 0.0071\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1707 - tp: 5846.0000 - fp: 2095.0000 - tn: 89585.0000 - fn: 12490.0000 - categorical_accuracy: 0.5220 - precision: 0.7362 - recall: 0.3188 - auc: 0.8572 - val_loss: 1.0418 - val_tp: 1552.0000 - val_fp: 289.0000 - val_tn: 22631.0000 - val_fn: 3032.0000 - val_categorical_accuracy: 0.5818 - val_precision: 0.8430 - val_recall: 0.3386 - val_auc: 0.8893 - lr: 0.0069\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1658 - tp: 5839.0000 - fp: 2089.0000 - tn: 89591.0000 - fn: 12497.0000 - categorical_accuracy: 0.5284 - precision: 0.7365 - recall: 0.3184 - auc: 0.8590 - val_loss: 1.0332 - val_tp: 1576.0000 - val_fp: 267.0000 - val_tn: 22653.0000 - val_fn: 3008.0000 - val_categorical_accuracy: 0.5796 - val_precision: 0.8551 - val_recall: 0.3438 - val_auc: 0.8912 - lr: 0.0067\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1779 - tp: 5865.0000 - fp: 2141.0000 - tn: 89539.0000 - fn: 12471.0000 - categorical_accuracy: 0.5236 - precision: 0.7326 - recall: 0.3199 - auc: 0.8551 - val_loss: 1.0949 - val_tp: 1389.0000 - val_fp: 289.0000 - val_tn: 22631.0000 - val_fn: 3195.0000 - val_categorical_accuracy: 0.5685 - val_precision: 0.8278 - val_recall: 0.3030 - val_auc: 0.8785 - lr: 0.0065\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1685 - tp: 5876.0000 - fp: 2206.0000 - tn: 89474.0000 - fn: 12460.0000 - categorical_accuracy: 0.5299 - precision: 0.7270 - recall: 0.3205 - auc: 0.8578 - val_loss: 1.0220 - val_tp: 1595.0000 - val_fp: 286.0000 - val_tn: 22634.0000 - val_fn: 2989.0000 - val_categorical_accuracy: 0.5927 - val_precision: 0.8480 - val_recall: 0.3479 - val_auc: 0.8957 - lr: 0.0063\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1823 - tp: 5732.0000 - fp: 2100.0000 - tn: 89580.0000 - fn: 12604.0000 - categorical_accuracy: 0.5221 - precision: 0.7319 - recall: 0.3126 - auc: 0.8545 - val_loss: 1.0542 - val_tp: 1506.0000 - val_fp: 276.0000 - val_tn: 22644.0000 - val_fn: 3078.0000 - val_categorical_accuracy: 0.5711 - val_precision: 0.8451 - val_recall: 0.3285 - val_auc: 0.8870 - lr: 0.0061\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1904 - tp: 5635.0000 - fp: 2103.0000 - tn: 89577.0000 - fn: 12701.0000 - categorical_accuracy: 0.5163 - precision: 0.7282 - recall: 0.3073 - auc: 0.8520 - val_loss: 1.0564 - val_tp: 1659.0000 - val_fp: 316.0000 - val_tn: 22604.0000 - val_fn: 2925.0000 - val_categorical_accuracy: 0.5744 - val_precision: 0.8400 - val_recall: 0.3619 - val_auc: 0.8865 - lr: 0.0059\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1571 - tp: 5846.0000 - fp: 2055.0000 - tn: 89625.0000 - fn: 12490.0000 - categorical_accuracy: 0.5246 - precision: 0.7399 - recall: 0.3188 - auc: 0.8607 - val_loss: 1.0277 - val_tp: 1717.0000 - val_fp: 385.0000 - val_tn: 22535.0000 - val_fn: 2867.0000 - val_categorical_accuracy: 0.5836 - val_precision: 0.8168 - val_recall: 0.3746 - val_auc: 0.8915 - lr: 0.0057\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1462 - tp: 6085.0000 - fp: 2104.0000 - tn: 89576.0000 - fn: 12251.0000 - categorical_accuracy: 0.5320 - precision: 0.7431 - recall: 0.3319 - auc: 0.8636 - val_loss: 1.0234 - val_tp: 1621.0000 - val_fp: 315.0000 - val_tn: 22605.0000 - val_fn: 2963.0000 - val_categorical_accuracy: 0.5827 - val_precision: 0.8373 - val_recall: 0.3536 - val_auc: 0.8950 - lr: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1493 - tp: 6188.0000 - fp: 2287.0000 - tn: 89393.0000 - fn: 12148.0000 - categorical_accuracy: 0.5328 - precision: 0.7301 - recall: 0.3375 - auc: 0.8631 - val_loss: 0.9957 - val_tp: 1661.0000 - val_fp: 283.0000 - val_tn: 22637.0000 - val_fn: 2923.0000 - val_categorical_accuracy: 0.5925 - val_precision: 0.8544 - val_recall: 0.3623 - val_auc: 0.8991 - lr: 0.0053\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1408 - tp: 6196.0000 - fp: 2182.0000 - tn: 89498.0000 - fn: 12140.0000 - categorical_accuracy: 0.5359 - precision: 0.7396 - recall: 0.3379 - auc: 0.8645 - val_loss: 1.0174 - val_tp: 1813.0000 - val_fp: 439.0000 - val_tn: 22481.0000 - val_fn: 2771.0000 - val_categorical_accuracy: 0.5809 - val_precision: 0.8051 - val_recall: 0.3955 - val_auc: 0.8936 - lr: 0.0051\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1300 - tp: 6426.0000 - fp: 2255.0000 - tn: 89425.0000 - fn: 11910.0000 - categorical_accuracy: 0.5383 - precision: 0.7402 - recall: 0.3505 - auc: 0.8671 - val_loss: 1.0165 - val_tp: 1720.0000 - val_fp: 363.0000 - val_tn: 22557.0000 - val_fn: 2864.0000 - val_categorical_accuracy: 0.5905 - val_precision: 0.8257 - val_recall: 0.3752 - val_auc: 0.8958 - lr: 0.0049\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1397 - tp: 6166.0000 - fp: 2086.0000 - tn: 89594.0000 - fn: 12170.0000 - categorical_accuracy: 0.5345 - precision: 0.7472 - recall: 0.3363 - auc: 0.8648 - val_loss: 0.9978 - val_tp: 1626.0000 - val_fp: 254.0000 - val_tn: 22666.0000 - val_fn: 2958.0000 - val_categorical_accuracy: 0.5999 - val_precision: 0.8649 - val_recall: 0.3547 - val_auc: 0.9009 - lr: 0.0047\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 2s 14ms/step - loss: 1.1079 - tp: 6515.0000 - fp: 2230.0000 - tn: 89450.0000 - fn: 11821.0000 - categorical_accuracy: 0.5432 - precision: 0.7450 - recall: 0.3553 - auc: 0.8726 - val_loss: 0.9914 - val_tp: 1715.0000 - val_fp: 342.0000 - val_tn: 22578.0000 - val_fn: 2869.0000 - val_categorical_accuracy: 0.5938 - val_precision: 0.8337 - val_recall: 0.3741 - val_auc: 0.9011 - lr: 0.0045\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.1157 - tp: 6479.0000 - fp: 2155.0000 - tn: 89525.0000 - fn: 11857.0000 - categorical_accuracy: 0.5405 - precision: 0.7504 - recall: 0.3533 - auc: 0.8708 - val_loss: 0.9895 - val_tp: 1832.0000 - val_fp: 429.0000 - val_tn: 22491.0000 - val_fn: 2752.0000 - val_categorical_accuracy: 0.5942 - val_precision: 0.8103 - val_recall: 0.3997 - val_auc: 0.9002 - lr: 0.0043\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 1.1192 - tp: 6344.0000 - fp: 2228.0000 - tn: 89452.0000 - fn: 11992.0000 - categorical_accuracy: 0.5393 - precision: 0.7401 - recall: 0.3460 - auc: 0.8699 - val_loss: 1.0355 - val_tp: 1673.0000 - val_fp: 449.0000 - val_tn: 22471.0000 - val_fn: 2911.0000 - val_categorical_accuracy: 0.5875 - val_precision: 0.7884 - val_recall: 0.3650 - val_auc: 0.8911 - lr: 0.0042\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.1379 - tp: 6293.0000 - fp: 2275.0000 - tn: 89405.0000 - fn: 12043.0000 - categorical_accuracy: 0.5382 - precision: 0.7345 - recall: 0.3432 - auc: 0.8659 - val_loss: 1.0025 - val_tp: 1801.0000 - val_fp: 387.0000 - val_tn: 22533.0000 - val_fn: 2783.0000 - val_categorical_accuracy: 0.5951 - val_precision: 0.8231 - val_recall: 0.3929 - val_auc: 0.8984 - lr: 0.0040\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0978 - tp: 6621.0000 - fp: 2161.0000 - tn: 89519.0000 - fn: 11715.0000 - categorical_accuracy: 0.5531 - precision: 0.7539 - recall: 0.3611 - auc: 0.8752 - val_loss: 0.9860 - val_tp: 1796.0000 - val_fp: 398.0000 - val_tn: 22522.0000 - val_fn: 2788.0000 - val_categorical_accuracy: 0.5977 - val_precision: 0.8186 - val_recall: 0.3918 - val_auc: 0.9006 - lr: 0.0038\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0896 - tp: 6780.0000 - fp: 2078.0000 - tn: 89602.0000 - fn: 11556.0000 - categorical_accuracy: 0.5500 - precision: 0.7654 - recall: 0.3698 - auc: 0.8766 - val_loss: 0.9701 - val_tp: 1721.0000 - val_fp: 296.0000 - val_tn: 22624.0000 - val_fn: 2863.0000 - val_categorical_accuracy: 0.5955 - val_precision: 0.8532 - val_recall: 0.3754 - val_auc: 0.9030 - lr: 0.0036\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0811 - tp: 6734.0000 - fp: 2108.0000 - tn: 89572.0000 - fn: 11602.0000 - categorical_accuracy: 0.5518 - precision: 0.7616 - recall: 0.3673 - auc: 0.8784 - val_loss: 0.9535 - val_tp: 1802.0000 - val_fp: 289.0000 - val_tn: 22631.0000 - val_fn: 2782.0000 - val_categorical_accuracy: 0.6049 - val_precision: 0.8618 - val_recall: 0.3931 - val_auc: 0.9079 - lr: 0.0035\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0596 - tp: 6982.0000 - fp: 2162.0000 - tn: 89518.0000 - fn: 11354.0000 - categorical_accuracy: 0.5640 - precision: 0.7636 - recall: 0.3808 - auc: 0.8835 - val_loss: 0.9475 - val_tp: 1878.0000 - val_fp: 397.0000 - val_tn: 22523.0000 - val_fn: 2706.0000 - val_categorical_accuracy: 0.6104 - val_precision: 0.8255 - val_recall: 0.4097 - val_auc: 0.9094 - lr: 0.0033\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0435 - tp: 7187.0000 - fp: 2139.0000 - tn: 89541.0000 - fn: 11149.0000 - categorical_accuracy: 0.5676 - precision: 0.7706 - recall: 0.3920 - auc: 0.8871 - val_loss: 0.9479 - val_tp: 1831.0000 - val_fp: 312.0000 - val_tn: 22608.0000 - val_fn: 2753.0000 - val_categorical_accuracy: 0.6049 - val_precision: 0.8544 - val_recall: 0.3994 - val_auc: 0.9081 - lr: 0.0032\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0536 - tp: 6941.0000 - fp: 2024.0000 - tn: 89656.0000 - fn: 11395.0000 - categorical_accuracy: 0.5633 - precision: 0.7742 - recall: 0.3785 - auc: 0.8843 - val_loss: 0.9417 - val_tp: 1774.0000 - val_fp: 282.0000 - val_tn: 22638.0000 - val_fn: 2810.0000 - val_categorical_accuracy: 0.6012 - val_precision: 0.8628 - val_recall: 0.3870 - val_auc: 0.9082 - lr: 0.0030\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0376 - tp: 7084.0000 - fp: 2056.0000 - tn: 89624.0000 - fn: 11252.0000 - categorical_accuracy: 0.5668 - precision: 0.7751 - recall: 0.3863 - auc: 0.8880 - val_loss: 0.9344 - val_tp: 1906.0000 - val_fp: 400.0000 - val_tn: 22520.0000 - val_fn: 2678.0000 - val_categorical_accuracy: 0.6095 - val_precision: 0.8265 - val_recall: 0.4158 - val_auc: 0.9101 - lr: 0.0029\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0231 - tp: 7201.0000 - fp: 2111.0000 - tn: 89569.0000 - fn: 11135.0000 - categorical_accuracy: 0.5736 - precision: 0.7733 - recall: 0.3927 - auc: 0.8909 - val_loss: 0.9254 - val_tp: 1896.0000 - val_fp: 379.0000 - val_tn: 22541.0000 - val_fn: 2688.0000 - val_categorical_accuracy: 0.6078 - val_precision: 0.8334 - val_recall: 0.4136 - val_auc: 0.9117 - lr: 0.0027\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0332 - tp: 7261.0000 - fp: 2067.0000 - tn: 89613.0000 - fn: 11075.0000 - categorical_accuracy: 0.5722 - precision: 0.7784 - recall: 0.3960 - auc: 0.8891 - val_loss: 0.9286 - val_tp: 1914.0000 - val_fp: 350.0000 - val_tn: 22570.0000 - val_fn: 2670.0000 - val_categorical_accuracy: 0.6056 - val_precision: 0.8454 - val_recall: 0.4175 - val_auc: 0.9109 - lr: 0.0026\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 2s 14ms/step - loss: 1.0188 - tp: 7286.0000 - fp: 2125.0000 - tn: 89555.0000 - fn: 11050.0000 - categorical_accuracy: 0.5725 - precision: 0.7742 - recall: 0.3974 - auc: 0.8923 - val_loss: 0.9200 - val_tp: 1926.0000 - val_fp: 360.0000 - val_tn: 22560.0000 - val_fn: 2658.0000 - val_categorical_accuracy: 0.6069 - val_precision: 0.8425 - val_recall: 0.4202 - val_auc: 0.9126 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0100 - tp: 7331.0000 - fp: 2060.0000 - tn: 89620.0000 - fn: 11005.0000 - categorical_accuracy: 0.5758 - precision: 0.7806 - recall: 0.3998 - auc: 0.8935 - val_loss: 0.9073 - val_tp: 1954.0000 - val_fp: 396.0000 - val_tn: 22524.0000 - val_fn: 2630.0000 - val_categorical_accuracy: 0.6110 - val_precision: 0.8315 - val_recall: 0.4263 - val_auc: 0.9146 - lr: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9975 - tp: 7487.0000 - fp: 2080.0000 - tn: 89600.0000 - fn: 10849.0000 - categorical_accuracy: 0.5803 - precision: 0.7826 - recall: 0.4083 - auc: 0.8960 - val_loss: 0.9144 - val_tp: 1937.0000 - val_fp: 381.0000 - val_tn: 22539.0000 - val_fn: 2647.0000 - val_categorical_accuracy: 0.6132 - val_precision: 0.8356 - val_recall: 0.4226 - val_auc: 0.9131 - lr: 0.0022\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 1.0011 - tp: 7481.0000 - fp: 2117.0000 - tn: 89563.0000 - fn: 10855.0000 - categorical_accuracy: 0.5841 - precision: 0.7794 - recall: 0.4080 - auc: 0.8960 - val_loss: 0.9063 - val_tp: 1943.0000 - val_fp: 350.0000 - val_tn: 22570.0000 - val_fn: 2641.0000 - val_categorical_accuracy: 0.6145 - val_precision: 0.8474 - val_recall: 0.4239 - val_auc: 0.9152 - lr: 0.0021\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 1.0000 - tp: 7504.0000 - fp: 2060.0000 - tn: 89620.0000 - fn: 10832.0000 - categorical_accuracy: 0.5828 - precision: 0.7846 - recall: 0.4092 - auc: 0.8959 - val_loss: 0.9162 - val_tp: 2009.0000 - val_fp: 439.0000 - val_tn: 22481.0000 - val_fn: 2575.0000 - val_categorical_accuracy: 0.6104 - val_precision: 0.8207 - val_recall: 0.4383 - val_auc: 0.9134 - lr: 0.0020\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9931 - tp: 7633.0000 - fp: 2095.0000 - tn: 89585.0000 - fn: 10703.0000 - categorical_accuracy: 0.5876 - precision: 0.7846 - recall: 0.4163 - auc: 0.8977 - val_loss: 0.9016 - val_tp: 2027.0000 - val_fp: 433.0000 - val_tn: 22487.0000 - val_fn: 2557.0000 - val_categorical_accuracy: 0.6126 - val_precision: 0.8240 - val_recall: 0.4422 - val_auc: 0.9153 - lr: 0.0019\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9808 - tp: 7701.0000 - fp: 2063.0000 - tn: 89617.0000 - fn: 10635.0000 - categorical_accuracy: 0.5919 - precision: 0.7887 - recall: 0.4200 - auc: 0.9001 - val_loss: 0.8896 - val_tp: 2073.0000 - val_fp: 442.0000 - val_tn: 22478.0000 - val_fn: 2511.0000 - val_categorical_accuracy: 0.6182 - val_precision: 0.8243 - val_recall: 0.4522 - val_auc: 0.9178 - lr: 0.0018\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9792 - tp: 7680.0000 - fp: 2019.0000 - tn: 89661.0000 - fn: 10656.0000 - categorical_accuracy: 0.5907 - precision: 0.7918 - recall: 0.4188 - auc: 0.9001 - val_loss: 0.8907 - val_tp: 1970.0000 - val_fp: 333.0000 - val_tn: 22587.0000 - val_fn: 2614.0000 - val_categorical_accuracy: 0.6200 - val_precision: 0.8554 - val_recall: 0.4298 - val_auc: 0.9181 - lr: 0.0017\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9722 - tp: 7710.0000 - fp: 2028.0000 - tn: 89652.0000 - fn: 10626.0000 - categorical_accuracy: 0.5970 - precision: 0.7917 - recall: 0.4205 - auc: 0.9022 - val_loss: 0.8995 - val_tp: 1926.0000 - val_fp: 318.0000 - val_tn: 22602.0000 - val_fn: 2658.0000 - val_categorical_accuracy: 0.6191 - val_precision: 0.8583 - val_recall: 0.4202 - val_auc: 0.9160 - lr: 0.0016\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9676 - tp: 7732.0000 - fp: 2087.0000 - tn: 89593.0000 - fn: 10604.0000 - categorical_accuracy: 0.5973 - precision: 0.7875 - recall: 0.4217 - auc: 0.9028 - val_loss: 0.8792 - val_tp: 2062.0000 - val_fp: 392.0000 - val_tn: 22528.0000 - val_fn: 2522.0000 - val_categorical_accuracy: 0.6235 - val_precision: 0.8403 - val_recall: 0.4498 - val_auc: 0.9193 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9471 - tp: 7912.0000 - fp: 2103.0000 - tn: 89577.0000 - fn: 10424.0000 - categorical_accuracy: 0.6023 - precision: 0.7900 - recall: 0.4315 - auc: 0.9068 - val_loss: 0.8792 - val_tp: 2073.0000 - val_fp: 420.0000 - val_tn: 22500.0000 - val_fn: 2511.0000 - val_categorical_accuracy: 0.6267 - val_precision: 0.8315 - val_recall: 0.4522 - val_auc: 0.9195 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9465 - tp: 7888.0000 - fp: 2048.0000 - tn: 89632.0000 - fn: 10448.0000 - categorical_accuracy: 0.6041 - precision: 0.7939 - recall: 0.4302 - auc: 0.9070 - val_loss: 0.8684 - val_tp: 2099.0000 - val_fp: 415.0000 - val_tn: 22505.0000 - val_fn: 2485.0000 - val_categorical_accuracy: 0.6281 - val_precision: 0.8349 - val_recall: 0.4579 - val_auc: 0.9215 - lr: 0.0013\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9529 - tp: 7885.0000 - fp: 2064.0000 - tn: 89616.0000 - fn: 10451.0000 - categorical_accuracy: 0.6009 - precision: 0.7925 - recall: 0.4300 - auc: 0.9057 - val_loss: 0.8812 - val_tp: 2119.0000 - val_fp: 454.0000 - val_tn: 22466.0000 - val_fn: 2465.0000 - val_categorical_accuracy: 0.6235 - val_precision: 0.8236 - val_recall: 0.4623 - val_auc: 0.9191 - lr: 0.0012\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9543 - tp: 7840.0000 - fp: 2095.0000 - tn: 89585.0000 - fn: 10496.0000 - categorical_accuracy: 0.6000 - precision: 0.7891 - recall: 0.4276 - auc: 0.9052 - val_loss: 0.8742 - val_tp: 2116.0000 - val_fp: 426.0000 - val_tn: 22494.0000 - val_fn: 2468.0000 - val_categorical_accuracy: 0.6243 - val_precision: 0.8324 - val_recall: 0.4616 - val_auc: 0.9202 - lr: 0.0011\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9406 - tp: 7991.0000 - fp: 1970.0000 - tn: 89710.0000 - fn: 10345.0000 - categorical_accuracy: 0.6009 - precision: 0.8022 - recall: 0.4358 - auc: 0.9075 - val_loss: 0.8741 - val_tp: 2111.0000 - val_fp: 418.0000 - val_tn: 22502.0000 - val_fn: 2473.0000 - val_categorical_accuracy: 0.6261 - val_precision: 0.8347 - val_recall: 0.4605 - val_auc: 0.9202 - lr: 0.0011\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9339 - tp: 8068.0000 - fp: 2090.0000 - tn: 89590.0000 - fn: 10268.0000 - categorical_accuracy: 0.6062 - precision: 0.7943 - recall: 0.4400 - auc: 0.9092 - val_loss: 0.8719 - val_tp: 2083.0000 - val_fp: 368.0000 - val_tn: 22552.0000 - val_fn: 2501.0000 - val_categorical_accuracy: 0.6300 - val_precision: 0.8499 - val_recall: 0.4544 - val_auc: 0.9210 - lr: 9.9648e-04\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9336 - tp: 7965.0000 - fp: 1982.0000 - tn: 89698.0000 - fn: 10371.0000 - categorical_accuracy: 0.6068 - precision: 0.8007 - recall: 0.4344 - auc: 0.9093 - val_loss: 0.8784 - val_tp: 2088.0000 - val_fp: 401.0000 - val_tn: 22519.0000 - val_fn: 2496.0000 - val_categorical_accuracy: 0.6252 - val_precision: 0.8389 - val_recall: 0.4555 - val_auc: 0.9199 - lr: 9.3129e-04\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9252 - tp: 8103.0000 - fp: 2034.0000 - tn: 89646.0000 - fn: 10233.0000 - categorical_accuracy: 0.6106 - precision: 0.7993 - recall: 0.4419 - auc: 0.9111 - val_loss: 0.8737 - val_tp: 2123.0000 - val_fp: 457.0000 - val_tn: 22463.0000 - val_fn: 2461.0000 - val_categorical_accuracy: 0.6272 - val_precision: 0.8229 - val_recall: 0.4631 - val_auc: 0.9210 - lr: 8.6955e-04\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9237 - tp: 8106.0000 - fp: 2007.0000 - tn: 89673.0000 - fn: 10230.0000 - categorical_accuracy: 0.6078 - precision: 0.8015 - recall: 0.4421 - auc: 0.9114 - val_loss: 0.8746 - val_tp: 2149.0000 - val_fp: 487.0000 - val_tn: 22433.0000 - val_fn: 2435.0000 - val_categorical_accuracy: 0.6265 - val_precision: 0.8153 - val_recall: 0.4688 - val_auc: 0.9204 - lr: 8.1115e-04\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9370 - tp: 8067.0000 - fp: 2081.0000 - tn: 89599.0000 - fn: 10269.0000 - categorical_accuracy: 0.6035 - precision: 0.7949 - recall: 0.4400 - auc: 0.9086 - val_loss: 0.8731 - val_tp: 2088.0000 - val_fp: 421.0000 - val_tn: 22499.0000 - val_fn: 2496.0000 - val_categorical_accuracy: 0.6287 - val_precision: 0.8322 - val_recall: 0.4555 - val_auc: 0.9210 - lr: 7.5596e-04\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9183 - tp: 8107.0000 - fp: 1992.0000 - tn: 89688.0000 - fn: 10229.0000 - categorical_accuracy: 0.6141 - precision: 0.8028 - recall: 0.4421 - auc: 0.9123 - val_loss: 0.8712 - val_tp: 2180.0000 - val_fp: 520.0000 - val_tn: 22400.0000 - val_fn: 2404.0000 - val_categorical_accuracy: 0.6272 - val_precision: 0.8074 - val_recall: 0.4756 - val_auc: 0.9209 - lr: 7.0388e-04\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9236 - tp: 8197.0000 - fp: 2103.0000 - tn: 89577.0000 - fn: 10139.0000 - categorical_accuracy: 0.6085 - precision: 0.7958 - recall: 0.4470 - auc: 0.9112 - val_loss: 0.8702 - val_tp: 2111.0000 - val_fp: 412.0000 - val_tn: 22508.0000 - val_fn: 2473.0000 - val_categorical_accuracy: 0.6265 - val_precision: 0.8367 - val_recall: 0.4605 - val_auc: 0.9212 - lr: 6.5477e-04\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9090 - tp: 8143.0000 - fp: 1969.0000 - tn: 89711.0000 - fn: 10193.0000 - categorical_accuracy: 0.6141 - precision: 0.8053 - recall: 0.4441 - auc: 0.9140 - val_loss: 0.8648 - val_tp: 2135.0000 - val_fp: 441.0000 - val_tn: 22479.0000 - val_fn: 2449.0000 - val_categorical_accuracy: 0.6291 - val_precision: 0.8288 - val_recall: 0.4658 - val_auc: 0.9221 - lr: 6.0852e-04\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9113 - tp: 8142.0000 - fp: 2055.0000 - tn: 89625.0000 - fn: 10194.0000 - categorical_accuracy: 0.6162 - precision: 0.7985 - recall: 0.4440 - auc: 0.9137 - val_loss: 0.8632 - val_tp: 2167.0000 - val_fp: 479.0000 - val_tn: 22441.0000 - val_fn: 2417.0000 - val_categorical_accuracy: 0.6302 - val_precision: 0.8190 - val_recall: 0.4727 - val_auc: 0.9226 - lr: 5.6502e-04\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.9031 - tp: 8298.0000 - fp: 2024.0000 - tn: 89656.0000 - fn: 10038.0000 - categorical_accuracy: 0.6168 - precision: 0.8039 - recall: 0.4526 - auc: 0.9151 - val_loss: 0.8664 - val_tp: 2109.0000 - val_fp: 447.0000 - val_tn: 22473.0000 - val_fn: 2475.0000 - val_categorical_accuracy: 0.6322 - val_precision: 0.8251 - val_recall: 0.4601 - val_auc: 0.9220 - lr: 5.2413e-04\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.9061 - tp: 8195.0000 - fp: 1960.0000 - tn: 89720.0000 - fn: 10141.0000 - categorical_accuracy: 0.6168 - precision: 0.8070 - recall: 0.4469 - auc: 0.9143 - val_loss: 0.8642 - val_tp: 2102.0000 - val_fp: 409.0000 - val_tn: 22511.0000 - val_fn: 2482.0000 - val_categorical_accuracy: 0.6337 - val_precision: 0.8371 - val_recall: 0.4586 - val_auc: 0.9226 - lr: 4.8576e-04\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8968 - tp: 8302.0000 - fp: 2042.0000 - tn: 89638.0000 - fn: 10034.0000 - categorical_accuracy: 0.6164 - precision: 0.8026 - recall: 0.4528 - auc: 0.9159 - val_loss: 0.8669 - val_tp: 2137.0000 - val_fp: 459.0000 - val_tn: 22461.0000 - val_fn: 2447.0000 - val_categorical_accuracy: 0.6346 - val_precision: 0.8232 - val_recall: 0.4662 - val_auc: 0.9223 - lr: 4.4978e-04\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.8998 - tp: 8319.0000 - fp: 1978.0000 - tn: 89702.0000 - fn: 10017.0000 - categorical_accuracy: 0.6193 - precision: 0.8079 - recall: 0.4537 - auc: 0.9157 - val_loss: 0.8645 - val_tp: 2160.0000 - val_fp: 464.0000 - val_tn: 22456.0000 - val_fn: 2424.0000 - val_categorical_accuracy: 0.6315 - val_precision: 0.8232 - val_recall: 0.4712 - val_auc: 0.9228 - lr: 4.1607e-04\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8940 - tp: 8330.0000 - fp: 2085.0000 - tn: 89595.0000 - fn: 10006.0000 - categorical_accuracy: 0.6192 - precision: 0.7998 - recall: 0.4543 - auc: 0.9166 - val_loss: 0.8638 - val_tp: 2148.0000 - val_fp: 457.0000 - val_tn: 22463.0000 - val_fn: 2436.0000 - val_categorical_accuracy: 0.6294 - val_precision: 0.8246 - val_recall: 0.4686 - val_auc: 0.9229 - lr: 3.8454e-04\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8876 - tp: 8407.0000 - fp: 2018.0000 - tn: 89662.0000 - fn: 9929.0000 - categorical_accuracy: 0.6202 - precision: 0.8064 - recall: 0.4585 - auc: 0.9177 - val_loss: 0.8656 - val_tp: 2152.0000 - val_fp: 443.0000 - val_tn: 22477.0000 - val_fn: 2432.0000 - val_categorical_accuracy: 0.6302 - val_precision: 0.8293 - val_recall: 0.4695 - val_auc: 0.9225 - lr: 3.5507e-04\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8852 - tp: 8439.0000 - fp: 1967.0000 - tn: 89713.0000 - fn: 9897.0000 - categorical_accuracy: 0.6255 - precision: 0.8110 - recall: 0.4602 - auc: 0.9183 - val_loss: 0.8661 - val_tp: 2177.0000 - val_fp: 471.0000 - val_tn: 22449.0000 - val_fn: 2407.0000 - val_categorical_accuracy: 0.6289 - val_precision: 0.8221 - val_recall: 0.4749 - val_auc: 0.9225 - lr: 3.2756e-04\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8856 - tp: 8442.0000 - fp: 2027.0000 - tn: 89653.0000 - fn: 9894.0000 - categorical_accuracy: 0.6257 - precision: 0.8064 - recall: 0.4604 - auc: 0.9185 - val_loss: 0.8640 - val_tp: 2167.0000 - val_fp: 472.0000 - val_tn: 22448.0000 - val_fn: 2417.0000 - val_categorical_accuracy: 0.6322 - val_precision: 0.8211 - val_recall: 0.4727 - val_auc: 0.9232 - lr: 3.0190e-04\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.8778 - tp: 8438.0000 - fp: 1953.0000 - tn: 89727.0000 - fn: 9898.0000 - categorical_accuracy: 0.6243 - precision: 0.8120 - recall: 0.4602 - auc: 0.9197 - val_loss: 0.8637 - val_tp: 2156.0000 - val_fp: 465.0000 - val_tn: 22455.0000 - val_fn: 2428.0000 - val_categorical_accuracy: 0.6348 - val_precision: 0.8226 - val_recall: 0.4703 - val_auc: 0.9232 - lr: 2.7799e-04\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.8734 - tp: 8500.0000 - fp: 1946.0000 - tn: 89734.0000 - fn: 9836.0000 - categorical_accuracy: 0.6273 - precision: 0.8137 - recall: 0.4636 - auc: 0.9203 - val_loss: 0.8630 - val_tp: 2179.0000 - val_fp: 477.0000 - val_tn: 22443.0000 - val_fn: 2405.0000 - val_categorical_accuracy: 0.6335 - val_precision: 0.8204 - val_recall: 0.4753 - val_auc: 0.9234 - lr: 2.5574e-04\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8752 - tp: 8513.0000 - fp: 1962.0000 - tn: 89718.0000 - fn: 9823.0000 - categorical_accuracy: 0.6265 - precision: 0.8127 - recall: 0.4643 - auc: 0.9201 - val_loss: 0.8649 - val_tp: 2198.0000 - val_fp: 509.0000 - val_tn: 22411.0000 - val_fn: 2386.0000 - val_categorical_accuracy: 0.6337 - val_precision: 0.8120 - val_recall: 0.4795 - val_auc: 0.9231 - lr: 2.3505e-04\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.8784 - tp: 8570.0000 - fp: 2088.0000 - tn: 89592.0000 - fn: 9766.0000 - categorical_accuracy: 0.6277 - precision: 0.8041 - recall: 0.4674 - auc: 0.9196 - val_loss: 0.8664 - val_tp: 2188.0000 - val_fp: 493.0000 - val_tn: 22427.0000 - val_fn: 2396.0000 - val_categorical_accuracy: 0.6322 - val_precision: 0.8161 - val_recall: 0.4773 - val_auc: 0.9227 - lr: 2.1584e-04\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8750 - tp: 8541.0000 - fp: 1980.0000 - tn: 89700.0000 - fn: 9795.0000 - categorical_accuracy: 0.6276 - precision: 0.8118 - recall: 0.4658 - auc: 0.9203 - val_loss: 0.8666 - val_tp: 2207.0000 - val_fp: 511.0000 - val_tn: 22409.0000 - val_fn: 2377.0000 - val_categorical_accuracy: 0.6339 - val_precision: 0.8120 - val_recall: 0.4815 - val_auc: 0.9228 - lr: 1.9802e-04\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.8794 - tp: 8509.0000 - fp: 1964.0000 - tn: 89716.0000 - fn: 9827.0000 - categorical_accuracy: 0.6265 - precision: 0.8125 - recall: 0.4641 - auc: 0.9195 - val_loss: 0.8646 - val_tp: 2188.0000 - val_fp: 478.0000 - val_tn: 22442.0000 - val_fn: 2396.0000 - val_categorical_accuracy: 0.6350 - val_precision: 0.8207 - val_recall: 0.4773 - val_auc: 0.9231 - lr: 1.8151e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 13ms/step - loss: 0.8719 - tp: 8537.0000 - fp: 1978.0000 - tn: 89702.0000 - fn: 9799.0000 - categorical_accuracy: 0.6253 - precision: 0.8119 - recall: 0.4656 - auc: 0.9205 - val_loss: 0.8643 - val_tp: 2200.0000 - val_fp: 496.0000 - val_tn: 22424.0000 - val_fn: 2384.0000 - val_categorical_accuracy: 0.6348 - val_precision: 0.8160 - val_recall: 0.4799 - val_auc: 0.9233 - lr: 1.6621e-04\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8720 - tp: 8496.0000 - fp: 2008.0000 - tn: 89672.0000 - fn: 9840.0000 - categorical_accuracy: 0.6246 - precision: 0.8088 - recall: 0.4634 - auc: 0.9204 - val_loss: 0.8646 - val_tp: 2199.0000 - val_fp: 494.0000 - val_tn: 22426.0000 - val_fn: 2385.0000 - val_categorical_accuracy: 0.6350 - val_precision: 0.8166 - val_recall: 0.4797 - val_auc: 0.9233 - lr: 1.5207e-04\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 2s 13ms/step - loss: 0.8775 - tp: 8483.0000 - fp: 1984.0000 - tn: 89696.0000 - fn: 9853.0000 - categorical_accuracy: 0.6239 - precision: 0.8105 - recall: 0.4626 - auc: 0.9195 - val_loss: 0.8644 - val_tp: 2196.0000 - val_fp: 490.0000 - val_tn: 22430.0000 - val_fn: 2388.0000 - val_categorical_accuracy: 0.6326 - val_precision: 0.8176 - val_recall: 0.4791 - val_auc: 0.9233 - lr: 1.3900e-04\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8773 - tp: 8529.0000 - fp: 2034.0000 - tn: 89646.0000 - fn: 9807.0000 - categorical_accuracy: 0.6235 - precision: 0.8074 - recall: 0.4652 - auc: 0.9195 - val_loss: 0.8648 - val_tp: 2179.0000 - val_fp: 473.0000 - val_tn: 22447.0000 - val_fn: 2405.0000 - val_categorical_accuracy: 0.6335 - val_precision: 0.8216 - val_recall: 0.4753 - val_auc: 0.9233 - lr: 1.2694e-04\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8701 - tp: 8497.0000 - fp: 1953.0000 - tn: 89727.0000 - fn: 9839.0000 - categorical_accuracy: 0.6261 - precision: 0.8131 - recall: 0.4634 - auc: 0.9208 - val_loss: 0.8642 - val_tp: 2183.0000 - val_fp: 471.0000 - val_tn: 22449.0000 - val_fn: 2401.0000 - val_categorical_accuracy: 0.6339 - val_precision: 0.8225 - val_recall: 0.4762 - val_auc: 0.9235 - lr: 1.1583e-04\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8704 - tp: 8551.0000 - fp: 2012.0000 - tn: 89668.0000 - fn: 9785.0000 - categorical_accuracy: 0.6281 - precision: 0.8095 - recall: 0.4664 - auc: 0.9208 - val_loss: 0.8647 - val_tp: 2189.0000 - val_fp: 482.0000 - val_tn: 22438.0000 - val_fn: 2395.0000 - val_categorical_accuracy: 0.6361 - val_precision: 0.8195 - val_recall: 0.4775 - val_auc: 0.9233 - lr: 1.0558e-04\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 2s 11ms/step - loss: 0.8713 - tp: 8519.0000 - fp: 1996.0000 - tn: 89684.0000 - fn: 9817.0000 - categorical_accuracy: 0.6290 - precision: 0.8102 - recall: 0.4646 - auc: 0.9208 - val_loss: 0.8644 - val_tp: 2189.0000 - val_fp: 492.0000 - val_tn: 22428.0000 - val_fn: 2395.0000 - val_categorical_accuracy: 0.6357 - val_precision: 0.8165 - val_recall: 0.4775 - val_auc: 0.9234 - lr: 9.6160e-05\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 2s 12ms/step - loss: 0.8711 - tp: 8503.0000 - fp: 2005.0000 - tn: 89675.0000 - fn: 9833.0000 - categorical_accuracy: 0.6293 - precision: 0.8092 - recall: 0.4637 - auc: 0.9209 - val_loss: 0.8646 - val_tp: 2203.0000 - val_fp: 491.0000 - val_tn: 22429.0000 - val_fn: 2381.0000 - val_categorical_accuracy: 0.6348 - val_precision: 0.8177 - val_recall: 0.4806 - val_auc: 0.9234 - lr: 8.7498e-05\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.1823 - tp: 2486.0000 - fp: 1110.0000 - tn: 27540.0000 - fn: 3244.0000 - categorical_accuracy: 0.5558 - precision: 0.6913 - recall: 0.4339 - auc: 0.8716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857174</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>28404.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>0.641536</td>\n",
       "      <td>0.902420</td>\n",
       "      <td>0.397033</td>\n",
       "      <td>0.926307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856898</td>\n",
       "      <td>2468.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>28194.0</td>\n",
       "      <td>3262.0</td>\n",
       "      <td>0.635079</td>\n",
       "      <td>0.844049</td>\n",
       "      <td>0.430716</td>\n",
       "      <td>0.924351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.011486</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>27823.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>0.575567</td>\n",
       "      <td>0.744517</td>\n",
       "      <td>0.420593</td>\n",
       "      <td>0.893107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.951549</td>\n",
       "      <td>2239.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>28202.0</td>\n",
       "      <td>3491.0</td>\n",
       "      <td>0.579407</td>\n",
       "      <td>0.833271</td>\n",
       "      <td>0.390750</td>\n",
       "      <td>0.901696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.182330</td>\n",
       "      <td>2486.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>27540.0</td>\n",
       "      <td>3244.0</td>\n",
       "      <td>0.555846</td>\n",
       "      <td>0.691324</td>\n",
       "      <td>0.433857</td>\n",
       "      <td>0.871578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss      tp      fp       tn      fn  accuracy  precision    recall  \\\n",
       "0  0.857174  2275.0   246.0  28404.0  3455.0  0.641536   0.902420  0.397033   \n",
       "0  0.856898  2468.0   456.0  28194.0  3262.0  0.635079   0.844049  0.430716   \n",
       "0  1.011486  2410.0   827.0  27823.0  3320.0  0.575567   0.744517  0.420593   \n",
       "0  0.951549  2239.0   448.0  28202.0  3491.0  0.579407   0.833271  0.390750   \n",
       "0  1.182330  2486.0  1110.0  27540.0  3244.0  0.555846   0.691324  0.433857   \n",
       "\n",
       "        auc  \n",
       "0  0.926307  \n",
       "0  0.924351  \n",
       "0  0.893107  \n",
       "0  0.901696  \n",
       "0  0.871578  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WHICH_DATA = \"radar\" # can be \"contact\" or \"radar\"\n",
    "WHICH_MODEL = \"fully_connected_small\"\n",
    "all_results_radar = helper_functions.kfold_cv_experiment(which_data=WHICH_DATA, which_model=WHICH_MODEL, hyperparams=HYPERPARAMS, metrics=METRICS, class_map=CLASS_MAP, n_folds=HYPERPARAMS[\"N_FOLDS\"])\n",
    "display(all_results_radar)\n",
    "\n",
    "# Save results\n",
    "Path(\"results/\"+WHICH_DATA+\"_kfold/\"+HYPERPARAMS[\"RUN_ID\"]).mkdir(parents=True, exist_ok=True)\n",
    "FILENAME = \"results/\"+WHICH_DATA+\"_kfold/\"+HYPERPARAMS[\"RUN_ID\"]+\"/results_\"+WHICH_MODEL+\".xlsx\"\n",
    "all_results_radar.to_excel(FILENAME, sheet_name=\"results\")\n",
    "writer = pd.ExcelWriter(FILENAME, engine='openpyxl', mode='a')\n",
    "pd.DataFrame(data=HYPERPARAMS, index=[0]).T.to_excel(writer, sheet_name=\"hyperparams\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f03372018e38d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f03372018e38d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6008;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tensorboard for visualisation, use jupyter magic to run it based on things saved during training\n",
    "%load_ext tensorboard\n",
    "if WHICH_DATA==\"contact\":\n",
    "    path = \"model_training_logs/contact_kfold/\"+HYPERPARAMS[\"RUN_ID\"]\n",
    "    %tensorboard --logdir $path --host localhost\n",
    "else:\n",
    "    path = \"model_training_logs/radar_kfold/\"+HYPERPARAMS[\"RUN_ID\"]\n",
    "    %tensorboard --logdir $path --host localhost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
